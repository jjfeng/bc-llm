import os
from os.path import join as path_join
from nestly.scons import SConsWrap
from nestly import Nest
from SCons.Script import Environment, Command, AddOption

"""
imagenette experiment
"""

Import('env')
localenv = env.Clone()

# Set up state
nest = SConsWrap(Nest(), localenv['output'], alias_environment=localenv)

# NOTE: The LLM Api only supports images for OpenAI models

BATCH_SIZE = 40
NUM_NEW_TOKENS = 300

NUM_GREEDY = 2
NUM_EPOCHS = 4
NUM_RESTRICTED_EPOCHS = 0
MAX_ITERS = 35
NUM_BOOST_ITERS = 15

BAYESIAN_PRIOR_PROMPT = 'exp_imagenette/prompts/bayesian_prior.txt'
BAYESIAN_ITER_PROMPT = 'exp_imagenette/prompts/bayesian_iter.txt'
EXTRACT_LLM_PROMPT = 'exp_imagenette/prompts/extract_concepts.txt'
BASELINE_PROMPT = 'exp_imagenette/prompts/baseline_init.txt'
BOOSTING_PROMPT = 'exp_imagenette/prompts/boosting_iter.txt'
CONCEPTS_PROMPT = 'exp_imagenette/prompts/concept_questions.txt'

LLM_MODELS = [
    'gpt-4o-mini'
]
LLM_DICT = {
    'gpt-4o-mini': True, # true using API
}

nest.add('seed', [
        0
    ],
    label_func=lambda c: "seed_%d" % c
)

nest.add(
    'max_num_obs', # per class
    [200],
    label_func=lambda c: f'max_num_obs_{c}')

@nest.add_target_with_env(localenv)
def assemble_imagenette(env, outdir, c):
    cmd = [
        'python scripts/assemble_imagenette.py',
        '--seed', c['seed'] + 1,
        '--labelled-data ${TARGETS[0]}',
        '--max-num-obs', c['max_num_obs'],
    ]
    
    targets = [
        path_join(outdir, 'labels.csv')
    ]

    return env.Command(
        targets,
        [],
        ' '.join(map(str, cmd))
    )

nest.add('llm_model', LLM_MODELS)

nest.add('test_frac',
    [
        0.5
    ],
    label_func=lambda c: "test_%.2f" % c
)

@nest.add_target_with_env(localenv)
def train_test_split(env, outdir, c):
    cmd = [
        'python scripts/train_test_split.py',
        '--seed', c['seed'] + 1,
        '--data-csv ${SOURCES[0]}',
        '--test-frac',
        c['test_frac'],
        '--indices-csv ${TARGETS[0]}',
    ]

    sources = c['assemble_imagenette']
    targets = [
        path_join(outdir, 'train_test_indices.csv'),
    ]

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

@nest.add_target_with_env(localenv)
def extract_llm_output(env, outdir, c):
    targets = [
        path_join(outdir, 'log_extract_informed.txt'),
        path_join(outdir, 'concept_extractions_informed.csv'),
    ]
    cmd = [
        'python scripts/extract_llm_concepts.py',
        '--cache cache_imagenette.db',
        f'--seed',
        c['seed'] + 3,
        '--is-image',
        '--num-new-tokens',
        NUM_NEW_TOKENS,
        '--in-dataset-file ${SOURCES[0]}',
        '--indices ${SOURCES[1]}',
        '--batch-size',
        40,
        '--prompt-file',
        EXTRACT_LLM_PROMPT,
        '--log-file ${TARGETS[0]}',
        '--llm-output ${TARGETS[1]}',
        '--llm-model-type',
        c['llm_model'],
        '--use-api',
    ]

    sources = [
        c['assemble_imagenette'][0],
        c['train_test_split'][0],
    ]

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

nest.add(
    'num_meta_concepts', 
    [10],
    label_func=lambda c: "num_concepts_%s" % c
)

nest.add_aggregate('all_test_extractions', list)
nest.add_aggregate('bayesian_agg', list)
nest.add_aggregate('result_agg', list)
nest.add_aggregate('train_baseline_history', str)
nest.add_aggregate('train_boosting_history', str)

@nest.add_target_with_env(localenv)
def train_baseline(env, outdir, c):
    cached_extractions = path_join('exp_imagenette', outdir, 'baseline_extractions.pkl')
    cmd = [
        'python scripts/train_baseline.py',
        f'--seed',
        c['seed'] + 2,
        '--batch-size', BATCH_SIZE,
        '--cache cache_imagenette.db',
        '--num-meta-concepts',
        c['num_meta_concepts'],
        '--learner-type count_l2',
        '--in-dataset-file ${SOURCES[0]}',
        '--indices-csv ${SOURCES[1]}',
        '--out-training-history-file ${TARGETS[0]}',
        '--log-file  ${TARGETS[1]}',
        '--num-top-attributes',
        c['num_meta_concepts'] + 20,
        '--llm-model-type',
         c['llm_model'],
         '--out-extractions', cached_extractions,
         '--is-image',
         '--prompt-concepts-file', CONCEPTS_PROMPT,
         '--baseline-init-file', BASELINE_PROMPT,
         '--init-concepts-file ${SOURCES[2]}'
    ]

    sources = [
        c['assemble_imagenette'][0],
        c['train_test_split'][0],
        c['extract_llm_output'][1],
    ]
    targets = [
        path_join(outdir, 'baseline_history.pkl'),
        path_join(outdir, 'log_train_baseline1.txt'),
    ]
    c['train_baseline_history'] = targets[0]
    # if os.path.exists(targets[0]):
    #     return

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

@nest.add_target_with_env(localenv)
def train_blackbox(env, outdir, c):
    cmd = [
            'python scripts/train_image_blackbox.py',
            '--seed', c['seed'] + 2,
            '--in-dataset-file ${SOURCES[0]}',
            '--indices-csv ${SOURCES[1]}',
            '--log-file  ${TARGETS[0]}',
            '--out-mdl ${TARGETS[1]}'
    ]

    sources = [
        c['assemble_imagenette'][0],
        c['train_test_split'][0],
    ]
    targets = [
        path_join(outdir, 'log_train_image_resnet.txt'),
        path_join(outdir, 'resnet_image_mdl.pkl'),
    ]

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )


@nest.add_target_with_env(localenv)
def evaluate_blackbox(env, outdir, c):
    cmd = [
            'python scripts/evaluate_image_blackbox.py',
            f'--seed', c['seed'] + 5,
            '--in-dataset-file ${SOURCES[0]}',
            '--indices-csv ${SOURCES[1]}',
            '--in-mdl ${SOURCES[2]}',
            '--results-csv ${TARGETS[0]}'
    ]

    sources = [
        c['assemble_imagenette'][0],
        c['train_test_split'][0],
        c['train_blackbox'][1]
    ]
    targets = [
        path_join(outdir, 'image_resnet_results.csv'),
    ]
    c['result_agg'].append(targets[0])

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

@nest.add_target_with_env(localenv)
def train_boosting(env, outdir, c):
#    cached_extractions = path_join('exp_imagenette', outdir, 'boosting_extractions.pkl')
    cmd = [
        'python scripts/train_boosting.py',
        f'--seed',
        c['seed'] + 2,
        '--cache cache_imagenette.db',
        '--num-boost-samples', 2,
        '--num-iters', NUM_BOOST_ITERS,
        '--batch-size', BATCH_SIZE,
        '--boosting-prompt', BOOSTING_PROMPT,
        '--prompt-concepts-file', CONCEPTS_PROMPT,
        '--in-dataset-file ${SOURCES[0]}',
        '--indices-csv ${SOURCES[1]}',
        '--out-training-history-file ${TARGETS[0]}',
        '--log-file  ${TARGETS[1]}',
        '--llm-model-type', c['llm_model'],
        '--use-api' if LLM_DICT[c['llm_model']] else '',
#        '--out-extractions', cached_extractions,
         '--is-image',
    ]

    sources = [
        c["assemble_imagenette"][0],
        c['train_test_split'][0],
    ]
    targets = [
        path_join(outdir, 'boosting_history.pkl'),
        path_join(outdir, 'log_train_boosting.txt')
    ]
    c['train_boosting_history'] = targets[0]
    if os.path.exists(targets[0]):
        return

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

@nest.add_target_with_env(localenv)
def evaluate_boosting(env, outdir, c):
    cmd = [
        'python scripts/evaluate_bayesian.py',
        f'--seed',
        c['seed'] + 5,
        '--cache cache_imagenette.db',
        '--method-name boosting',
        '--num-posterior-iters',
        1,
        '--batch-size',
        BATCH_SIZE,
        '--prompt-concepts-file', CONCEPTS_PROMPT,
        '--in-dataset-file ${SOURCES[0]}',
        '--indices-csv ${SOURCES[1]}',
        '--training-history-file ${SOURCES[2]}',
        '--log-file ${TARGETS[0]}',
        '--llm-model-type',
        c['llm_model'],
        '--use-api' if LLM_DICT[c['llm_model']] else '',
        '--result-csv ${TARGETS[1]}',
        '--is-image',
    ]

    sources = [
        c["assemble_imagenette"][0],
        c['train_test_split'][0],
        c['train_boosting_history'],
    ]
    targets = [
        path_join(outdir, 'test_boosting_log.txt'),
        path_join(outdir, 'result_boosting.csv'),
    ]
    c['result_agg'].append(targets[1])

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

nest.add(
    'bayesian',
    [
        'bayesian',
    ])

nest.add(
    'train_frac',
    [
        0.5
    ],
    label_func=lambda c: "train_frac_%.2f" % c)

nest.add_aggregate('train_bayesian_history', str)
@nest.add_target_with_env(localenv)
def train_bayesian(env, outdir, c):
    cached_extractions = path_join('exp_imagenette', outdir, 'extractions.pkl')
    cmd = [
        'python scripts/train_bayesian.py',
        f'--seed',
        c['seed'] + 4,
        '--cache cache_imagenette.db',
        '--batch-size', BATCH_SIZE,
        '--num-greedy-holdout', 2,
        '--num-greedy-epochs', NUM_GREEDY,
        '--is-greedy-metric-acc',
        '--max-epochs',
        NUM_GREEDY,
        '--num-meta-concepts',
        c['num_meta_concepts'],
        '--learner-type count_l2',
        '--final-learner l2',
        '--train-frac', c['train_frac'],
        '--in-dataset-file ${SOURCES[0]}',
        '--indices-csv ${SOURCES[2]}',
        '--out-extraction', cached_extractions,
        '--log-file ${TARGETS[0]}',
        '--init-history-file ${SOURCES[1]}',
        '--training-history-file ${TARGETS[1]}',
        '--aucs-plot-file ${TARGETS[2]}',
        '--llm-extraction-type',
        c['llm_model'],
        '--llm-iter-type',
        'gpt-4o',
        '--is-image',
        '--use-api',
        '--prompt-concepts-file', CONCEPTS_PROMPT,
        '--prompt-prior-file', BAYESIAN_PRIOR_PROMPT,
        '--prompt-iter-file', BAYESIAN_ITER_PROMPT,
        '--prompt-iter-type conditional',
        '--init-concepts-file ${SOURCES[3]}',
    ]

    sources = [
        c['assemble_imagenette'][0],
        c['train_baseline_history'],
        c['train_test_split'][0],
        c['extract_llm_output'][1],
    ]
    targets = [
        path_join(outdir, 'log_train_bayesian.txt'),
        path_join(outdir, 'training_history.pkl'),
        path_join(outdir, 'aucs.png'),
    ]
    c['train_bayesian_history'] = targets[1]
    c['bayesian_agg'].append(targets[1])
    # if os.path.exists(targets[1]):
    #     return

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
        )

@nest.add_target_with_env(localenv)
def evaluate_bayesian(env, outdir, c):
    cmd = [
        'python scripts/evaluate_bayesian.py',
        f'--seed',
        c['seed'] + 5,
        '--cache cache.db',
        '--num-posterior-iters',
        c['num_meta_concepts'] * 2,
        '--batch-size',
        BATCH_SIZE,
        '--method-name bayesian',
        '--in-dataset-file ${SOURCES[0]}',
        '--indices-csv ${SOURCES[1]}',
        '--training-history-file ${SOURCES[2]}',
        # '--out-extraction ${SOURCES[3]}',
        '--log-file ${TARGETS[0]}',
        '--llm-model-type',
        c['llm_model'],
        '--prompt-concepts-file', CONCEPTS_PROMPT,
        '--use-api' if LLM_DICT[c['llm_model']] else '',
        '--is-image',
        # '--calib ${TARGETS[1]}',
        '--result-csv ${TARGETS[1]}',
    ]

    sources = [
        c['assemble_imagenette'][0],
        c['train_test_split'][0],
        c['train_bayesian_history'],
    ]
    targets = [
        path_join(outdir, 'test_bayesian_log.txt'),
        # path_join(outdir, 'calib_bayesian.png'),
        path_join(outdir, 'result_bayesian.csv'),
    ]
    c['result_agg'].append(targets[1])

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )
