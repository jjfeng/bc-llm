{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"text_topic_extraction\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bertopic import BERTopic\n",
    "\n",
    "import asyncio\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "from text_topic_extraction.utils.matrix_builder import MatrixBuilder\n",
    "from text_topic_extraction.concept_extractor.concept_extractor import Concept, PatientConcepts\n",
    "from text_topic_extraction.text_topic_processor import TextTopicProcessor, AsyncTextTopicProcessor, BERTopicModeler, QuestionGenerator, AnswerGenerator, AsyncAnswerGenerator\n",
    "from text_topic_extraction.config import API_VERSION, AZURE_ENDPOINT, OPENAI_API_KEY, USE_AZURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_prompt = \"\"\"\n",
    "The following topics were found in clinical notes. Generate yes/no questions for the following medical topics:\n",
    "{topics_text}\n",
    "Return a JSON object with topic numbers as keys and questions as values. Example:\n",
    "{\n",
    "\"1\": \"Does the note mention the patient having a history of diabetes?\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "answer_prompt = \"\"\"\n",
    "You will be given a clinical note. I will give you a series of questions. Your task is answer each question with a probability from 0 to 1. Summarize the response with a JSON that includes your answer to all of the questions. Questions:\n",
    "{prompt_questions}\n",
    "\n",
    "clinical note:\n",
    "{sentence}\n",
    "\n",
    "Example answer: {\n",
    "    \"Does this person smoke?\": 0,\n",
    "    \"Does this person drink?\": 1,\n",
    "    \"Does this note mention alcohol?\": 0.5\n",
    "}\n",
    "Answer all the questions and do not answer with anything else besides valid JSON. Do not add comments to the JSON.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_extract_df = pd.read_csv(\"../llm-bart/exp_mimic/_output/long_notes/max_obs_-1/seed_0/gpt-4o-mini/concept_extractions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       male, man, gentleman,age 82, elderly, senior,s...\n",
       "1       81-year-old, elderly, senior,female, woman, ad...\n",
       "2       75 years, elderly, senior,man, male,retired, u...\n",
       "3       66 year old, elderly, senior,male, man, adult,...\n",
       "4       female, woman, patient,elderly, senior, aged,m...\n",
       "                              ...                        \n",
       "7038    tobacco use, smoking, nicotine use,15 pack yea...\n",
       "7039    86 M, elderly, senior,prostate cancer, cancer,...\n",
       "7040    86 M, elderly, senior,prostate cancer, cancer,...\n",
       "7041    elderly, senior, advanced age,female, woman,fe...\n",
       "7042    male, man, gender,68 years old, elderly, senio...\n",
       "Name: llm_output, Length: 7043, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_extract_df.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idxs = np.random.choice(llm_extract_df.shape[0], llm_extract_df.shape[0], replace=False)\n",
    "train_idxs = rand_idxs[:400]\n",
    "test_idxs = rand_idxs[400:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_notes = {}\n",
    "for patient_id in rand_idxs[:800]:\n",
    "    note_text = llm_extract_df.iloc[patient_id].sentence\n",
    "    note_type = \"H&P\"\n",
    "    patient_notes[str(patient_id)] = [{\"note_text\": note_text, \"note_type\": note_type}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_id = 0\n",
    "patient_concepts = {}\n",
    "for patient_id in rand_idxs[:800]:\n",
    "    a = llm_extract_df.iloc[patient_id].llm_output.split(\",\")\n",
    "    concept_list = [Concept(id=str(concept_id + concept_offset_id), descriptor=protoconcept.strip().lower()) for concept_offset_id, protoconcept in enumerate(a)]\n",
    "    concept_id += len(concept_list)\n",
    "    patient_concepts[str(patient_id)] = PatientConcepts(\n",
    "        patient_id=str(patient_id),\n",
    "        all_concepts=concept_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 16:01:12,200 - text_topic_extraction.cache.cache_manager - INFO - Text Topic Extraction cache initialized at cache/text_topic_cache.duckdb\n",
      "2025-03-13 16:01:12,233 - text_topic_extraction.text_topic_processor - INFO - Initialized TextTopicProcessor with model gpt-4o-mini-2024-07-18\n",
      "2025-03-13 16:01:12,239 - text_topic_extraction.cache.cache_manager - INFO - Text Topic Extraction cache initialized at cache/text_topic_cache.duckdb\n",
      "2025-03-13 16:01:12,245 - text_topic_extraction.text_topic_processor - INFO - Initialized AsyncTextTopicProcessor with model gpt-4o-mini-2024-07-18\n"
     ]
    }
   ],
   "source": [
    "processor = TextTopicProcessor(\n",
    "    model_type=\"gpt-4o-mini-2024-07-18\",\n",
    "    # \"gpt-4o-mini-2024-07-18\", \n",
    "    # model_type=\"gpt-4o-2024-08-06\",\n",
    "    temperature=0.0,\n",
    "    num_topics=400,\n",
    "    use_cache=True,\n",
    "    use_structured_output=True,\n",
    "    use_azure=False,\n",
    "    azure_endpoint=AZURE_ENDPOINT,\n",
    "    api_version=API_VERSION,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    cache_dir=\"cache\",\n",
    "    concept_prompt_template=\"{notes}\",\n",
    "    concept_questions_prompt_template=question_prompt,\n",
    "    answer_prompt_template=answer_prompt,\n",
    ")\n",
    "async_processor = AsyncTextTopicProcessor(\n",
    "    model_type=\"gpt-4o-mini-2024-07-18\",\n",
    "    # \"gpt-4o-mini-2024-07-18\", \n",
    "    # model_type=\"gpt-4o-2024-08-06\",\n",
    "    temperature=0.0,\n",
    "    num_topics=400,\n",
    "    use_cache=True,\n",
    "    use_structured_output=True,\n",
    "    use_azure=False,\n",
    "    azure_endpoint=AZURE_ENDPOINT,\n",
    "    api_version=API_VERSION,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    cache_dir=\"cache\",\n",
    "    concept_prompt_template=\"{notes}\",\n",
    "    concept_questions_prompt_template=question_prompt,\n",
    "    answer_prompt_template=answer_prompt,\n",
    "    max_concurrent_patients=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.patient_notes = patient_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x106616dd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.openai_client.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 16:01:12,255 - text_topic_extraction.topic_modeler.bertopic_modeler - INFO - Initialized BERTopicModeler with 400 topics\n"
     ]
    }
   ],
   "source": [
    "topic_modeler = BERTopicModeler(\n",
    "    num_topics=processor.num_topics,\n",
    "    embedding_model=(\n",
    "        processor.embedding_model if processor.embedding_model != \"default\" else None\n",
    "    ),\n",
    "    vectorizer_model=processor.vectorizer_model,\n",
    "    min_topic_size=processor.min_topic_size,\n",
    "    language=processor.language,\n",
    "    n_gram_range=processor.n_gram_range,\n",
    ")\n",
    "\n",
    "question_generator = QuestionGenerator(\n",
    "    llm_api=processor.openai_client,\n",
    "    batch_prompt_template=processor.concept_questions_prompt_template,\n",
    ")\n",
    "answer_generator = AsyncAnswerGenerator(\n",
    "    llm_api=async_processor.openai_client, prompt_template=processor.answer_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 16:01:12,258 - text_topic_extraction.text_topic_processor - INFO - Performing topic modeling on concepts from 800 patients\n",
      "2025-03-13 16:01:12,284 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps\n",
      "2025-03-13 16:01:12,284 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m topics = \u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_perform_topic_modeling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatient_concepts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatient_concepts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtopic_modeler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtopic_modeler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/text_topic_extraction/text_topic_extraction/text_topic_processor.py:727\u001b[39m, in \u001b[36mTextTopicProcessor._perform_topic_modeling\u001b[39m\u001b[34m(self, patient_concepts, topic_modeler)\u001b[39m\n\u001b[32m    724\u001b[39m patient_concepts_list = \u001b[38;5;28mlist\u001b[39m(patient_concepts.values())\n\u001b[32m    726\u001b[39m \u001b[38;5;66;03m# Fit the topic model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m topics = \u001b[43mtopic_modeler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatient_concepts_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    729\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(topics)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m topics\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m topics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/text_topic_extraction/text_topic_extraction/topic_modeler/bertopic_modeler.py:121\u001b[39m, in \u001b[36mBERTopicModeler.fit_transform\u001b[39m\u001b[34m(self, patient_concepts_list)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[32m    120\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFitting BERTopic model on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(descriptors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m concepts\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m topics, probs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescriptors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTopics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopics\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Convert BERTopic topics to our Topic format\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/venv/lib/python3.11/site-packages/bertopic/_bertopic.py:431\u001b[39m, in \u001b[36mBERTopic.fit_transform\u001b[39m\u001b[34m(self, documents, embeddings, images, y)\u001b[39m\n\u001b[32m    429\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mEmbedding - Transforming documents to embeddings.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    430\u001b[39m     \u001b[38;5;28mself\u001b[39m.embedding_model = select_backend(\u001b[38;5;28mself\u001b[39m.embedding_model, language=\u001b[38;5;28mself\u001b[39m.language, verbose=\u001b[38;5;28mself\u001b[39m.verbose)\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDocument\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocument\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mEmbedding - Completed \u001b[39m\u001b[38;5;130;01m\\u2713\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/venv/lib/python3.11/site-packages/bertopic/_bertopic.py:3677\u001b[39m, in \u001b[36mBERTopic._extract_embeddings\u001b[39m\u001b[34m(self, documents, images, method, verbose)\u001b[39m\n\u001b[32m   3675\u001b[39m     embeddings = \u001b[38;5;28mself\u001b[39m.embedding_model.embed_words(words=documents, verbose=verbose)\n\u001b[32m   3676\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mdocument\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3677\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3678\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m documents[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3679\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3680\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMake sure to use an embedding model that can either embed documents\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor images depending on which you want to embed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3682\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/venv/lib/python3.11/site-packages/bertopic/backend/_base.py:62\u001b[39m, in \u001b[36mBaseEmbedder.embed_documents\u001b[39m\u001b[34m(self, document, verbose)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, document: List[\u001b[38;5;28mstr\u001b[39m], verbose: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> np.ndarray:\n\u001b[32m     51\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Embed a list of n words into an n-dimensional\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m    matrix of embeddings.\u001b[39;00m\n\u001b[32m     53\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m \u001b[33;03m        that each have an embeddings size of `m`\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/venv/lib/python3.11/site-packages/bertopic/backend/_sentencetransformers.py:65\u001b[39m, in \u001b[36mSentenceTransformerBackend.embed\u001b[39m\u001b[34m(self, documents, verbose)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(\u001b[38;5;28mself\u001b[39m, documents: List[\u001b[38;5;28mstr\u001b[39m], verbose: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> np.ndarray:\n\u001b[32m     54\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Embed a list of n documents/words into an n-dimensional\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m    matrix of embeddings.\u001b[39;00m\n\u001b[32m     56\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     63\u001b[39m \u001b[33;03m        that each have an embeddings size of `m`\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:591\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[39m\n\u001b[32m    589\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc=\u001b[33m\"\u001b[39m\u001b[33mBatches\u001b[39m\u001b[33m\"\u001b[39m, disable=\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[32m    590\u001b[39m     sentences_batch = sentences_sorted[start_index : start_index + batch_size]\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m     features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    592\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    593\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1056\u001b[39m, in \u001b[36mSentenceTransformer.tokenize\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[32m   1046\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1047\u001b[39m \u001b[33;03m    Tokenizes the texts.\u001b[39;00m\n\u001b[32m   1048\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1054\u001b[39m \u001b[33;03m            \"attention_mask\", and \"token_type_ids\".\u001b[39;00m\n\u001b[32m   1055\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_first_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/venv/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:505\u001b[39m, in \u001b[36mTransformer.tokenize\u001b[39m\u001b[34m(self, texts, padding)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_lower_case:\n\u001b[32m    503\u001b[39m     to_tokenize = [[s.lower() \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m to_tokenize]\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m \u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43mto_tokenize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlongest_first\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:298\u001b[39m, in \u001b[36mBatchEncoding.keys\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencodings\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n\u001b[32m    296\u001b[39m         \u001b[38;5;28mself\u001b[39m._encodings = state[\u001b[33m\"\u001b[39m\u001b[33mencodings\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mkeys\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data.keys()\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "topics = processor._perform_topic_modeling(\n",
    "    patient_concepts=patient_concepts,\n",
    "    topic_modeler=topic_modeler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 15:03:47,644 - text_topic_extraction.text_topic_processor - INFO - Generating questions for 200 topics\n",
      "2025-03-13 15:04:14,368 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:04:14,402 - text_topic_extraction.cache.cache_manager - INFO - Stored response in cache with key cb2a80c8fe...\n",
      "2025-03-13 15:04:14,403 - text_topic_extraction.text_topic_processor - INFO - Generated 200 questions\n",
      "2025-03-13 15:04:14,404 - text_topic_extraction.text_topic_processor - INFO - Question for topic 0: Is the patient an elderly senior adult?\n",
      "2025-03-13 15:04:14,404 - text_topic_extraction.text_topic_processor - INFO - Question for topic 1: Is the patient a nonsmoker?\n",
      "2025-03-13 15:04:14,404 - text_topic_extraction.text_topic_processor - INFO - Question for topic 2: Is the patient a woman?\n",
      "2025-03-13 15:04:14,404 - text_topic_extraction.text_topic_processor - INFO - Question for topic 3: Has the patient been hospitalized?\n",
      "2025-03-13 15:04:14,404 - text_topic_extraction.text_topic_processor - INFO - Question for topic 4: Is the patient consuming alcohol?\n",
      "2025-03-13 15:04:14,405 - text_topic_extraction.text_topic_processor - INFO - Question for topic 5: Does the patient have heart failure?\n",
      "2025-03-13 15:04:14,405 - text_topic_extraction.text_topic_processor - INFO - Question for topic 6: Is the patient experiencing shortness of breath?\n",
      "2025-03-13 15:04:14,405 - text_topic_extraction.text_topic_processor - INFO - Question for topic 7: Does the patient have a documented social history?\n",
      "2025-03-13 15:04:14,405 - text_topic_extraction.text_topic_processor - INFO - Question for topic 8: Does the patient have hypertension?\n",
      "2025-03-13 15:04:14,405 - text_topic_extraction.text_topic_processor - INFO - Question for topic 9: Is there a medical record available for the patient?\n",
      "2025-03-13 15:04:14,405 - text_topic_extraction.text_topic_processor - INFO - Question for topic 10: Is the patient experiencing muscle pain?\n",
      "2025-03-13 15:04:14,405 - text_topic_extraction.text_topic_processor - INFO - Question for topic 11: Is the patient in the emergency department?\n",
      "2025-03-13 15:04:14,405 - text_topic_extraction.text_topic_processor - INFO - Question for topic 12: Is the patient drug-free?\n",
      "2025-03-13 15:04:14,406 - text_topic_extraction.text_topic_processor - INFO - Question for topic 13: Does the patient have a daughter?\n",
      "2025-03-13 15:04:14,406 - text_topic_extraction.text_topic_processor - INFO - Question for topic 14: Is the patient married?\n",
      "2025-03-13 15:04:14,406 - text_topic_extraction.text_topic_processor - INFO - Question for topic 15: Is the patient a man?\n",
      "2025-03-13 15:04:14,406 - text_topic_extraction.text_topic_processor - INFO - Question for topic 16: Is the patient being treated with antibiotics for an infection?\n",
      "2025-03-13 15:04:14,406 - text_topic_extraction.text_topic_processor - INFO - Question for topic 17: Has the patient undergone surgery?\n",
      "2025-03-13 15:04:14,406 - text_topic_extraction.text_topic_processor - INFO - Question for topic 18: Does the patient have tachycardia?\n",
      "2025-03-13 15:04:14,406 - text_topic_extraction.text_topic_processor - INFO - Question for topic 19: Has the patient had a chest x-ray?\n",
      "2025-03-13 15:04:14,407 - text_topic_extraction.text_topic_processor - INFO - Question for topic 20: Is the patient struggling with substance addiction?\n",
      "2025-03-13 15:04:14,407 - text_topic_extraction.text_topic_processor - INFO - Question for topic 21: Does the patient have cancer?\n",
      "2025-03-13 15:04:14,407 - text_topic_extraction.text_topic_processor - INFO - Question for topic 22: Is the patient currently unemployed?\n",
      "2025-03-13 15:04:14,407 - text_topic_extraction.text_topic_processor - INFO - Question for topic 23: Does the patient have coronary artery disease?\n",
      "2025-03-13 15:04:14,407 - text_topic_extraction.text_topic_processor - INFO - Question for topic 24: Is there a treatment plan for the patient?\n",
      "2025-03-13 15:04:14,407 - text_topic_extraction.text_topic_processor - INFO - Question for topic 25: Does the patient have renal failure?\n",
      "2025-03-13 15:04:14,407 - text_topic_extraction.text_topic_processor - INFO - Question for topic 26: Does the patient have unhealthy lifestyle factors?\n",
      "2025-03-13 15:04:14,408 - text_topic_extraction.text_topic_processor - INFO - Question for topic 27: Does the patient have pneumonia?\n",
      "2025-03-13 15:04:14,408 - text_topic_extraction.text_topic_processor - INFO - Question for topic 28: Are there any symptoms present in the patient?\n",
      "2025-03-13 15:04:14,408 - text_topic_extraction.text_topic_processor - INFO - Question for topic 29: Does the patient have a chronic health condition?\n",
      "2025-03-13 15:04:14,408 - text_topic_extraction.text_topic_processor - INFO - Question for topic 30: Has the patient undergone an assessment?\n",
      "2025-03-13 15:04:14,408 - text_topic_extraction.text_topic_processor - INFO - Question for topic 31: Is the patient experiencing nausea?\n",
      "2025-03-13 15:04:14,408 - text_topic_extraction.text_topic_processor - INFO - Question for topic 32: Does the patient have diabetes mellitus?\n",
      "2025-03-13 15:04:14,408 - text_topic_extraction.text_topic_processor - INFO - Question for topic 33: Is the patient experiencing diarrhea?\n",
      "2025-03-13 15:04:14,408 - text_topic_extraction.text_topic_processor - INFO - Question for topic 34: Has the patient suffered a trauma?\n",
      "2025-03-13 15:04:14,408 - text_topic_extraction.text_topic_processor - INFO - Question for topic 35: Has the patient had an imaging study?\n",
      "2025-03-13 15:04:14,409 - text_topic_extraction.text_topic_processor - INFO - Question for topic 36: Is the patient being transferred to another facility?\n",
      "2025-03-13 15:04:14,409 - text_topic_extraction.text_topic_processor - INFO - Question for topic 37: Is the patient experiencing stomach upset?\n",
      "2025-03-13 15:04:14,409 - text_topic_extraction.text_topic_processor - INFO - Question for topic 38: Is the patient feeling fatigued?\n",
      "2025-03-13 15:04:14,409 - text_topic_extraction.text_topic_processor - INFO - Question for topic 39: Does the patient live alone?\n",
      "2025-03-13 15:04:14,409 - text_topic_extraction.text_topic_processor - INFO - Question for topic 40: Is the patient independent?\n",
      "2025-03-13 15:04:14,409 - text_topic_extraction.text_topic_processor - INFO - Question for topic 41: Does the patient have a support system?\n",
      "2025-03-13 15:04:14,409 - text_topic_extraction.text_topic_processor - INFO - Question for topic 42: Has the patient had a CT scan?\n",
      "2025-03-13 15:04:14,410 - text_topic_extraction.text_topic_processor - INFO - Question for topic 43: Has the patient been admitted to the hospital?\n",
      "2025-03-13 15:04:14,410 - text_topic_extraction.text_topic_processor - INFO - Question for topic 44: Is the patient experiencing dyspnea?\n",
      "2025-03-13 15:04:14,410 - text_topic_extraction.text_topic_processor - INFO - Question for topic 45: Does the patient have children?\n",
      "2025-03-13 15:04:14,410 - text_topic_extraction.text_topic_processor - INFO - Question for topic 46: Does the patient have hypotension?\n",
      "2025-03-13 15:04:14,410 - text_topic_extraction.text_topic_processor - INFO - Question for topic 47: Is the patient experiencing bleeding?\n",
      "2025-03-13 15:04:14,410 - text_topic_extraction.text_topic_processor - INFO - Question for topic 48: Does the patient have a urinary tract infection?\n",
      "2025-03-13 15:04:14,410 - text_topic_extraction.text_topic_processor - INFO - Question for topic 49: Is the patient receiving a blood transfusion?\n",
      "2025-03-13 15:04:14,410 - text_topic_extraction.text_topic_processor - INFO - Question for topic 50: Is the patient in an intensive care unit?\n",
      "2025-03-13 15:04:14,411 - text_topic_extraction.text_topic_processor - INFO - Question for topic 51: Is the patient receiving supplemental oxygen?\n",
      "2025-03-13 15:04:14,411 - text_topic_extraction.text_topic_processor - INFO - Question for topic 52: Does the patient have a fever?\n",
      "2025-03-13 15:04:14,411 - text_topic_extraction.text_topic_processor - INFO - Question for topic 53: Is the patient overweight?\n",
      "2025-03-13 15:04:14,411 - text_topic_extraction.text_topic_processor - INFO - Question for topic 54: Does the patient have vascular issues?\n",
      "2025-03-13 15:04:14,411 - text_topic_extraction.text_topic_processor - INFO - Question for topic 55: Is there fluid retention in the patient?\n",
      "2025-03-13 15:04:14,411 - text_topic_extraction.text_topic_processor - INFO - Question for topic 56: Is the patient experiencing altered mental status?\n",
      "2025-03-13 15:04:14,412 - text_topic_extraction.text_topic_processor - INFO - Question for topic 57: Is the patient experiencing weakness in the arm?\n",
      "2025-03-13 15:04:14,412 - text_topic_extraction.text_topic_processor - INFO - Question for topic 58: Is the patient coughing?\n",
      "2025-03-13 15:04:14,412 - text_topic_extraction.text_topic_processor - INFO - Question for topic 59: Is there swelling in the leg?\n",
      "2025-03-13 15:04:14,412 - text_topic_extraction.text_topic_processor - INFO - Question for topic 60: Is the patient consuming alcohol?\n",
      "2025-03-13 15:04:14,412 - text_topic_extraction.text_topic_processor - INFO - Question for topic 61: Is the patient cohabitating with someone?\n",
      "2025-03-13 15:04:14,413 - text_topic_extraction.text_topic_processor - INFO - Question for topic 62: Does the patient have neurological issues?\n",
      "2025-03-13 15:04:14,413 - text_topic_extraction.text_topic_processor - INFO - Question for topic 63: Is the patient in an assisted living situation?\n",
      "2025-03-13 15:04:14,413 - text_topic_extraction.text_topic_processor - INFO - Question for topic 64: Is the patient receiving palliative care?\n",
      "2025-03-13 15:04:14,413 - text_topic_extraction.text_topic_processor - INFO - Question for topic 65: Does the patient have an aortic aneurysm?\n",
      "2025-03-13 15:04:14,413 - text_topic_extraction.text_topic_processor - INFO - Question for topic 66: Does the patient have liver cirrhosis?\n",
      "2025-03-13 15:04:14,413 - text_topic_extraction.text_topic_processor - INFO - Question for topic 67: Is there a risk to the patient's safety?\n",
      "2025-03-13 15:04:14,414 - text_topic_extraction.text_topic_processor - INFO - Question for topic 68: Is the patient undergoing rehabilitation?\n",
      "2025-03-13 15:04:14,414 - text_topic_extraction.text_topic_processor - INFO - Question for topic 69: Is the patient receiving IV fluids?\n",
      "2025-03-13 15:04:14,414 - text_topic_extraction.text_topic_processor - INFO - Question for topic 70: Is the patient a diabetic?\n",
      "2025-03-13 15:04:14,414 - text_topic_extraction.text_topic_processor - INFO - Question for topic 71: Is the patient taking medication?\n",
      "2025-03-13 15:04:14,414 - text_topic_extraction.text_topic_processor - INFO - Question for topic 72: Is the patient's condition deteriorating?\n",
      "2025-03-13 15:04:14,415 - text_topic_extraction.text_topic_processor - INFO - Question for topic 73: Does the patient have a low hematocrit?\n",
      "2025-03-13 15:04:14,415 - text_topic_extraction.text_topic_processor - INFO - Question for topic 74: Has the patient undergone catheterization?\n",
      "2025-03-13 15:04:14,415 - text_topic_extraction.text_topic_processor - INFO - Question for topic 75: Is the patient abstinent from substances?\n",
      "2025-03-13 15:04:14,415 - text_topic_extraction.text_topic_processor - INFO - Question for topic 76: Is the patient's condition acute?\n",
      "2025-03-13 15:04:14,415 - text_topic_extraction.text_topic_processor - INFO - Question for topic 77: Does the patient have leukocytosis?\n",
      "2025-03-13 15:04:14,415 - text_topic_extraction.text_topic_processor - INFO - Question for topic 78: Is the patient experiencing agitation?\n",
      "2025-03-13 15:04:14,416 - text_topic_extraction.text_topic_processor - INFO - Question for topic 79: Is the patient hemodynamically stable?\n",
      "2025-03-13 15:04:14,416 - text_topic_extraction.text_topic_processor - INFO - Question for topic 80: Is the patient experiencing loose stools?\n",
      "2025-03-13 15:04:14,416 - text_topic_extraction.text_topic_processor - INFO - Question for topic 81: Does the patient have hypertension?\n",
      "2025-03-13 15:04:14,416 - text_topic_extraction.text_topic_processor - INFO - Question for topic 82: Are the patient's vital signs stable?\n",
      "2025-03-13 15:04:14,416 - text_topic_extraction.text_topic_processor - INFO - Question for topic 83: Has the patient had a stroke?\n",
      "2025-03-13 15:04:14,417 - text_topic_extraction.text_topic_processor - INFO - Question for topic 84: Is there demographic information available for the patient?\n",
      "2025-03-13 15:04:14,417 - text_topic_extraction.text_topic_processor - INFO - Question for topic 85: Is the patient exercising regularly?\n",
      "2025-03-13 15:04:14,417 - text_topic_extraction.text_topic_processor - INFO - Question for topic 86: Does the patient belong to a community with socioeconomic factors?\n",
      "2025-03-13 15:04:14,417 - text_topic_extraction.text_topic_processor - INFO - Question for topic 87: Is there a specific side affected in the patient?\n",
      "2025-03-13 15:04:14,417 - text_topic_extraction.text_topic_processor - INFO - Question for topic 88: Is the patient in an ICU?\n",
      "2025-03-13 15:04:14,417 - text_topic_extraction.text_topic_processor - INFO - Question for topic 89: Does the patient have atrial fibrillation?\n",
      "2025-03-13 15:04:14,418 - text_topic_extraction.text_topic_processor - INFO - Question for topic 90: Is the patient receiving opioid medication?\n",
      "2025-03-13 15:04:14,418 - text_topic_extraction.text_topic_processor - INFO - Question for topic 91: Is the patient experiencing chills?\n",
      "2025-03-13 15:04:14,418 - text_topic_extraction.text_topic_processor - INFO - Question for topic 92: Does the patient have CAD?\n",
      "2025-03-13 15:04:14,418 - text_topic_extraction.text_topic_processor - INFO - Question for topic 93: Does the patient have cognitive impairment?\n",
      "2025-03-13 15:04:14,418 - text_topic_extraction.text_topic_processor - INFO - Question for topic 94: Does the patient have high cholesterol?\n",
      "2025-03-13 15:04:14,419 - text_topic_extraction.text_topic_processor - INFO - Question for topic 95: Has the patient been intubated?\n",
      "2025-03-13 15:04:14,419 - text_topic_extraction.text_topic_processor - INFO - Question for topic 96: Is the patient part of a management team?\n",
      "2025-03-13 15:04:14,419 - text_topic_extraction.text_topic_processor - INFO - Question for topic 97: Is the patient's airway protected?\n",
      "2025-03-13 15:04:14,419 - text_topic_extraction.text_topic_processor - INFO - Question for topic 98: Is the patient in a partnership?\n",
      "2025-03-13 15:04:14,419 - text_topic_extraction.text_topic_processor - INFO - Question for topic 99: Has the patient undergone an organ transplant?\n",
      "2025-03-13 15:04:14,419 - text_topic_extraction.text_topic_processor - INFO - Question for topic 100: Does the patient have back pain?\n",
      "2025-03-13 15:04:14,420 - text_topic_extraction.text_topic_processor - INFO - Question for topic 101: Does the patient have a hip fracture?\n",
      "2025-03-13 15:04:14,420 - text_topic_extraction.text_topic_processor - INFO - Question for topic 102: Does the patient have prior conditions?\n",
      "2025-03-13 15:04:14,420 - text_topic_extraction.text_topic_processor - INFO - Question for topic 103: Are there lab results available for the patient?\n",
      "2025-03-13 15:04:14,420 - text_topic_extraction.text_topic_processor - INFO - Question for topic 104: Is the patient retired?\n",
      "2025-03-13 15:04:14,420 - text_topic_extraction.text_topic_processor - INFO - Question for topic 105: Has the patient had an EKG?\n",
      "2025-03-13 15:04:14,420 - text_topic_extraction.text_topic_processor - INFO - Question for topic 106: Is the patient a nondrinker?\n",
      "2025-03-13 15:04:14,421 - text_topic_extraction.text_topic_processor - INFO - Question for topic 107: Does the patient have a mitral valve issue?\n",
      "2025-03-13 15:04:14,421 - text_topic_extraction.text_topic_processor - INFO - Question for topic 108: Is the patient using a walking aid?\n",
      "2025-03-13 15:04:14,421 - text_topic_extraction.text_topic_processor - INFO - Question for topic 109: Is the patient experiencing headaches?\n",
      "2025-03-13 15:04:14,421 - text_topic_extraction.text_topic_processor - INFO - Question for topic 110: Is the patient traveling?\n",
      "2025-03-13 15:04:14,421 - text_topic_extraction.text_topic_processor - INFO - Question for topic 111: Does the patient have CHF?\n",
      "2025-03-13 15:04:14,422 - text_topic_extraction.text_topic_processor - INFO - Question for topic 112: Is the patient conscious?\n",
      "2025-03-13 15:04:14,422 - text_topic_extraction.text_topic_processor - INFO - Question for topic 113: Is the patient's temperature elevated?\n",
      "2025-03-13 15:04:14,422 - text_topic_extraction.text_topic_processor - INFO - Question for topic 114: Is the patient involved in education?\n",
      "2025-03-13 15:04:14,422 - text_topic_extraction.text_topic_processor - INFO - Question for topic 115: Is the patient on anticoagulants?\n",
      "2025-03-13 15:04:14,422 - text_topic_extraction.text_topic_processor - INFO - Question for topic 116: Does the patient have gastroesophageal reflux?\n",
      "2025-03-13 15:04:14,422 - text_topic_extraction.text_topic_processor - INFO - Question for topic 117: Does the patient have seizures?\n",
      "2025-03-13 15:04:14,422 - text_topic_extraction.text_topic_processor - INFO - Question for topic 118: Has the patient denied substance use?\n",
      "2025-03-13 15:04:14,422 - text_topic_extraction.text_topic_processor - INFO - Question for topic 119: Does the patient have a pleural effusion?\n",
      "2025-03-13 15:04:14,423 - text_topic_extraction.text_topic_processor - INFO - Question for topic 120: Is there a clinical note regarding the patient?\n",
      "2025-03-13 15:04:14,423 - text_topic_extraction.text_topic_processor - INFO - Question for topic 121: Is the patient experiencing coffee ground emesis?\n",
      "2025-03-13 15:04:14,423 - text_topic_extraction.text_topic_processor - INFO - Question for topic 122: Is the patient's appetite poor?\n",
      "2025-03-13 15:04:14,423 - text_topic_extraction.text_topic_processor - INFO - Question for topic 123: Has the patient had a stent placed?\n",
      "2025-03-13 15:04:14,423 - text_topic_extraction.text_topic_processor - INFO - Question for topic 124: Is the patient sweating excessively?\n",
      "2025-03-13 15:04:14,423 - text_topic_extraction.text_topic_processor - INFO - Question for topic 125: Is there a clinical report available for the patient?\n",
      "2025-03-13 15:04:14,423 - text_topic_extraction.text_topic_processor - INFO - Question for topic 126: Does the patient have COPD?\n",
      "2025-03-13 15:04:14,424 - text_topic_extraction.text_topic_processor - INFO - Question for topic 127: Is the patient experiencing clotting issues?\n",
      "2025-03-13 15:04:14,424 - text_topic_extraction.text_topic_processor - INFO - Question for topic 128: Is the patient receiving intravenous drugs?\n",
      "2025-03-13 15:04:14,424 - text_topic_extraction.text_topic_processor - INFO - Question for topic 129: Does the patient have gallbladder issues?\n",
      "2025-03-13 15:04:14,424 - text_topic_extraction.text_topic_processor - INFO - Question for topic 130: Does the patient require antiplatelet therapy?\n",
      "2025-03-13 15:04:14,424 - text_topic_extraction.text_topic_processor - INFO - Question for topic 131: Has the patient visited the ED?\n",
      "2025-03-13 15:04:14,425 - text_topic_extraction.text_topic_processor - INFO - Question for topic 132: Are there abnormal findings in the patient's reports?\n",
      "2025-03-13 15:04:14,425 - text_topic_extraction.text_topic_processor - INFO - Question for topic 133: Has the patient been referred to a specialist?\n",
      "2025-03-13 15:04:14,425 - text_topic_extraction.text_topic_processor - INFO - Question for topic 134: Is there a blockage in the patient's arteries?\n",
      "2025-03-13 15:04:14,425 - text_topic_extraction.text_topic_processor - INFO - Question for topic 135: Does the patient have a venous embolism?\n",
      "2025-03-13 15:04:14,425 - text_topic_extraction.text_topic_processor - INFO - Question for topic 136: Is the patient experiencing dysuria?\n",
      "2025-03-13 15:04:14,426 - text_topic_extraction.text_topic_processor - INFO - Question for topic 137: Does the patient have orthopnea?\n",
      "2025-03-13 15:04:14,426 - text_topic_extraction.text_topic_processor - INFO - Question for topic 138: Is the patient experiencing sensory numbness?\n",
      "2025-03-13 15:04:14,426 - text_topic_extraction.text_topic_processor - INFO - Question for topic 139: Is the patient on anticoagulant therapy?\n",
      "2025-03-13 15:04:14,426 - text_topic_extraction.text_topic_processor - INFO - Question for topic 140: Is the patient working longer hours?\n",
      "2025-03-13 15:04:14,426 - text_topic_extraction.text_topic_processor - INFO - Question for topic 141: Is the patient feeling queasy?\n",
      "2025-03-13 15:04:14,426 - text_topic_extraction.text_topic_processor - INFO - Question for topic 142: Has the patient had an ABG done?\n",
      "2025-03-13 15:04:14,427 - text_topic_extraction.text_topic_processor - INFO - Question for topic 143: Is the patient receiving tube feeding?\n",
      "2025-03-13 15:04:14,427 - text_topic_extraction.text_topic_processor - INFO - Question for topic 144: Is there personal background information available for the patient?\n",
      "2025-03-13 15:04:14,427 - text_topic_extraction.text_topic_processor - INFO - Question for topic 145: Is there a cessation of symptoms in the patient?\n",
      "2025-03-13 15:04:14,427 - text_topic_extraction.text_topic_processor - INFO - Question for topic 146: Does the patient have elevated creatinine levels?\n",
      "2025-03-13 15:04:14,427 - text_topic_extraction.text_topic_processor - INFO - Question for topic 147: Is the patient experiencing pain in the groin or knee?\n",
      "2025-03-13 15:04:14,428 - text_topic_extraction.text_topic_processor - INFO - Question for topic 148: Is the patient's condition sudden or intermittent?\n",
      "2025-03-13 15:04:14,428 - text_topic_extraction.text_topic_processor - INFO - Question for topic 149: Is the patient experiencing erythema?\n",
      "2025-03-13 15:04:14,428 - text_topic_extraction.text_topic_processor - INFO - Question for topic 150: Is the patient taking aspirin?\n",
      "2025-03-13 15:04:14,428 - text_topic_extraction.text_topic_processor - INFO - Question for topic 151: Does the patient have cephalalgia?\n",
      "2025-03-13 15:04:14,428 - text_topic_extraction.text_topic_processor - INFO - Question for topic 152: Is the patient on steroids?\n",
      "2025-03-13 15:04:14,428 - text_topic_extraction.text_topic_processor - INFO - Question for topic 153: Does the patient have vision issues?\n",
      "2025-03-13 15:04:14,428 - text_topic_extraction.text_topic_processor - INFO - Question for topic 154: Is there inflammation present in the patient?\n",
      "2025-03-13 15:04:14,429 - text_topic_extraction.text_topic_processor - INFO - Question for topic 155: Is the patient involved in legal matters?\n",
      "2025-03-13 15:04:14,429 - text_topic_extraction.text_topic_processor - INFO - Question for topic 156: Is the patient's speech slurred?\n",
      "2025-03-13 15:04:14,429 - text_topic_extraction.text_topic_processor - INFO - Question for topic 157: Is the patient smoking a pack a day?\n",
      "2025-03-13 15:04:14,429 - text_topic_extraction.text_topic_processor - INFO - Question for topic 158: Does the patient have elevated troponin levels?\n",
      "2025-03-13 15:04:14,429 - text_topic_extraction.text_topic_processor - INFO - Question for topic 159: Is the patient experiencing dizziness?\n",
      "2025-03-13 15:04:14,430 - text_topic_extraction.text_topic_processor - INFO - Question for topic 160: Does the patient have arthritis?\n",
      "2025-03-13 15:04:14,430 - text_topic_extraction.text_topic_processor - INFO - Question for topic 161: Is the patient's condition localized?\n",
      "2025-03-13 15:04:14,430 - text_topic_extraction.text_topic_processor - INFO - Question for topic 162: Is the procedure elective?\n",
      "2025-03-13 15:04:14,430 - text_topic_extraction.text_topic_processor - INFO - Question for topic 163: Is the patient Caucasian?\n",
      "2025-03-13 15:04:14,431 - text_topic_extraction.text_topic_processor - INFO - Question for topic 164: Does the patient have pancreatitis?\n",
      "2025-03-13 15:04:14,431 - text_topic_extraction.text_topic_processor - INFO - Question for topic 165: Is the patient experiencing stress?\n",
      "2025-03-13 15:04:14,431 - text_topic_extraction.text_topic_processor - INFO - Question for topic 166: Does the patient have a wound?\n",
      "2025-03-13 15:04:14,431 - text_topic_extraction.text_topic_processor - INFO - Question for topic 167: Does the patient have a myocardial infarction?\n",
      "2025-03-13 15:04:14,431 - text_topic_extraction.text_topic_processor - INFO - Question for topic 168: Is the patient having difficulty swallowing?\n",
      "2025-03-13 15:04:14,432 - text_topic_extraction.text_topic_processor - INFO - Question for topic 169: Is the patient afebrile?\n",
      "2025-03-13 15:04:14,432 - text_topic_extraction.text_topic_processor - INFO - Question for topic 170: Has the patient undergone bypass grafting?\n",
      "2025-03-13 15:04:14,432 - text_topic_extraction.text_topic_processor - INFO - Question for topic 171: Is there a lobectomy planned for the patient?\n",
      "2025-03-13 15:04:14,432 - text_topic_extraction.text_topic_processor - INFO - Question for topic 172: Is the patient experiencing rectal bleeding?\n",
      "2025-03-13 15:04:14,432 - text_topic_extraction.text_topic_processor - INFO - Question for topic 173: Does the patient have an ulcer?\n",
      "2025-03-13 15:04:14,433 - text_topic_extraction.text_topic_processor - INFO - Question for topic 174: Has the patient had a dental checkup?\n",
      "2025-03-13 15:04:14,433 - text_topic_extraction.text_topic_processor - INFO - Question for topic 175: Is the patient asymptomatic?\n",
      "2025-03-13 15:04:14,433 - text_topic_extraction.text_topic_processor - INFO - Question for topic 176: Is there a central line in place for the patient?\n",
      "2025-03-13 15:04:14,433 - text_topic_extraction.text_topic_processor - INFO - Question for topic 177: Has the patient undergone an amputation?\n",
      "2025-03-13 15:04:14,433 - text_topic_extraction.text_topic_processor - INFO - Question for topic 178: Is the patient's ejection fraction normal?\n",
      "2025-03-13 15:04:14,434 - text_topic_extraction.text_topic_processor - INFO - Question for topic 179: Is the patient malnourished?\n",
      "2025-03-13 15:04:14,434 - text_topic_extraction.text_topic_processor - INFO - Question for topic 180: Is the patient a smoker?\n",
      "2025-03-13 15:04:14,434 - text_topic_extraction.text_topic_processor - INFO - Question for topic 181: Are the patient's potassium and sodium levels normal?\n",
      "2025-03-13 15:04:14,434 - text_topic_extraction.text_topic_processor - INFO - Question for topic 182: Is the patient under monitoring?\n",
      "2025-03-13 15:04:14,434 - text_topic_extraction.text_topic_processor - INFO - Question for topic 183: Is the patient dehydrated?\n",
      "2025-03-13 15:04:14,434 - text_topic_extraction.text_topic_processor - INFO - Question for topic 184: Is the patient confused?\n",
      "2025-03-13 15:04:14,434 - text_topic_extraction.text_topic_processor - INFO - Question for topic 185: Has the patient experienced a fall?\n",
      "2025-03-13 15:04:14,435 - text_topic_extraction.text_topic_processor - INFO - Question for topic 186: Is the patient receiving metronidazole?\n",
      "2025-03-13 15:04:14,435 - text_topic_extraction.text_topic_processor - INFO - Question for topic 187: Are there observations recorded for the patient?\n",
      "2025-03-13 15:04:14,435 - text_topic_extraction.text_topic_processor - INFO - Question for topic 188: Does the patient have PE?\n",
      "2025-03-13 15:04:14,435 - text_topic_extraction.text_topic_processor - INFO - Question for topic 189: Is there domestic conflict in the patient's life?\n",
      "2025-03-13 15:04:14,435 - text_topic_extraction.text_topic_processor - INFO - Question for topic 190: Is the patient receiving vancomycin?\n",
      "2025-03-13 15:04:14,435 - text_topic_extraction.text_topic_processor - INFO - Question for topic 191: Has the patient had an echocardiogram?\n",
      "2025-03-13 15:04:14,435 - text_topic_extraction.text_topic_processor - INFO - Question for topic 192: Has the patient undergone a tracheostomy?\n",
      "2025-03-13 15:04:14,436 - text_topic_extraction.text_topic_processor - INFO - Question for topic 193: Is the guaiac test positive for the patient?\n",
      "2025-03-13 15:04:14,436 - text_topic_extraction.text_topic_processor - INFO - Question for topic 194: Does the patient have vague complaints?\n",
      "2025-03-13 15:04:14,436 - text_topic_extraction.text_topic_processor - INFO - Question for topic 195: Does the patient have metabolic acidosis?\n",
      "2025-03-13 15:04:14,436 - text_topic_extraction.text_topic_processor - INFO - Question for topic 196: Is the patient using nitroglycerin?\n",
      "2025-03-13 15:04:14,437 - text_topic_extraction.text_topic_processor - INFO - Question for topic 197: Is the patient nonverbal?\n",
      "2025-03-13 15:04:14,437 - text_topic_extraction.text_topic_processor - INFO - Question for topic 198: Is the patient receiving norepinephrine?\n",
      "2025-03-13 15:04:14,437 - text_topic_extraction.text_topic_processor - INFO - Question for topic 199: Is there demographic data available for the patient?\n",
      "2025-03-13 15:04:14,437 - text_topic_extraction.text_topic_processor - INFO - Generating questions for 199 topics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic question ex: topic_id=0 topic_name='elderly senior adult' question='Is the patient an elderly senior adult?' keywords=['elderly', 'senior', 'adult', 'middleaged', 'yo', 'years', 'old', 'age', 'young', 'older'] keyword_scores=[0.05966476998871776, 0.059362585114674474, 0.050684648743146696, 0.041141828700968594, 0.04084985157403527, 0.0373779493951345, 0.03722355930087635, 0.03665847953079638, 0.03298190066395977, 0.027227526765457755]\n",
      "num topics 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 15:04:44,475 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:04:44,519 - text_topic_extraction.cache.cache_manager - INFO - Stored response in cache with key f84484bb77...\n",
      "2025-03-13 15:04:44,521 - text_topic_extraction.text_topic_processor - INFO - Generated 199 questions\n",
      "2025-03-13 15:04:44,521 - text_topic_extraction.text_topic_processor - INFO - Question for topic 200: Is resuscitation being performed?\n",
      "2025-03-13 15:04:44,521 - text_topic_extraction.text_topic_processor - INFO - Question for topic 201: Is there adequate blood flow in the circulatory system?\n",
      "2025-03-13 15:04:44,521 - text_topic_extraction.text_topic_processor - INFO - Question for topic 202: Is radiation therapy being administered?\n",
      "2025-03-13 15:04:44,522 - text_topic_extraction.text_topic_processor - INFO - Question for topic 203: Is Lasix (furosemide) being given to the patient?\n",
      "2025-03-13 15:04:44,522 - text_topic_extraction.text_topic_processor - INFO - Question for topic 204: Is the patient experiencing anemia?\n",
      "2025-03-13 15:04:44,522 - text_topic_extraction.text_topic_processor - INFO - Question for topic 205: Is there a lesion located in the pelvic area?\n",
      "2025-03-13 15:04:44,522 - text_topic_extraction.text_topic_processor - INFO - Question for topic 206: Is the patient experiencing lightheadedness?\n",
      "2025-03-13 15:04:44,522 - text_topic_extraction.text_topic_processor - INFO - Question for topic 207: Is the patient's state considered normal?\n",
      "2025-03-13 15:04:44,523 - text_topic_extraction.text_topic_processor - INFO - Question for topic 208: Is the patient diagnosed with NSTEMI?\n",
      "2025-03-13 15:04:44,523 - text_topic_extraction.text_topic_processor - INFO - Question for topic 209: Has the patient undergone CABG surgery?\n",
      "2025-03-13 15:04:44,523 - text_topic_extraction.text_topic_processor - INFO - Question for topic 210: Is a vasopressor being used for treatment?\n",
      "2025-03-13 15:04:44,523 - text_topic_extraction.text_topic_processor - INFO - Question for topic 211: Did the onset of symptoms occur suddenly?\n",
      "2025-03-13 15:04:44,523 - text_topic_extraction.text_topic_processor - INFO - Question for topic 212: Is there evidence of melena?\n",
      "2025-03-13 15:04:44,523 - text_topic_extraction.text_topic_processor - INFO - Question for topic 213: Is the patient lethargic?\n",
      "2025-03-13 15:04:44,524 - text_topic_extraction.text_topic_processor - INFO - Question for topic 214: Does the chest X-ray show any proximal findings?\n",
      "2025-03-13 15:04:44,524 - text_topic_extraction.text_topic_processor - INFO - Question for topic 215: Is there evidence of abnormal growth or enlargement?\n",
      "2025-03-13 15:04:44,524 - text_topic_extraction.text_topic_processor - INFO - Question for topic 216: Has an ultrasound of the right upper quadrant been performed?\n",
      "2025-03-13 15:04:44,524 - text_topic_extraction.text_topic_processor - INFO - Question for topic 217: Is the patient experiencing mucus production and bloating?\n",
      "2025-03-13 15:04:44,524 - text_topic_extraction.text_topic_processor - INFO - Question for topic 218: Is the patient diaphoretic?\n",
      "2025-03-13 15:04:44,525 - text_topic_extraction.text_topic_processor - INFO - Question for topic 219: Is the patient unresponsive?\n",
      "2025-03-13 15:04:44,525 - text_topic_extraction.text_topic_processor - INFO - Question for topic 220: Is the patient responsive and mobile?\n",
      "2025-03-13 15:04:44,525 - text_topic_extraction.text_topic_processor - INFO - Question for topic 221: Is there mitral or tricuspid regurgitation present?\n",
      "2025-03-13 15:04:44,525 - text_topic_extraction.text_topic_processor - INFO - Question for topic 222: Is there sputum production noted?\n",
      "2025-03-13 15:04:44,525 - text_topic_extraction.text_topic_processor - INFO - Question for topic 223: Was CPR initiated for the patient?\n",
      "2025-03-13 15:04:44,526 - text_topic_extraction.text_topic_processor - INFO - Question for topic 224: Is the patient sedentary or ambulatory?\n",
      "2025-03-13 15:04:44,526 - text_topic_extraction.text_topic_processor - INFO - Question for topic 225: Is Dilantin (phenytoin) being administered?\n",
      "2025-03-13 15:04:44,526 - text_topic_extraction.text_topic_processor - INFO - Question for topic 226: Is there evidence of stage progression in the disease?\n",
      "2025-03-13 15:04:44,526 - text_topic_extraction.text_topic_processor - INFO - Question for topic 227: Is the patient single?\n",
      "2025-03-13 15:04:44,526 - text_topic_extraction.text_topic_processor - INFO - Question for topic 228: Is a consultation appointment scheduled?\n",
      "2025-03-13 15:04:44,526 - text_topic_extraction.text_topic_processor - INFO - Question for topic 229: Is the patient's condition worsening?\n",
      "2025-03-13 15:04:44,527 - text_topic_extraction.text_topic_processor - INFO - Question for topic 230: Is the patient on BiPAP?\n",
      "2025-03-13 15:04:44,527 - text_topic_extraction.text_topic_processor - INFO - Question for topic 231: Is Levofloxacin being prescribed?\n",
      "2025-03-13 15:04:44,527 - text_topic_extraction.text_topic_processor - INFO - Question for topic 232: Is there an absence of symptoms?\n",
      "2025-03-13 15:04:44,527 - text_topic_extraction.text_topic_processor - INFO - Question for topic 233: Is sedation being used for the patient?\n",
      "2025-03-13 15:04:44,527 - text_topic_extraction.text_topic_processor - INFO - Question for topic 234: Has an endoscopy or colonoscopy been performed?\n",
      "2025-03-13 15:04:44,527 - text_topic_extraction.text_topic_processor - INFO - Question for topic 235: Is there a history of myocardial infarction in Massachusetts?\n",
      "2025-03-13 15:04:44,527 - text_topic_extraction.text_topic_processor - INFO - Question for topic 236: Does the patient have a disability?\n",
      "2025-03-13 15:04:44,528 - text_topic_extraction.text_topic_processor - INFO - Question for topic 237: Is the AI system considered autonomous?\n",
      "2025-03-13 15:04:44,528 - text_topic_extraction.text_topic_processor - INFO - Question for topic 238: Has the patient been moved or relocated?\n",
      "2025-03-13 15:04:44,528 - text_topic_extraction.text_topic_processor - INFO - Question for topic 239: Is the patient considered self-sufficient?\n",
      "2025-03-13 15:04:44,528 - text_topic_extraction.text_topic_processor - INFO - Question for topic 240: Is the patient experiencing fainting spells?\n",
      "2025-03-13 15:04:44,528 - text_topic_extraction.text_topic_processor - INFO - Question for topic 241: Is the patient inactive but comfortable?\n",
      "2025-03-13 15:04:44,528 - text_topic_extraction.text_topic_processor - INFO - Question for topic 242: Is there a follow-up appointment scheduled?\n",
      "2025-03-13 15:04:44,528 - text_topic_extraction.text_topic_processor - INFO - Question for topic 243: Is the HCT level being monitored?\n",
      "2025-03-13 15:04:44,529 - text_topic_extraction.text_topic_processor - INFO - Question for topic 244: Does the patient have hyperlipidemia?\n",
      "2025-03-13 15:04:44,529 - text_topic_extraction.text_topic_processor - INFO - Question for topic 245: Is the patient an individual with personal information?\n",
      "2025-03-13 15:04:44,529 - text_topic_extraction.text_topic_processor - INFO - Question for topic 246: Is the driver a mechanic?\n",
      "2025-03-13 15:04:44,529 - text_topic_extraction.text_topic_processor - INFO - Question for topic 247: Is aspiration of ascites being considered?\n",
      "2025-03-13 15:04:44,529 - text_topic_extraction.text_topic_processor - INFO - Question for topic 248: Is the environment suitable for a landscaper or homemaker?\n",
      "2025-03-13 15:04:44,530 - text_topic_extraction.text_topic_processor - INFO - Question for topic 249: Is there a solid mass present?\n",
      "2025-03-13 15:04:44,530 - text_topic_extraction.text_topic_processor - INFO - Question for topic 250: Are there any issues with the arms or legs?\n",
      "2025-03-13 15:04:44,530 - text_topic_extraction.text_topic_processor - INFO - Question for topic 251: Has the patient experienced a cerebrovascular accident?\n",
      "2025-03-13 15:04:44,530 - text_topic_extraction.text_topic_processor - INFO - Question for topic 252: Is there evidence of dysarthria or dysphagia?\n",
      "2025-03-13 15:04:44,531 - text_topic_extraction.text_topic_processor - INFO - Question for topic 253: Is the consumption of a certain quantity being monitored?\n",
      "2025-03-13 15:04:44,531 - text_topic_extraction.text_topic_processor - INFO - Question for topic 254: Is there paralysis affecting the spinal area?\n",
      "2025-03-13 15:04:44,531 - text_topic_extraction.text_topic_processor - INFO - Question for topic 255: Is an operation being performed?\n",
      "2025-03-13 15:04:44,531 - text_topic_extraction.text_topic_processor - INFO - Question for topic 256: Are enzyme levels being monitored in the liver?\n",
      "2025-03-13 15:04:44,531 - text_topic_extraction.text_topic_processor - INFO - Question for topic 257: Is there an improvement in the patient's condition?\n",
      "2025-03-13 15:04:44,531 - text_topic_extraction.text_topic_processor - INFO - Question for topic 258: Is the hepatitis C virus inactive?\n",
      "2025-03-13 15:04:44,532 - text_topic_extraction.text_topic_processor - INFO - Question for topic 259: Is the ejection fraction reduced?\n",
      "2025-03-13 15:04:44,532 - text_topic_extraction.text_topic_processor - INFO - Question for topic 260: Is the patient experiencing self-harm or suicidal thoughts?\n",
      "2025-03-13 15:04:44,532 - text_topic_extraction.text_topic_processor - INFO - Question for topic 261: Is the patient HIV positive?\n",
      "2025-03-13 15:04:44,532 - text_topic_extraction.text_topic_processor - INFO - Question for topic 262: Is the patient undergoing treatment for ESRD?\n",
      "2025-03-13 15:04:44,532 - text_topic_extraction.text_topic_processor - INFO - Question for topic 263: Are physiological metrics being measured?\n",
      "2025-03-13 15:04:44,533 - text_topic_extraction.text_topic_processor - INFO - Question for topic 264: Are the measurements fitting the required size?\n",
      "2025-03-13 15:04:44,533 - text_topic_extraction.text_topic_processor - INFO - Question for topic 265: Are daily activities being performed?\n",
      "2025-03-13 15:04:44,533 - text_topic_extraction.text_topic_processor - INFO - Question for topic 266: Does the patient have diverticulosis or diverticulitis?\n",
      "2025-03-13 15:04:44,533 - text_topic_extraction.text_topic_processor - INFO - Question for topic 267: Is the patient in their 40s or 50s?\n",
      "2025-03-13 15:04:44,534 - text_topic_extraction.text_topic_processor - INFO - Question for topic 268: Is drainage being performed?\n",
      "2025-03-13 15:04:44,534 - text_topic_extraction.text_topic_processor - INFO - Question for topic 269: Is the condition critical?\n",
      "2025-03-13 15:04:44,534 - text_topic_extraction.text_topic_processor - INFO - Question for topic 270: Is there ischemia in the limb?\n",
      "2025-03-13 15:04:44,534 - text_topic_extraction.text_topic_processor - INFO - Question for topic 271: Is the patient alert?\n",
      "2025-03-13 15:04:44,534 - text_topic_extraction.text_topic_processor - INFO - Question for topic 272: Is the system vulnerable to attacks?\n",
      "2025-03-13 15:04:44,535 - text_topic_extraction.text_topic_processor - INFO - Question for topic 273: Is there a comparison being made?\n",
      "2025-03-13 15:04:44,535 - text_topic_extraction.text_topic_processor - INFO - Question for topic 274: Is a pacemaker being placed?\n",
      "2025-03-13 15:04:44,535 - text_topic_extraction.text_topic_processor - INFO - Question for topic 275: Is there a history of PMH?\n",
      "2025-03-13 15:04:44,535 - text_topic_extraction.text_topic_processor - INFO - Question for topic 276: Is Ciprofloxacin being prescribed?\n",
      "2025-03-13 15:04:44,536 - text_topic_extraction.text_topic_processor - INFO - Question for topic 277: Are baseline measurements being taken?\n",
      "2025-03-13 15:04:44,536 - text_topic_extraction.text_topic_processor - INFO - Question for topic 278: Is there a diagnosis of hypothyroidism?\n",
      "2025-03-13 15:04:44,536 - text_topic_extraction.text_topic_processor - INFO - Question for topic 279: Has the patient experienced syncope?\n",
      "2025-03-13 15:04:44,536 - text_topic_extraction.text_topic_processor - INFO - Question for topic 280: Is the patient experiencing longstanding issues?\n",
      "2025-03-13 15:04:44,536 - text_topic_extraction.text_topic_processor - INFO - Question for topic 281: Is the duration of symptoms short?\n",
      "2025-03-13 15:04:44,537 - text_topic_extraction.text_topic_processor - INFO - Question for topic 282: Is there an analysis of arterial gases?\n",
      "2025-03-13 15:04:44,537 - text_topic_extraction.text_topic_processor - INFO - Question for topic 283: Is there malaise present?\n",
      "2025-03-13 15:04:44,537 - text_topic_extraction.text_topic_processor - INFO - Question for topic 284: Is the patient in the ER?\n",
      "2025-03-13 15:04:44,537 - text_topic_extraction.text_topic_processor - INFO - Question for topic 285: Is lactate level elevated?\n",
      "2025-03-13 15:04:44,537 - text_topic_extraction.text_topic_processor - INFO - Question for topic 286: Are CK levels being monitored?\n",
      "2025-03-13 15:04:44,537 - text_topic_extraction.text_topic_processor - INFO - Question for topic 287: Are gastrointestinal symptoms present?\n",
      "2025-03-13 15:04:44,538 - text_topic_extraction.text_topic_processor - INFO - Question for topic 288: Are palpitations intermittent?\n",
      "2025-03-13 15:04:44,538 - text_topic_extraction.text_topic_processor - INFO - Question for topic 289: Is the screening test positive?\n",
      "2025-03-13 15:04:44,538 - text_topic_extraction.text_topic_processor - INFO - Question for topic 290: Is there a CVA in the VP territory?\n",
      "2025-03-13 15:04:44,538 - text_topic_extraction.text_topic_processor - INFO - Question for topic 291: Is the patient on blood thinners?\n",
      "2025-03-13 15:04:44,538 - text_topic_extraction.text_topic_processor - INFO - Question for topic 292: Is there a decline in cognitive function?\n",
      "2025-03-13 15:04:44,538 - text_topic_extraction.text_topic_processor - INFO - Question for topic 293: Is the patient's condition unremarkable?\n",
      "2025-03-13 15:04:44,539 - text_topic_extraction.text_topic_processor - INFO - Question for topic 294: Is there evidence of pyrexia?\n",
      "2025-03-13 15:04:44,539 - text_topic_extraction.text_topic_processor - INFO - Question for topic 295: Is there redness present?\n",
      "2025-03-13 15:04:44,539 - text_topic_extraction.text_topic_processor - INFO - Question for topic 296: Is there compliance with treatment?\n",
      "2025-03-13 15:04:44,539 - text_topic_extraction.text_topic_processor - INFO - Question for topic 297: Is there a barrier to communication?\n",
      "2025-03-13 15:04:44,539 - text_topic_extraction.text_topic_processor - INFO - Question for topic 298: Is the patient sedated?\n",
      "2025-03-13 15:04:44,540 - text_topic_extraction.text_topic_processor - INFO - Question for topic 299: Are there episodes of symptoms?\n",
      "2025-03-13 15:04:44,540 - text_topic_extraction.text_topic_processor - INFO - Question for topic 300: Is INR being monitored?\n",
      "2025-03-13 15:04:44,540 - text_topic_extraction.text_topic_processor - INFO - Question for topic 301: Is there a GI bleed present?\n",
      "2025-03-13 15:04:44,540 - text_topic_extraction.text_topic_processor - INFO - Question for topic 302: Is the patient a military veteran?\n",
      "2025-03-13 15:04:44,540 - text_topic_extraction.text_topic_processor - INFO - Question for topic 303: Is dopamine being administered via drip?\n",
      "2025-03-13 15:04:44,540 - text_topic_extraction.text_topic_processor - INFO - Question for topic 304: Is the business a retail store?\n",
      "2025-03-13 15:04:44,540 - text_topic_extraction.text_topic_processor - INFO - Question for topic 305: Is assistance being provided?\n",
      "2025-03-13 15:04:44,541 - text_topic_extraction.text_topic_processor - INFO - Question for topic 306: Is an EGD being performed?\n",
      "2025-03-13 15:04:44,541 - text_topic_extraction.text_topic_processor - INFO - Question for topic 307: Is the patient disoriented?\n",
      "2025-03-13 15:04:44,541 - text_topic_extraction.text_topic_processor - INFO - Question for topic 308: Is there an elevation in ST segment?\n",
      "2025-03-13 15:04:44,541 - text_topic_extraction.text_topic_processor - INFO - Question for topic 309: Is there light sensitivity present?\n",
      "2025-03-13 15:04:44,541 - text_topic_extraction.text_topic_processor - INFO - Question for topic 310: Is the patient being discharged?\n",
      "2025-03-13 15:04:44,541 - text_topic_extraction.text_topic_processor - INFO - Question for topic 311: Is the patient climbing a ladder?\n",
      "2025-03-13 15:04:44,542 - text_topic_extraction.text_topic_processor - INFO - Question for topic 312: Is TPN being administered?\n",
      "2025-03-13 15:04:44,542 - text_topic_extraction.text_topic_processor - INFO - Question for topic 313: Is there an occlusion of the mask?\n",
      "2025-03-13 15:04:44,542 - text_topic_extraction.text_topic_processor - INFO - Question for topic 314: Is the patient being airlifted?\n",
      "2025-03-13 15:04:44,542 - text_topic_extraction.text_topic_processor - INFO - Question for topic 315: Is normal saline being used?\n",
      "2025-03-13 15:04:44,542 - text_topic_extraction.text_topic_processor - INFO - Question for topic 316: Is there evidence of sepsis?\n",
      "2025-03-13 15:04:44,542 - text_topic_extraction.text_topic_processor - INFO - Question for topic 317: Is AAA present?\n",
      "2025-03-13 15:04:44,543 - text_topic_extraction.text_topic_processor - INFO - Question for topic 318: Are there gastric varices?\n",
      "2025-03-13 15:04:44,543 - text_topic_extraction.text_topic_processor - INFO - Question for topic 319: Is there facial droop present?\n",
      "2025-03-13 15:04:44,543 - text_topic_extraction.text_topic_processor - INFO - Question for topic 320: Is there a strep infection?\n",
      "2025-03-13 15:04:44,543 - text_topic_extraction.text_topic_processor - INFO - Question for topic 321: Is a biopsy being performed?\n",
      "2025-03-13 15:04:44,543 - text_topic_extraction.text_topic_processor - INFO - Question for topic 322: Is the individual a tradesman?\n",
      "2025-03-13 15:04:44,544 - text_topic_extraction.text_topic_processor - INFO - Question for topic 323: Is there contact information available?\n",
      "2025-03-13 15:04:44,544 - text_topic_extraction.text_topic_processor - INFO - Question for topic 324: Is there lymphadenopathy present?\n",
      "2025-03-13 15:04:44,544 - text_topic_extraction.text_topic_processor - INFO - Question for topic 325: Is there a locational issue?\n",
      "2025-03-13 15:04:44,544 - text_topic_extraction.text_topic_processor - INFO - Question for topic 326: Is there an exacerbation of symptoms?\n",
      "2025-03-13 15:04:44,544 - text_topic_extraction.text_topic_processor - INFO - Question for topic 327: Is ASA being administered?\n",
      "2025-03-13 15:04:44,545 - text_topic_extraction.text_topic_processor - INFO - Question for topic 328: Is PNA being treated?\n",
      "2025-03-13 15:04:44,545 - text_topic_extraction.text_topic_processor - INFO - Question for topic 329: Is the patient involved in financial banking?\n",
      "2025-03-13 15:04:44,545 - text_topic_extraction.text_topic_processor - INFO - Question for topic 330: Is there a behavioral issue present?\n",
      "2025-03-13 15:04:44,545 - text_topic_extraction.text_topic_processor - INFO - Question for topic 331: Is there a subdural hematoma?\n",
      "2025-03-13 15:04:44,545 - text_topic_extraction.text_topic_processor - INFO - Question for topic 332: Is Zosyn being prescribed?\n",
      "2025-03-13 15:04:44,545 - text_topic_extraction.text_topic_processor - INFO - Question for topic 333: Is documentation being followed?\n",
      "2025-03-13 15:04:44,546 - text_topic_extraction.text_topic_processor - INFO - Question for topic 334: Is there pruritis present?\n",
      "2025-03-13 15:04:44,546 - text_topic_extraction.text_topic_processor - INFO - Question for topic 335: Is there a problem with the toe or foot?\n",
      "2025-03-13 15:04:44,546 - text_topic_extraction.text_topic_processor - INFO - Question for topic 336: Is the patient bereaved?\n",
      "2025-03-13 15:04:44,546 - text_topic_extraction.text_topic_processor - INFO - Question for topic 337: Is octreotide being administered?\n",
      "2025-03-13 15:04:44,547 - text_topic_extraction.text_topic_processor - INFO - Question for topic 338: Is the patient febrile?\n",
      "2025-03-13 15:04:44,547 - text_topic_extraction.text_topic_processor - INFO - Question for topic 339: Is Vanc being administered?\n",
      "2025-03-13 15:04:44,547 - text_topic_extraction.text_topic_processor - INFO - Question for topic 340: Is the patient a recent returnee?\n",
      "2025-03-13 15:04:44,547 - text_topic_extraction.text_topic_processor - INFO - Question for topic 341: Is there occupational exposure?\n",
      "2025-03-13 15:04:44,548 - text_topic_extraction.text_topic_processor - INFO - Question for topic 342: Is there evidence of BRBPR?\n",
      "2025-03-13 15:04:44,548 - text_topic_extraction.text_topic_processor - INFO - Question for topic 343: Is the patient somnolent?\n",
      "2025-03-13 15:04:44,548 - text_topic_extraction.text_topic_processor - INFO - Question for topic 344: Is there a genetic predisposition?\n",
      "2025-03-13 15:04:44,548 - text_topic_extraction.text_topic_processor - INFO - Question for topic 345: Is it nighttime?\n",
      "2025-03-13 15:04:44,548 - text_topic_extraction.text_topic_processor - INFO - Question for topic 346: Is there a diagnosis of OSA?\n",
      "2025-03-13 15:04:44,548 - text_topic_extraction.text_topic_processor - INFO - Question for topic 347: Is a balloon pump being used?\n",
      "2025-03-13 15:04:44,549 - text_topic_extraction.text_topic_processor - INFO - Question for topic 348: Is there a narrowing present?\n",
      "2025-03-13 15:04:44,549 - text_topic_extraction.text_topic_processor - INFO - Question for topic 349: Is the patient in sinus rhythm?\n",
      "2025-03-13 15:04:44,549 - text_topic_extraction.text_topic_processor - INFO - Question for topic 350: Is the patient in shock?\n",
      "2025-03-13 15:04:44,549 - text_topic_extraction.text_topic_processor - INFO - Question for topic 351: Is there a shift in the midline?\n",
      "2025-03-13 15:04:44,549 - text_topic_extraction.text_topic_processor - INFO - Question for topic 352: Is there evidence of GIB?\n",
      "2025-03-13 15:04:44,549 - text_topic_extraction.text_topic_processor - INFO - Question for topic 353: Is there a filter in the IVC?\n",
      "2025-03-13 15:04:44,550 - text_topic_extraction.text_topic_processor - INFO - Question for topic 354: Are there multiple comorbidities?\n",
      "2025-03-13 15:04:44,550 - text_topic_extraction.text_topic_processor - INFO - Question for topic 355: Are rigors present?\n",
      "2025-03-13 15:04:44,550 - text_topic_extraction.text_topic_processor - INFO - Question for topic 356: Are there T-waves present?\n",
      "2025-03-13 15:04:44,550 - text_topic_extraction.text_topic_processor - INFO - Question for topic 357: Is the patient oriented and upright?\n",
      "2025-03-13 15:04:44,550 - text_topic_extraction.text_topic_processor - INFO - Question for topic 358: Is there a diagnosis of SAH?\n",
      "2025-03-13 15:04:44,550 - text_topic_extraction.text_topic_processor - INFO - Question for topic 359: Is decompression being performed?\n",
      "2025-03-13 15:04:44,551 - text_topic_extraction.text_topic_processor - INFO - Question for topic 360: Is the review of systems negative?\n",
      "2025-03-13 15:04:44,551 - text_topic_extraction.text_topic_processor - INFO - Question for topic 361: Is there immobility present?\n",
      "2025-03-13 15:04:44,551 - text_topic_extraction.text_topic_processor - INFO - Question for topic 362: Was the patient found down?\n",
      "2025-03-13 15:04:44,551 - text_topic_extraction.text_topic_processor - INFO - Question for topic 363: Is there mild epigastric pain?\n",
      "2025-03-13 15:04:44,551 - text_topic_extraction.text_topic_processor - INFO - Question for topic 364: Is there a 3VD present?\n",
      "2025-03-13 15:04:44,551 - text_topic_extraction.text_topic_processor - INFO - Question for topic 365: Is there a wide bilateral excision?\n",
      "2025-03-13 15:04:44,551 - text_topic_extraction.text_topic_processor - INFO - Question for topic 366: Is the impact significant?\n",
      "2025-03-13 15:04:44,552 - text_topic_extraction.text_topic_processor - INFO - Question for topic 367: Is the patient's sex biological?\n",
      "2025-03-13 15:04:44,552 - text_topic_extraction.text_topic_processor - INFO - Question for topic 368: Is the patient in a postictal state?\n",
      "2025-03-13 15:04:44,552 - text_topic_extraction.text_topic_processor - INFO - Question for topic 369: Is BNP elevated?\n",
      "2025-03-13 15:04:44,552 - text_topic_extraction.text_topic_processor - INFO - Question for topic 370: Is assistance needed for ADLs?\n",
      "2025-03-13 15:04:44,552 - text_topic_extraction.text_topic_processor - INFO - Question for topic 371: Is there a healthcare proxy?\n",
      "2025-03-13 15:04:44,552 - text_topic_extraction.text_topic_processor - INFO - Question for topic 372: Is the patient celiac?\n",
      "2025-03-13 15:04:44,553 - text_topic_extraction.text_topic_processor - INFO - Question for topic 373: Is calcium gluconate being administered?\n",
      "2025-03-13 15:04:44,553 - text_topic_extraction.text_topic_processor - INFO - Question for topic 374: Are there physical limitations?\n",
      "2025-03-13 15:04:44,553 - text_topic_extraction.text_topic_processor - INFO - Question for topic 375: Is MRSA present?\n",
      "2025-03-13 15:04:44,553 - text_topic_extraction.text_topic_processor - INFO - Question for topic 376: Is Plavix being administered?\n",
      "2025-03-13 15:04:44,553 - text_topic_extraction.text_topic_processor - INFO - Question for topic 377: Is amylase elevated?\n",
      "2025-03-13 15:04:44,553 - text_topic_extraction.text_topic_processor - INFO - Question for topic 378: Is ammonia level increased?\n",
      "2025-03-13 15:04:44,554 - text_topic_extraction.text_topic_processor - INFO - Question for topic 379: Is the laundry clean?\n",
      "2025-03-13 15:04:44,554 - text_topic_extraction.text_topic_processor - INFO - Question for topic 380: Was there a collision involving a vehicle?\n",
      "2025-03-13 15:04:44,554 - text_topic_extraction.text_topic_processor - INFO - Question for topic 381: Is the patient a teetotaler?\n",
      "2025-03-13 15:04:44,554 - text_topic_extraction.text_topic_processor - INFO - Question for topic 382: Is coiling being performed?\n",
      "2025-03-13 15:04:44,554 - text_topic_extraction.text_topic_processor - INFO - Question for topic 383: Is there obstructive jaundice?\n",
      "2025-03-13 15:04:44,554 - text_topic_extraction.text_topic_processor - INFO - Question for topic 384: Is the patient in AFib or VFib?\n",
      "2025-03-13 15:04:44,555 - text_topic_extraction.text_topic_processor - INFO - Question for topic 385: Is the patient homeless?\n",
      "2025-03-13 15:04:44,555 - text_topic_extraction.text_topic_processor - INFO - Question for topic 386: Is there an extensive workup being done?\n",
      "2025-03-13 15:04:44,555 - text_topic_extraction.text_topic_processor - INFO - Question for topic 387: Is the patient self-reporting?\n",
      "2025-03-13 15:04:44,555 - text_topic_extraction.text_topic_processor - INFO - Question for topic 388: Is the patient a walker or hiker?\n",
      "2025-03-13 15:04:44,555 - text_topic_extraction.text_topic_processor - INFO - Question for topic 389: Is there a diagnosis of prostate hyperplasia?\n",
      "2025-03-13 15:04:44,556 - text_topic_extraction.text_topic_processor - INFO - Question for topic 390: Is debridement being performed?\n",
      "2025-03-13 15:04:44,556 - text_topic_extraction.text_topic_processor - INFO - Question for topic 391: Is there a diagnosis of leukemia?\n",
      "2025-03-13 15:04:44,556 - text_topic_extraction.text_topic_processor - INFO - Question for topic 392: Are reflexes present?\n",
      "2025-03-13 15:04:44,556 - text_topic_extraction.text_topic_processor - INFO - Question for topic 393: Is there an RCA issue?\n",
      "2025-03-13 15:04:44,556 - text_topic_extraction.text_topic_processor - INFO - Question for topic 394: Is tissue sampling being performed?\n",
      "2025-03-13 15:04:44,556 - text_topic_extraction.text_topic_processor - INFO - Question for topic 395: Is there a significant recent loss?\n",
      "2025-03-13 15:04:44,557 - text_topic_extraction.text_topic_processor - INFO - Question for topic 396: Is the tidal volume being monitored?\n",
      "2025-03-13 15:04:44,557 - text_topic_extraction.text_topic_processor - INFO - Question for topic 397: Are secretions thick?\n",
      "2025-03-13 15:04:44,557 - text_topic_extraction.text_topic_processor - INFO - Question for topic 398: Is dexamethasone being administered?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic question ex: topic_id=200 topic_name='resuscitation resuscitate do' question='Is resuscitation being performed?' keywords=['resuscitation', 'resuscitate', 'do', 'not', 'resuscitated', 'cardiopulmonary', 'fluid', 'revived', 'actively', 'field'] keyword_scores=[0.5854071466114107, 0.35405664936809095, 0.29724377308394734, 0.13744134982272763, 0.1322701848574556, 0.1322701848574556, 0.11937424860421932, 0.07735244051303433, 0.07735244051303433, 0.0661350924287278]\n",
      "num topics 199\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "all_topic_questions = []\n",
    "for i in range(0, len(topics), batch_size):\n",
    "    topic_batch = topics[i:i + batch_size]\n",
    "    topic_questions = processor._generate_questions(\n",
    "        topics=topic_batch,\n",
    "        question_generator=question_generator,\n",
    "    )\n",
    "    print(\"topic question ex:\", topic_questions[0])\n",
    "    print(\"num topics\", len(topic_questions))\n",
    "    all_topic_questions += topic_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 15:33:27,574 - text_topic_extraction.text_topic_processor - INFO - Generating answers for 400 patients and 399 questions\n",
      "2025-03-13 15:33:27,576 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2200\n",
      "2025-03-13 15:33:27,576 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2200 for 399 questions\n",
      "2025-03-13 15:33:27,577 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2200 asynchronously\n",
      "2025-03-13 15:33:27,578 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4627\n",
      "2025-03-13 15:33:27,578 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4627 for 399 questions\n",
      "2025-03-13 15:33:27,580 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4627 asynchronously\n",
      "2025-03-13 15:33:27,581 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3225\n",
      "2025-03-13 15:33:27,581 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3225 for 399 questions\n",
      "2025-03-13 15:33:27,581 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3225 asynchronously\n",
      "2025-03-13 15:33:27,582 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2828\n",
      "2025-03-13 15:33:27,582 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2828 for 399 questions\n",
      "2025-03-13 15:33:27,583 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2828 asynchronously\n",
      "2025-03-13 15:33:27,583 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3768\n",
      "2025-03-13 15:33:27,583 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3768 for 399 questions\n",
      "2025-03-13 15:33:27,584 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3768 asynchronously\n",
      "2025-03-13 15:33:27,584 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4446\n",
      "2025-03-13 15:33:27,584 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4446 for 399 questions\n",
      "2025-03-13 15:33:27,584 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4446 asynchronously\n",
      "2025-03-13 15:33:27,585 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2234\n",
      "2025-03-13 15:33:27,585 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2234 for 399 questions\n",
      "2025-03-13 15:33:27,586 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2234 asynchronously\n",
      "2025-03-13 15:33:27,587 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5454\n",
      "2025-03-13 15:33:27,597 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5454 for 399 questions\n",
      "2025-03-13 15:33:27,613 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5454 asynchronously\n",
      "2025-03-13 15:33:27,614 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1278\n",
      "2025-03-13 15:33:27,614 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1278 for 399 questions\n",
      "2025-03-13 15:33:27,614 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1278 asynchronously\n",
      "2025-03-13 15:33:27,615 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 578\n",
      "2025-03-13 15:33:27,615 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 578 for 399 questions\n",
      "2025-03-13 15:33:27,615 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 578 asynchronously\n",
      "2025-03-13 15:33:27,616 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5960\n",
      "2025-03-13 15:33:27,616 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5960 for 399 questions\n",
      "2025-03-13 15:33:27,617 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5960 asynchronously\n",
      "2025-03-13 15:33:27,617 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 521\n",
      "2025-03-13 15:33:27,618 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 521 for 399 questions\n",
      "2025-03-13 15:33:27,618 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 521 asynchronously\n",
      "2025-03-13 15:33:27,618 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 217\n",
      "2025-03-13 15:33:27,619 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 217 for 399 questions\n",
      "2025-03-13 15:33:27,620 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 217 asynchronously\n",
      "2025-03-13 15:33:27,624 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5716\n",
      "2025-03-13 15:33:27,624 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5716 for 399 questions\n",
      "2025-03-13 15:33:27,625 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5716 asynchronously\n",
      "2025-03-13 15:33:27,625 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 202\n",
      "2025-03-13 15:33:27,625 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 202 for 399 questions\n",
      "2025-03-13 15:33:27,626 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 202 asynchronously\n",
      "2025-03-13 15:33:27,626 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 134\n",
      "2025-03-13 15:33:27,626 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 134 for 399 questions\n",
      "2025-03-13 15:33:27,626 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 134 asynchronously\n",
      "2025-03-13 15:33:27,627 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 154\n",
      "2025-03-13 15:33:27,627 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 154 for 399 questions\n",
      "2025-03-13 15:33:27,627 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 154 asynchronously\n",
      "2025-03-13 15:33:27,628 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4486\n",
      "2025-03-13 15:33:27,628 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4486 for 399 questions\n",
      "2025-03-13 15:33:27,628 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4486 asynchronously\n",
      "2025-03-13 15:33:27,628 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3283\n",
      "2025-03-13 15:33:27,629 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3283 for 399 questions\n",
      "2025-03-13 15:33:27,629 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3283 asynchronously\n",
      "2025-03-13 15:33:27,629 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3731\n",
      "2025-03-13 15:33:27,630 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3731 for 399 questions\n",
      "2025-03-13 15:33:27,631 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3731 asynchronously\n",
      "2025-03-13 15:33:27,632 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2572\n",
      "2025-03-13 15:33:27,632 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2572 for 399 questions\n",
      "2025-03-13 15:33:27,632 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2572 asynchronously\n",
      "2025-03-13 15:33:27,633 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4296\n",
      "2025-03-13 15:33:27,633 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4296 for 399 questions\n",
      "2025-03-13 15:33:27,633 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4296 asynchronously\n",
      "2025-03-13 15:33:27,633 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2838\n",
      "2025-03-13 15:33:27,634 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2838 for 399 questions\n",
      "2025-03-13 15:33:27,634 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2838 asynchronously\n",
      "2025-03-13 15:33:27,634 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3711\n",
      "2025-03-13 15:33:27,634 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3711 for 399 questions\n",
      "2025-03-13 15:33:27,634 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3711 asynchronously\n",
      "2025-03-13 15:33:27,635 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2425\n",
      "2025-03-13 15:33:27,635 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2425 for 399 questions\n",
      "2025-03-13 15:33:27,635 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2425 asynchronously\n",
      "2025-03-13 15:33:27,636 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5721\n",
      "2025-03-13 15:33:27,636 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5721 for 399 questions\n",
      "2025-03-13 15:33:27,636 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5721 asynchronously\n",
      "2025-03-13 15:33:27,637 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6429\n",
      "2025-03-13 15:33:27,637 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6429 for 399 questions\n",
      "2025-03-13 15:33:27,637 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6429 asynchronously\n",
      "2025-03-13 15:33:27,638 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5458\n",
      "2025-03-13 15:33:27,638 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5458 for 399 questions\n",
      "2025-03-13 15:33:27,638 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5458 asynchronously\n",
      "2025-03-13 15:33:27,638 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5549\n",
      "2025-03-13 15:33:27,638 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5549 for 399 questions\n",
      "2025-03-13 15:33:27,639 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5549 asynchronously\n",
      "2025-03-13 15:33:27,639 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6258\n",
      "2025-03-13 15:33:27,639 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6258 for 399 questions\n",
      "2025-03-13 15:33:27,640 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6258 asynchronously\n",
      "2025-03-13 15:33:27,640 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4481\n",
      "2025-03-13 15:33:27,640 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4481 for 399 questions\n",
      "2025-03-13 15:33:27,640 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4481 asynchronously\n",
      "2025-03-13 15:33:27,641 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 779\n",
      "2025-03-13 15:33:27,641 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 779 for 399 questions\n",
      "2025-03-13 15:33:27,641 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 779 asynchronously\n",
      "2025-03-13 15:33:27,641 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4120\n",
      "2025-03-13 15:33:27,641 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4120 for 399 questions\n",
      "2025-03-13 15:33:27,642 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4120 asynchronously\n",
      "2025-03-13 15:33:27,642 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6533\n",
      "2025-03-13 15:33:27,642 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6533 for 399 questions\n",
      "2025-03-13 15:33:27,642 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6533 asynchronously\n",
      "2025-03-13 15:33:27,642 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4559\n",
      "2025-03-13 15:33:27,643 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4559 for 399 questions\n",
      "2025-03-13 15:33:27,643 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4559 asynchronously\n",
      "2025-03-13 15:33:27,643 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1564\n",
      "2025-03-13 15:33:27,643 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1564 for 399 questions\n",
      "2025-03-13 15:33:27,644 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1564 asynchronously\n",
      "2025-03-13 15:33:27,644 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 693\n",
      "2025-03-13 15:33:27,644 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 693 for 399 questions\n",
      "2025-03-13 15:33:27,645 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 693 asynchronously\n",
      "2025-03-13 15:33:27,645 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3028\n",
      "2025-03-13 15:33:27,645 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3028 for 399 questions\n",
      "2025-03-13 15:33:27,645 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3028 asynchronously\n",
      "2025-03-13 15:33:27,646 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4346\n",
      "2025-03-13 15:33:27,646 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4346 for 399 questions\n",
      "2025-03-13 15:33:27,647 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4346 asynchronously\n",
      "2025-03-13 15:33:27,648 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6556\n",
      "2025-03-13 15:33:27,648 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6556 for 399 questions\n",
      "2025-03-13 15:33:27,648 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6556 asynchronously\n",
      "2025-03-13 15:33:27,649 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 55077a27c0...)\n",
      "2025-03-13 15:33:27,650 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2200\n",
      "2025-03-13 15:33:27,650 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 12cd5095a5...)\n",
      "2025-03-13 15:33:27,651 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4627\n",
      "2025-03-13 15:33:27,651 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e1a20ec3d3...)\n",
      "2025-03-13 15:33:27,651 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3225\n",
      "2025-03-13 15:33:27,652 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7ee28cf0c4...)\n",
      "2025-03-13 15:33:27,652 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2828\n",
      "2025-03-13 15:33:27,653 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 3c82b067cd...)\n",
      "2025-03-13 15:33:27,654 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3768\n",
      "2025-03-13 15:33:27,654 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 526\n",
      "2025-03-13 15:33:27,654 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 526 for 399 questions\n",
      "2025-03-13 15:33:27,654 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 526 asynchronously\n",
      "2025-03-13 15:33:27,655 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 502\n",
      "2025-03-13 15:33:27,655 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 502 for 399 questions\n",
      "2025-03-13 15:33:27,655 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 502 asynchronously\n",
      "2025-03-13 15:33:27,656 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4743\n",
      "2025-03-13 15:33:27,656 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4743 for 399 questions\n",
      "2025-03-13 15:33:27,656 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4743 asynchronously\n",
      "2025-03-13 15:33:27,657 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3112\n",
      "2025-03-13 15:33:27,657 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3112 for 399 questions\n",
      "2025-03-13 15:33:27,657 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3112 asynchronously\n",
      "2025-03-13 15:33:27,657 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 295\n",
      "2025-03-13 15:33:27,657 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 295 for 399 questions\n",
      "2025-03-13 15:33:27,658 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 295 asynchronously\n",
      "2025-03-13 15:33:27,658 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 5a613d7e86...)\n",
      "2025-03-13 15:33:27,659 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4446\n",
      "2025-03-13 15:33:27,659 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4003\n",
      "2025-03-13 15:33:27,660 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4003 for 399 questions\n",
      "2025-03-13 15:33:27,660 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4003 asynchronously\n",
      "2025-03-13 15:33:27,662 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6c2b958dfd...)\n",
      "2025-03-13 15:33:27,662 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2234\n",
      "2025-03-13 15:33:27,663 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6790\n",
      "2025-03-13 15:33:27,664 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6790 for 399 questions\n",
      "2025-03-13 15:33:27,664 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6790 asynchronously\n",
      "2025-03-13 15:33:27,670 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: eb4820aa47...)\n",
      "2025-03-13 15:33:27,671 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5454\n",
      "2025-03-13 15:33:27,671 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1726\n",
      "2025-03-13 15:33:27,671 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1726 for 399 questions\n",
      "2025-03-13 15:33:27,672 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1726 asynchronously\n",
      "2025-03-13 15:33:27,677 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: f26a83f8da...)\n",
      "2025-03-13 15:33:27,678 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1278\n",
      "2025-03-13 15:33:27,678 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 530\n",
      "2025-03-13 15:33:27,678 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 530 for 399 questions\n",
      "2025-03-13 15:33:27,679 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 530 asynchronously\n",
      "2025-03-13 15:33:27,684 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d29f5e1d18...)\n",
      "2025-03-13 15:33:27,685 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 578\n",
      "2025-03-13 15:33:27,685 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4188\n",
      "2025-03-13 15:33:27,685 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4188 for 399 questions\n",
      "2025-03-13 15:33:27,686 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4188 asynchronously\n",
      "2025-03-13 15:33:27,692 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 57a27a7897...)\n",
      "2025-03-13 15:33:27,693 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5960\n",
      "2025-03-13 15:33:27,693 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5022\n",
      "2025-03-13 15:33:27,693 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5022 for 399 questions\n",
      "2025-03-13 15:33:27,694 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5022 asynchronously\n",
      "2025-03-13 15:33:27,698 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 59d13f2208...)\n",
      "2025-03-13 15:33:27,699 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 521\n",
      "2025-03-13 15:33:27,699 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2716\n",
      "2025-03-13 15:33:27,699 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2716 for 399 questions\n",
      "2025-03-13 15:33:27,700 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2716 asynchronously\n",
      "2025-03-13 15:33:27,705 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: eaad5b83c1...)\n",
      "2025-03-13 15:33:27,706 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 217\n",
      "2025-03-13 15:33:27,707 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1220\n",
      "2025-03-13 15:33:27,707 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1220 for 399 questions\n",
      "2025-03-13 15:33:27,707 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1220 asynchronously\n",
      "2025-03-13 15:33:27,711 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 972ff8c0c8...)\n",
      "2025-03-13 15:33:27,712 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5716\n",
      "2025-03-13 15:33:27,712 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2938\n",
      "2025-03-13 15:33:27,713 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2938 for 399 questions\n",
      "2025-03-13 15:33:27,713 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2938 asynchronously\n",
      "2025-03-13 15:33:27,718 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 3a41213624...)\n",
      "2025-03-13 15:33:27,719 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 202\n",
      "2025-03-13 15:33:27,719 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4098\n",
      "2025-03-13 15:33:27,720 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4098 for 399 questions\n",
      "2025-03-13 15:33:27,720 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4098 asynchronously\n",
      "2025-03-13 15:33:27,725 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: cbf3742573...)\n",
      "2025-03-13 15:33:27,725 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 134\n",
      "2025-03-13 15:33:27,726 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1922\n",
      "2025-03-13 15:33:27,726 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1922 for 399 questions\n",
      "2025-03-13 15:33:27,726 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1922 asynchronously\n",
      "2025-03-13 15:33:27,731 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 96b132350b...)\n",
      "2025-03-13 15:33:27,732 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 154\n",
      "2025-03-13 15:33:27,733 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5098\n",
      "2025-03-13 15:33:27,733 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5098 for 399 questions\n",
      "2025-03-13 15:33:27,733 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5098 asynchronously\n",
      "2025-03-13 15:33:27,737 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 69a50e07ad...)\n",
      "2025-03-13 15:33:27,738 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4486\n",
      "2025-03-13 15:33:27,738 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4154\n",
      "2025-03-13 15:33:27,739 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4154 for 399 questions\n",
      "2025-03-13 15:33:27,739 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4154 asynchronously\n",
      "2025-03-13 15:33:27,744 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: b193efd588...)\n",
      "2025-03-13 15:33:27,745 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3283\n",
      "2025-03-13 15:33:27,745 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2188\n",
      "2025-03-13 15:33:27,745 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2188 for 399 questions\n",
      "2025-03-13 15:33:27,746 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2188 asynchronously\n",
      "2025-03-13 15:33:27,750 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 666a427d1c...)\n",
      "2025-03-13 15:33:27,752 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3731\n",
      "2025-03-13 15:33:27,752 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6760\n",
      "2025-03-13 15:33:27,752 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6760 for 399 questions\n",
      "2025-03-13 15:33:27,752 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6760 asynchronously\n",
      "2025-03-13 15:33:27,756 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 88ab8c94c3...)\n",
      "2025-03-13 15:33:27,757 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2572\n",
      "2025-03-13 15:33:27,758 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2913\n",
      "2025-03-13 15:33:27,758 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2913 for 399 questions\n",
      "2025-03-13 15:33:27,758 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2913 asynchronously\n",
      "2025-03-13 15:33:27,762 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 89edcfb5e1...)\n",
      "2025-03-13 15:33:27,763 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4296\n",
      "2025-03-13 15:33:27,763 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6174\n",
      "2025-03-13 15:33:27,764 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6174 for 399 questions\n",
      "2025-03-13 15:33:27,764 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6174 asynchronously\n",
      "2025-03-13 15:33:27,768 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a3fda18afa...)\n",
      "2025-03-13 15:33:27,769 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2838\n",
      "2025-03-13 15:33:27,769 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5197\n",
      "2025-03-13 15:33:27,770 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5197 for 399 questions\n",
      "2025-03-13 15:33:27,770 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5197 asynchronously\n",
      "2025-03-13 15:33:27,774 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 1eef8e9beb...)\n",
      "2025-03-13 15:33:27,775 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3711\n",
      "2025-03-13 15:33:27,775 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 641\n",
      "2025-03-13 15:33:27,776 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 641 for 399 questions\n",
      "2025-03-13 15:33:27,776 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 641 asynchronously\n",
      "2025-03-13 15:33:27,780 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 8ccf7e253c...)\n",
      "2025-03-13 15:33:27,781 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2425\n",
      "2025-03-13 15:33:27,782 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 224\n",
      "2025-03-13 15:33:27,782 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 224 for 399 questions\n",
      "2025-03-13 15:33:27,783 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 224 asynchronously\n",
      "2025-03-13 15:33:27,786 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c9e9f850a6...)\n",
      "2025-03-13 15:33:27,787 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5721\n",
      "2025-03-13 15:33:27,787 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2162\n",
      "2025-03-13 15:33:27,788 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2162 for 399 questions\n",
      "2025-03-13 15:33:27,788 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2162 asynchronously\n",
      "2025-03-13 15:33:27,792 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 413930a1ef...)\n",
      "2025-03-13 15:33:27,793 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6429\n",
      "2025-03-13 15:33:27,793 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3370\n",
      "2025-03-13 15:33:27,794 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3370 for 399 questions\n",
      "2025-03-13 15:33:27,794 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3370 asynchronously\n",
      "2025-03-13 15:33:27,799 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: de5092acbf...)\n",
      "2025-03-13 15:33:27,800 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5458\n",
      "2025-03-13 15:33:27,800 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6038\n",
      "2025-03-13 15:33:27,800 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6038 for 399 questions\n",
      "2025-03-13 15:33:27,800 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6038 asynchronously\n",
      "2025-03-13 15:33:27,804 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 24f273bdba...)\n",
      "2025-03-13 15:33:27,805 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5549\n",
      "2025-03-13 15:33:27,806 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6114\n",
      "2025-03-13 15:33:27,806 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6114 for 399 questions\n",
      "2025-03-13 15:33:27,807 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6114 asynchronously\n",
      "2025-03-13 15:33:27,811 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 05b9558ce2...)\n",
      "2025-03-13 15:33:27,812 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6258\n",
      "2025-03-13 15:33:27,812 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 979\n",
      "2025-03-13 15:33:27,813 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 979 for 399 questions\n",
      "2025-03-13 15:33:27,813 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 979 asynchronously\n",
      "2025-03-13 15:33:27,818 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d5b4e0bf40...)\n",
      "2025-03-13 15:33:27,819 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4481\n",
      "2025-03-13 15:33:27,819 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4185\n",
      "2025-03-13 15:33:27,820 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4185 for 399 questions\n",
      "2025-03-13 15:33:27,820 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4185 asynchronously\n",
      "2025-03-13 15:33:27,824 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: f0acf058a7...)\n",
      "2025-03-13 15:33:27,825 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 779\n",
      "2025-03-13 15:33:27,825 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5830\n",
      "2025-03-13 15:33:27,825 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5830 for 399 questions\n",
      "2025-03-13 15:33:27,826 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5830 asynchronously\n",
      "2025-03-13 15:33:27,830 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: cf49d6d0c7...)\n",
      "2025-03-13 15:33:27,831 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4120\n",
      "2025-03-13 15:33:27,831 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6951\n",
      "2025-03-13 15:33:27,832 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6951 for 399 questions\n",
      "2025-03-13 15:33:27,832 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6951 asynchronously\n",
      "2025-03-13 15:33:27,837 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c16bb3d88f...)\n",
      "2025-03-13 15:33:27,838 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6533\n",
      "2025-03-13 15:33:27,838 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 509\n",
      "2025-03-13 15:33:27,839 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 509 for 399 questions\n",
      "2025-03-13 15:33:27,839 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 509 asynchronously\n",
      "2025-03-13 15:33:27,843 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 2083cb3458...)\n",
      "2025-03-13 15:33:27,844 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4559\n",
      "2025-03-13 15:33:27,844 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3302\n",
      "2025-03-13 15:33:27,845 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3302 for 399 questions\n",
      "2025-03-13 15:33:27,845 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3302 asynchronously\n",
      "2025-03-13 15:33:27,849 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a256c042be...)\n",
      "2025-03-13 15:33:27,850 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1564\n",
      "2025-03-13 15:33:27,850 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2568\n",
      "2025-03-13 15:33:27,851 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2568 for 399 questions\n",
      "2025-03-13 15:33:27,851 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2568 asynchronously\n",
      "2025-03-13 15:33:27,855 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9457036a62...)\n",
      "2025-03-13 15:33:27,856 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 693\n",
      "2025-03-13 15:33:27,856 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6471\n",
      "2025-03-13 15:33:27,857 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6471 for 399 questions\n",
      "2025-03-13 15:33:27,857 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6471 asynchronously\n",
      "2025-03-13 15:33:27,861 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 757adbc4b0...)\n",
      "2025-03-13 15:33:27,862 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3028\n",
      "2025-03-13 15:33:27,862 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3883\n",
      "2025-03-13 15:33:27,863 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3883 for 399 questions\n",
      "2025-03-13 15:33:27,863 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3883 asynchronously\n",
      "2025-03-13 15:33:27,868 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 54d1cd3fa8...)\n",
      "2025-03-13 15:33:27,869 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4346\n",
      "2025-03-13 15:33:27,869 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5895\n",
      "2025-03-13 15:33:27,870 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5895 for 399 questions\n",
      "2025-03-13 15:33:27,870 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5895 asynchronously\n",
      "2025-03-13 15:33:27,874 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 26a5d36716...)\n",
      "2025-03-13 15:33:27,875 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6556\n",
      "2025-03-13 15:33:27,875 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 548\n",
      "2025-03-13 15:33:27,875 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 548 for 399 questions\n",
      "2025-03-13 15:33:27,875 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 548 asynchronously\n",
      "2025-03-13 15:33:27,879 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 3eddc2f4bf...)\n",
      "2025-03-13 15:33:27,882 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 526\n",
      "2025-03-13 15:33:27,882 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4234\n",
      "2025-03-13 15:33:27,882 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4234 for 399 questions\n",
      "2025-03-13 15:33:27,883 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4234 asynchronously\n",
      "2025-03-13 15:33:27,886 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 053c1ea23d...)\n",
      "2025-03-13 15:33:27,887 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 502\n",
      "2025-03-13 15:33:27,888 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 574\n",
      "2025-03-13 15:33:27,888 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 574 for 399 questions\n",
      "2025-03-13 15:33:27,888 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 574 asynchronously\n",
      "2025-03-13 15:33:27,893 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 76e690537e...)\n",
      "2025-03-13 15:33:27,893 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4743\n",
      "2025-03-13 15:33:27,894 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1422\n",
      "2025-03-13 15:33:27,894 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1422 for 399 questions\n",
      "2025-03-13 15:33:27,894 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1422 asynchronously\n",
      "2025-03-13 15:33:27,899 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ea7b177acc...)\n",
      "2025-03-13 15:33:27,900 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3112\n",
      "2025-03-13 15:33:27,900 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4339\n",
      "2025-03-13 15:33:27,900 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4339 for 399 questions\n",
      "2025-03-13 15:33:27,912 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4339 asynchronously\n",
      "2025-03-13 15:33:27,933 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 214b579ccf...)\n",
      "2025-03-13 15:33:27,935 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 295\n",
      "2025-03-13 15:33:27,941 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4324\n",
      "2025-03-13 15:33:27,942 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4324 for 399 questions\n",
      "2025-03-13 15:33:27,942 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4324 asynchronously\n",
      "2025-03-13 15:33:27,945 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 1ff832a906...)\n",
      "2025-03-13 15:33:27,946 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4003\n",
      "2025-03-13 15:33:27,946 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1043\n",
      "2025-03-13 15:33:27,947 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1043 for 399 questions\n",
      "2025-03-13 15:33:27,947 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1043 asynchronously\n",
      "2025-03-13 15:33:27,951 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ec5ccaf562...)\n",
      "2025-03-13 15:33:27,952 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6790\n",
      "2025-03-13 15:33:27,953 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 144\n",
      "2025-03-13 15:33:27,953 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 144 for 399 questions\n",
      "2025-03-13 15:33:27,953 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 144 asynchronously\n",
      "2025-03-13 15:33:27,958 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e8ebcc2a51...)\n",
      "2025-03-13 15:33:27,959 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1726\n",
      "2025-03-13 15:33:27,959 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6355\n",
      "2025-03-13 15:33:27,959 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6355 for 399 questions\n",
      "2025-03-13 15:33:27,959 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6355 asynchronously\n",
      "2025-03-13 15:33:27,963 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 5c69e517a3...)\n",
      "2025-03-13 15:33:27,965 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 530\n",
      "2025-03-13 15:33:27,965 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2625\n",
      "2025-03-13 15:33:27,966 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2625 for 399 questions\n",
      "2025-03-13 15:33:27,966 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2625 asynchronously\n",
      "2025-03-13 15:33:27,970 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d7aa953596...)\n",
      "2025-03-13 15:33:27,971 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4188\n",
      "2025-03-13 15:33:27,971 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4265\n",
      "2025-03-13 15:33:27,971 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4265 for 399 questions\n",
      "2025-03-13 15:33:27,972 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4265 asynchronously\n",
      "2025-03-13 15:33:27,976 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d1edcc6f84...)\n",
      "2025-03-13 15:33:27,977 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5022\n",
      "2025-03-13 15:33:27,977 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2641\n",
      "2025-03-13 15:33:27,978 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2641 for 399 questions\n",
      "2025-03-13 15:33:27,978 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2641 asynchronously\n",
      "2025-03-13 15:33:27,983 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 556f885ba9...)\n",
      "2025-03-13 15:33:27,984 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2716\n",
      "2025-03-13 15:33:27,985 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6906\n",
      "2025-03-13 15:33:27,985 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6906 for 399 questions\n",
      "2025-03-13 15:33:27,985 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6906 asynchronously\n",
      "2025-03-13 15:33:27,989 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 834ad71b3f...)\n",
      "2025-03-13 15:33:27,990 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1220\n",
      "2025-03-13 15:33:27,991 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1585\n",
      "2025-03-13 15:33:27,991 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1585 for 399 questions\n",
      "2025-03-13 15:33:27,991 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1585 asynchronously\n",
      "2025-03-13 15:33:27,996 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 842640e3fb...)\n",
      "2025-03-13 15:33:27,997 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2938\n",
      "2025-03-13 15:33:27,997 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4909\n",
      "2025-03-13 15:33:27,997 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4909 for 399 questions\n",
      "2025-03-13 15:33:27,998 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4909 asynchronously\n",
      "2025-03-13 15:33:28,003 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 2e849dae6f...)\n",
      "2025-03-13 15:33:28,004 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4098\n",
      "2025-03-13 15:33:28,004 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4411\n",
      "2025-03-13 15:33:28,004 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4411 for 399 questions\n",
      "2025-03-13 15:33:28,004 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4411 asynchronously\n",
      "2025-03-13 15:33:28,009 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: cb9b5bc696...)\n",
      "2025-03-13 15:33:28,010 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1922\n",
      "2025-03-13 15:33:28,011 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3895\n",
      "2025-03-13 15:33:28,011 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3895 for 399 questions\n",
      "2025-03-13 15:33:28,011 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3895 asynchronously\n",
      "2025-03-13 15:33:28,015 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 1823579a40...)\n",
      "2025-03-13 15:33:28,016 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5098\n",
      "2025-03-13 15:33:28,016 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 451\n",
      "2025-03-13 15:33:28,016 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 451 for 399 questions\n",
      "2025-03-13 15:33:28,016 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 451 asynchronously\n",
      "2025-03-13 15:33:28,022 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 26610039e9...)\n",
      "2025-03-13 15:33:28,022 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4154\n",
      "2025-03-13 15:33:28,023 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1414\n",
      "2025-03-13 15:33:28,023 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1414 for 399 questions\n",
      "2025-03-13 15:33:28,023 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1414 asynchronously\n",
      "2025-03-13 15:33:28,028 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 58479941ff...)\n",
      "2025-03-13 15:33:28,029 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2188\n",
      "2025-03-13 15:33:28,029 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2031\n",
      "2025-03-13 15:33:28,029 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2031 for 399 questions\n",
      "2025-03-13 15:33:28,030 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2031 asynchronously\n",
      "2025-03-13 15:33:28,034 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 561cf98265...)\n",
      "2025-03-13 15:33:28,035 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6760\n",
      "2025-03-13 15:33:28,035 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2894\n",
      "2025-03-13 15:33:28,036 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2894 for 399 questions\n",
      "2025-03-13 15:33:28,036 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2894 asynchronously\n",
      "2025-03-13 15:33:28,040 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7f7ddd0c0c...)\n",
      "2025-03-13 15:33:28,041 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2913\n",
      "2025-03-13 15:33:28,041 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3424\n",
      "2025-03-13 15:33:28,042 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3424 for 399 questions\n",
      "2025-03-13 15:33:28,042 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3424 asynchronously\n",
      "2025-03-13 15:33:28,046 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 3e1a22969f...)\n",
      "2025-03-13 15:33:28,047 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6174\n",
      "2025-03-13 15:33:28,047 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3884\n",
      "2025-03-13 15:33:28,048 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3884 for 399 questions\n",
      "2025-03-13 15:33:28,048 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3884 asynchronously\n",
      "2025-03-13 15:33:28,052 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 2d5b76e52b...)\n",
      "2025-03-13 15:33:28,054 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5197\n",
      "2025-03-13 15:33:28,054 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6882\n",
      "2025-03-13 15:33:28,054 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6882 for 399 questions\n",
      "2025-03-13 15:33:28,054 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6882 asynchronously\n",
      "2025-03-13 15:33:28,058 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: cad694af63...)\n",
      "2025-03-13 15:33:28,059 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 641\n",
      "2025-03-13 15:33:28,059 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3261\n",
      "2025-03-13 15:33:28,060 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3261 for 399 questions\n",
      "2025-03-13 15:33:28,060 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3261 asynchronously\n",
      "2025-03-13 15:33:28,064 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 108affa239...)\n",
      "2025-03-13 15:33:28,065 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 224\n",
      "2025-03-13 15:33:28,065 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2240\n",
      "2025-03-13 15:33:28,065 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2240 for 399 questions\n",
      "2025-03-13 15:33:28,066 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2240 asynchronously\n",
      "2025-03-13 15:33:28,070 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 97921bb2f3...)\n",
      "2025-03-13 15:33:28,070 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2162\n",
      "2025-03-13 15:33:28,071 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4123\n",
      "2025-03-13 15:33:28,071 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4123 for 399 questions\n",
      "2025-03-13 15:33:28,071 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4123 asynchronously\n",
      "2025-03-13 15:33:28,077 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4492d3463b...)\n",
      "2025-03-13 15:33:28,077 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3370\n",
      "2025-03-13 15:33:28,078 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5430\n",
      "2025-03-13 15:33:28,078 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5430 for 399 questions\n",
      "2025-03-13 15:33:28,078 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5430 asynchronously\n",
      "2025-03-13 15:33:28,084 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7484d55dac...)\n",
      "2025-03-13 15:33:28,084 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6038\n",
      "2025-03-13 15:33:28,085 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4018\n",
      "2025-03-13 15:33:28,085 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4018 for 399 questions\n",
      "2025-03-13 15:33:28,085 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4018 asynchronously\n",
      "2025-03-13 15:33:28,089 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 3e3d2ef467...)\n",
      "2025-03-13 15:33:28,090 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6114\n",
      "2025-03-13 15:33:28,091 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2657\n",
      "2025-03-13 15:33:28,091 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2657 for 399 questions\n",
      "2025-03-13 15:33:28,091 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2657 asynchronously\n",
      "2025-03-13 15:33:28,095 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 5e3657f44d...)\n",
      "2025-03-13 15:33:28,097 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 979\n",
      "2025-03-13 15:33:28,097 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4397\n",
      "2025-03-13 15:33:28,097 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4397 for 399 questions\n",
      "2025-03-13 15:33:28,098 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4397 asynchronously\n",
      "2025-03-13 15:33:28,102 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: f8efc9f3c7...)\n",
      "2025-03-13 15:33:28,103 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4185\n",
      "2025-03-13 15:33:28,103 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 7025\n",
      "2025-03-13 15:33:28,104 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 7025 for 399 questions\n",
      "2025-03-13 15:33:28,104 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 7025 asynchronously\n",
      "2025-03-13 15:33:28,109 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6675db3f99...)\n",
      "2025-03-13 15:33:28,110 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5830\n",
      "2025-03-13 15:33:28,111 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1656\n",
      "2025-03-13 15:33:28,111 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1656 for 399 questions\n",
      "2025-03-13 15:33:28,111 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1656 asynchronously\n",
      "2025-03-13 15:33:28,116 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 8b547dc4ac...)\n",
      "2025-03-13 15:33:28,117 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6951\n",
      "2025-03-13 15:33:28,118 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5904\n",
      "2025-03-13 15:33:28,118 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5904 for 399 questions\n",
      "2025-03-13 15:33:28,119 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5904 asynchronously\n",
      "2025-03-13 15:33:28,123 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 2ea79c24e4...)\n",
      "2025-03-13 15:33:28,125 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 509\n",
      "2025-03-13 15:33:28,125 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6988\n",
      "2025-03-13 15:33:28,126 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6988 for 399 questions\n",
      "2025-03-13 15:33:28,126 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6988 asynchronously\n",
      "2025-03-13 15:33:28,130 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 5f7e3d6266...)\n",
      "2025-03-13 15:33:28,131 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3302\n",
      "2025-03-13 15:33:28,132 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6053\n",
      "2025-03-13 15:33:28,133 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6053 for 399 questions\n",
      "2025-03-13 15:33:28,134 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6053 asynchronously\n",
      "2025-03-13 15:33:28,138 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 091e1e4b7f...)\n",
      "2025-03-13 15:33:28,139 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2568\n",
      "2025-03-13 15:33:28,140 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5639\n",
      "2025-03-13 15:33:28,140 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5639 for 399 questions\n",
      "2025-03-13 15:33:28,140 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5639 asynchronously\n",
      "2025-03-13 15:33:28,144 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 919664cdd6...)\n",
      "2025-03-13 15:33:28,146 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6471\n",
      "2025-03-13 15:33:28,146 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 38\n",
      "2025-03-13 15:33:28,147 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 38 for 399 questions\n",
      "2025-03-13 15:33:28,148 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 38 asynchronously\n",
      "2025-03-13 15:33:28,152 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: be4dfcae12...)\n",
      "2025-03-13 15:33:28,153 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3883\n",
      "2025-03-13 15:33:28,153 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1386\n",
      "2025-03-13 15:33:28,154 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1386 for 399 questions\n",
      "2025-03-13 15:33:28,154 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1386 asynchronously\n",
      "2025-03-13 15:33:28,174 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9a5a08a8f7...)\n",
      "2025-03-13 15:33:28,182 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5895\n",
      "2025-03-13 15:33:28,183 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1700\n",
      "2025-03-13 15:33:28,183 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1700 for 399 questions\n",
      "2025-03-13 15:33:28,183 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1700 asynchronously\n",
      "2025-03-13 15:33:28,192 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0519c01633...)\n",
      "2025-03-13 15:33:28,193 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 548\n",
      "2025-03-13 15:33:28,193 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2652\n",
      "2025-03-13 15:33:28,193 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2652 for 399 questions\n",
      "2025-03-13 15:33:28,194 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2652 asynchronously\n",
      "2025-03-13 15:33:28,199 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 3b66836624...)\n",
      "2025-03-13 15:33:28,200 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4234\n",
      "2025-03-13 15:33:28,200 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3733\n",
      "2025-03-13 15:33:28,200 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3733 for 399 questions\n",
      "2025-03-13 15:33:28,201 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3733 asynchronously\n",
      "2025-03-13 15:33:28,205 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4b23c9c732...)\n",
      "2025-03-13 15:33:28,206 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 574\n",
      "2025-03-13 15:33:28,206 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1411\n",
      "2025-03-13 15:33:28,207 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1411 for 399 questions\n",
      "2025-03-13 15:33:28,207 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1411 asynchronously\n",
      "2025-03-13 15:33:28,212 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a7fc244dfe...)\n",
      "2025-03-13 15:33:28,212 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1422\n",
      "2025-03-13 15:33:28,213 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1952\n",
      "2025-03-13 15:33:28,213 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1952 for 399 questions\n",
      "2025-03-13 15:33:28,213 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1952 asynchronously\n",
      "2025-03-13 15:33:28,218 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: fde0d01539...)\n",
      "2025-03-13 15:33:28,220 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4339\n",
      "2025-03-13 15:33:28,220 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4752\n",
      "2025-03-13 15:33:28,220 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4752 for 399 questions\n",
      "2025-03-13 15:33:28,220 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4752 asynchronously\n",
      "2025-03-13 15:33:28,224 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 68f99e870a...)\n",
      "2025-03-13 15:33:28,225 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4324\n",
      "2025-03-13 15:33:28,225 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5777\n",
      "2025-03-13 15:33:28,225 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5777 for 399 questions\n",
      "2025-03-13 15:33:28,226 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5777 asynchronously\n",
      "2025-03-13 15:33:28,230 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 1534eaf5f2...)\n",
      "2025-03-13 15:33:28,231 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1043\n",
      "2025-03-13 15:33:28,232 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 558\n",
      "2025-03-13 15:33:28,232 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 558 for 399 questions\n",
      "2025-03-13 15:33:28,232 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 558 asynchronously\n",
      "2025-03-13 15:33:28,236 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: bbe08ac70a...)\n",
      "2025-03-13 15:33:28,237 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 144\n",
      "2025-03-13 15:33:28,237 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4551\n",
      "2025-03-13 15:33:28,237 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4551 for 399 questions\n",
      "2025-03-13 15:33:28,238 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4551 asynchronously\n",
      "2025-03-13 15:33:28,242 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 16e2a53840...)\n",
      "2025-03-13 15:33:28,243 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6355\n",
      "2025-03-13 15:33:28,243 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5769\n",
      "2025-03-13 15:33:28,244 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5769 for 399 questions\n",
      "2025-03-13 15:33:28,244 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5769 asynchronously\n",
      "2025-03-13 15:33:28,248 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 659119e79c...)\n",
      "2025-03-13 15:33:28,249 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2625\n",
      "2025-03-13 15:33:28,249 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5912\n",
      "2025-03-13 15:33:28,249 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5912 for 399 questions\n",
      "2025-03-13 15:33:28,250 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5912 asynchronously\n",
      "2025-03-13 15:33:28,255 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 30ca15094a...)\n",
      "2025-03-13 15:33:28,256 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4265\n",
      "2025-03-13 15:33:28,256 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 296\n",
      "2025-03-13 15:33:28,256 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 296 for 399 questions\n",
      "2025-03-13 15:33:28,257 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 296 asynchronously\n",
      "2025-03-13 15:33:28,261 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4fb3521c43...)\n",
      "2025-03-13 15:33:28,263 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2641\n",
      "2025-03-13 15:33:28,263 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 444\n",
      "2025-03-13 15:33:28,263 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 444 for 399 questions\n",
      "2025-03-13 15:33:28,264 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 444 asynchronously\n",
      "2025-03-13 15:33:28,268 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 21eca775e0...)\n",
      "2025-03-13 15:33:28,269 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6906\n",
      "2025-03-13 15:33:28,269 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1140\n",
      "2025-03-13 15:33:28,269 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1140 for 399 questions\n",
      "2025-03-13 15:33:28,270 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1140 asynchronously\n",
      "2025-03-13 15:33:28,274 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: f71b598bfa...)\n",
      "2025-03-13 15:33:28,275 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1585\n",
      "2025-03-13 15:33:28,275 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 812\n",
      "2025-03-13 15:33:28,276 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 812 for 399 questions\n",
      "2025-03-13 15:33:28,276 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 812 asynchronously\n",
      "2025-03-13 15:33:28,281 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9f5e8b96da...)\n",
      "2025-03-13 15:33:28,282 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4909\n",
      "2025-03-13 15:33:28,283 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2531\n",
      "2025-03-13 15:33:28,283 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2531 for 399 questions\n",
      "2025-03-13 15:33:28,283 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2531 asynchronously\n",
      "2025-03-13 15:33:28,294 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: dca542e18c...)\n",
      "2025-03-13 15:33:28,295 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4411\n",
      "2025-03-13 15:33:28,296 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6311\n",
      "2025-03-13 15:33:28,296 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6311 for 399 questions\n",
      "2025-03-13 15:33:28,296 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6311 asynchronously\n",
      "2025-03-13 15:33:28,301 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c0ca80a1be...)\n",
      "2025-03-13 15:33:28,302 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3895\n",
      "2025-03-13 15:33:28,302 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2915\n",
      "2025-03-13 15:33:28,302 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2915 for 399 questions\n",
      "2025-03-13 15:33:28,303 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2915 asynchronously\n",
      "2025-03-13 15:33:28,308 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a41181bfab...)\n",
      "2025-03-13 15:33:28,309 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 451\n",
      "2025-03-13 15:33:28,309 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6941\n",
      "2025-03-13 15:33:28,310 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6941 for 399 questions\n",
      "2025-03-13 15:33:28,310 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6941 asynchronously\n",
      "2025-03-13 15:33:28,314 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a77d12920b...)\n",
      "2025-03-13 15:33:28,316 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1414\n",
      "2025-03-13 15:33:28,316 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4601\n",
      "2025-03-13 15:33:28,316 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4601 for 399 questions\n",
      "2025-03-13 15:33:28,317 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4601 asynchronously\n",
      "2025-03-13 15:33:28,321 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 213d8034fc...)\n",
      "2025-03-13 15:33:28,322 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2031\n",
      "2025-03-13 15:33:28,322 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5384\n",
      "2025-03-13 15:33:28,323 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5384 for 399 questions\n",
      "2025-03-13 15:33:28,323 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5384 asynchronously\n",
      "2025-03-13 15:33:28,327 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 738103e086...)\n",
      "2025-03-13 15:33:28,328 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2894\n",
      "2025-03-13 15:33:28,328 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4672\n",
      "2025-03-13 15:33:28,328 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4672 for 399 questions\n",
      "2025-03-13 15:33:28,329 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4672 asynchronously\n",
      "2025-03-13 15:33:44,876 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:44,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:44,909 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:44,924 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5777\n",
      "2025-03-13 15:33:44,925 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3055\n",
      "2025-03-13 15:33:44,925 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3055 for 399 questions\n",
      "2025-03-13 15:33:44,926 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3055 asynchronously\n",
      "2025-03-13 15:33:44,935 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:44,941 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:44,956 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2531\n",
      "2025-03-13 15:33:44,956 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1601\n",
      "2025-03-13 15:33:44,957 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1601 for 399 questions\n",
      "2025-03-13 15:33:44,957 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1601 asynchronously\n",
      "2025-03-13 15:33:44,966 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:44,982 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5639\n",
      "2025-03-13 15:33:44,982 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4382\n",
      "2025-03-13 15:33:44,982 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4382 for 399 questions\n",
      "2025-03-13 15:33:44,983 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4382 asynchronously\n",
      "2025-03-13 15:33:44,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:45,012 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1700\n",
      "2025-03-13 15:33:45,013 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6247\n",
      "2025-03-13 15:33:45,013 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6247 for 399 questions\n",
      "2025-03-13 15:33:45,014 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6247 asynchronously\n",
      "2025-03-13 15:33:45,032 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4601\n",
      "2025-03-13 15:33:45,033 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6063\n",
      "2025-03-13 15:33:45,033 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6063 for 399 questions\n",
      "2025-03-13 15:33:45,033 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6063 asynchronously\n",
      "2025-03-13 15:33:45,059 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4551\n",
      "2025-03-13 15:33:45,059 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4001\n",
      "2025-03-13 15:33:45,060 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4001 for 399 questions\n",
      "2025-03-13 15:33:45,060 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4001 asynchronously\n",
      "2025-03-13 15:33:45,083 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3424\n",
      "2025-03-13 15:33:45,084 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5180\n",
      "2025-03-13 15:33:45,084 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5180 for 399 questions\n",
      "2025-03-13 15:33:45,084 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5180 asynchronously\n",
      "2025-03-13 15:33:45,164 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:45,198 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4672\n",
      "2025-03-13 15:33:45,198 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3638\n",
      "2025-03-13 15:33:45,198 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3638 for 399 questions\n",
      "2025-03-13 15:33:45,199 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3638 asynchronously\n",
      "2025-03-13 15:33:45,646 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:45,700 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 444\n",
      "2025-03-13 15:33:45,700 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3788\n",
      "2025-03-13 15:33:45,701 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3788 for 399 questions\n",
      "2025-03-13 15:33:45,701 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3788 asynchronously\n",
      "2025-03-13 15:33:46,362 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:46,383 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:46,412 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4123\n",
      "2025-03-13 15:33:46,413 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3965\n",
      "2025-03-13 15:33:46,413 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3965 for 399 questions\n",
      "2025-03-13 15:33:46,413 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3965 asynchronously\n",
      "2025-03-13 15:33:46,422 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:46,438 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2657\n",
      "2025-03-13 15:33:46,438 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1633\n",
      "2025-03-13 15:33:46,439 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1633 for 399 questions\n",
      "2025-03-13 15:33:46,439 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1633 asynchronously\n",
      "2025-03-13 15:33:46,442 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:46,468 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1411\n",
      "2025-03-13 15:33:46,468 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6555\n",
      "2025-03-13 15:33:46,469 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6555 for 399 questions\n",
      "2025-03-13 15:33:46,469 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6555 asynchronously\n",
      "2025-03-13 15:33:46,473 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:46,479 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:46,494 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6941\n",
      "2025-03-13 15:33:46,495 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1870\n",
      "2025-03-13 15:33:46,495 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1870 for 399 questions\n",
      "2025-03-13 15:33:46,495 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1870 asynchronously\n",
      "2025-03-13 15:33:46,520 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 296\n",
      "2025-03-13 15:33:46,520 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 42\n",
      "2025-03-13 15:33:46,521 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 42 for 399 questions\n",
      "2025-03-13 15:33:46,521 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 42 asynchronously\n",
      "2025-03-13 15:33:46,539 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4397\n",
      "2025-03-13 15:33:46,539 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3598\n",
      "2025-03-13 15:33:46,539 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3598 for 399 questions\n",
      "2025-03-13 15:33:46,540 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3598 asynchronously\n",
      "2025-03-13 15:33:46,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:46,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:46,578 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2240\n",
      "2025-03-13 15:33:46,578 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1456\n",
      "2025-03-13 15:33:46,578 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1456 for 399 questions\n",
      "2025-03-13 15:33:46,579 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1456 asynchronously\n",
      "2025-03-13 15:33:46,596 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3733\n",
      "2025-03-13 15:33:46,597 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1979\n",
      "2025-03-13 15:33:46,597 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1979 for 399 questions\n",
      "2025-03-13 15:33:46,597 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1979 asynchronously\n",
      "2025-03-13 15:33:46,977 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:46,992 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,047 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3261\n",
      "2025-03-13 15:33:47,047 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 464\n",
      "2025-03-13 15:33:47,048 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 464 for 399 questions\n",
      "2025-03-13 15:33:47,048 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 464 asynchronously\n",
      "2025-03-13 15:33:47,069 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6882\n",
      "2025-03-13 15:33:47,070 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3567\n",
      "2025-03-13 15:33:47,070 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3567 for 399 questions\n",
      "2025-03-13 15:33:47,070 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3567 asynchronously\n",
      "2025-03-13 15:33:47,195 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,229 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 7025\n",
      "2025-03-13 15:33:47,230 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2242\n",
      "2025-03-13 15:33:47,230 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2242 for 399 questions\n",
      "2025-03-13 15:33:47,230 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2242 asynchronously\n",
      "2025-03-13 15:33:47,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,289 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5769\n",
      "2025-03-13 15:33:47,290 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5216\n",
      "2025-03-13 15:33:47,290 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5216 for 399 questions\n",
      "2025-03-13 15:33:47,290 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5216 asynchronously\n",
      "2025-03-13 15:33:47,311 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,318 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,333 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,338 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2652\n",
      "2025-03-13 15:33:47,338 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 244\n",
      "2025-03-13 15:33:47,338 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 244 for 399 questions\n",
      "2025-03-13 15:33:47,339 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 244 asynchronously\n",
      "2025-03-13 15:33:47,358 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5904\n",
      "2025-03-13 15:33:47,358 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2796\n",
      "2025-03-13 15:33:47,358 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2796 for 399 questions\n",
      "2025-03-13 15:33:47,358 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2796 asynchronously\n",
      "2025-03-13 15:33:47,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,377 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,384 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5912\n",
      "2025-03-13 15:33:47,384 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2931\n",
      "2025-03-13 15:33:47,384 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2931 for 399 questions\n",
      "2025-03-13 15:33:47,384 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2931 asynchronously\n",
      "2025-03-13 15:33:47,395 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,401 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,409 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4752\n",
      "2025-03-13 15:33:47,409 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3855\n",
      "2025-03-13 15:33:47,410 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3855 for 399 questions\n",
      "2025-03-13 15:33:47,410 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3855 asynchronously\n",
      "2025-03-13 15:33:47,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,431 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,436 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1656\n",
      "2025-03-13 15:33:47,437 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3964\n",
      "2025-03-13 15:33:47,437 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3964 for 399 questions\n",
      "2025-03-13 15:33:47,437 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3964 asynchronously\n",
      "2025-03-13 15:33:47,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,455 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6988\n",
      "2025-03-13 15:33:47,455 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2249\n",
      "2025-03-13 15:33:47,455 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2249 for 399 questions\n",
      "2025-03-13 15:33:47,456 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2249 asynchronously\n",
      "2025-03-13 15:33:47,475 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 558\n",
      "2025-03-13 15:33:47,475 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4357\n",
      "2025-03-13 15:33:47,475 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4357 for 399 questions\n",
      "2025-03-13 15:33:47,475 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4357 asynchronously\n",
      "2025-03-13 15:33:47,488 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,501 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6053\n",
      "2025-03-13 15:33:47,502 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6271\n",
      "2025-03-13 15:33:47,502 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6271 for 399 questions\n",
      "2025-03-13 15:33:47,502 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6271 asynchronously\n",
      "2025-03-13 15:33:47,520 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 812\n",
      "2025-03-13 15:33:47,520 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4619\n",
      "2025-03-13 15:33:47,520 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4619 for 399 questions\n",
      "2025-03-13 15:33:47,521 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4619 asynchronously\n",
      "2025-03-13 15:33:47,552 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1952\n",
      "2025-03-13 15:33:47,552 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6792\n",
      "2025-03-13 15:33:47,552 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6792 for 399 questions\n",
      "2025-03-13 15:33:47,553 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6792 asynchronously\n",
      "2025-03-13 15:33:47,577 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6311\n",
      "2025-03-13 15:33:47,577 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1829\n",
      "2025-03-13 15:33:47,578 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1829 for 399 questions\n",
      "2025-03-13 15:33:47,578 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1829 asynchronously\n",
      "2025-03-13 15:33:47,597 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1386\n",
      "2025-03-13 15:33:47,598 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6017\n",
      "2025-03-13 15:33:47,598 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6017 for 399 questions\n",
      "2025-03-13 15:33:47,598 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6017 asynchronously\n",
      "2025-03-13 15:33:47,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,825 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2915\n",
      "2025-03-13 15:33:47,825 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2372\n",
      "2025-03-13 15:33:47,826 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2372 for 399 questions\n",
      "2025-03-13 15:33:47,826 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2372 asynchronously\n",
      "2025-03-13 15:33:47,928 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,966 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:47,975 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5430\n",
      "2025-03-13 15:33:47,976 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4282\n",
      "2025-03-13 15:33:47,976 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4282 for 399 questions\n",
      "2025-03-13 15:33:47,976 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4282 asynchronously\n",
      "2025-03-13 15:33:47,996 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5384\n",
      "2025-03-13 15:33:47,996 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6543\n",
      "2025-03-13 15:33:47,996 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6543 for 399 questions\n",
      "2025-03-13 15:33:47,997 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6543 asynchronously\n",
      "2025-03-13 15:33:48,319 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:48,348 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:48,371 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1140\n",
      "2025-03-13 15:33:48,371 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4088\n",
      "2025-03-13 15:33:48,371 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4088 for 399 questions\n",
      "2025-03-13 15:33:48,372 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4088 asynchronously\n",
      "2025-03-13 15:33:48,420 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3884\n",
      "2025-03-13 15:33:48,420 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3804\n",
      "2025-03-13 15:33:48,420 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3804 for 399 questions\n",
      "2025-03-13 15:33:48,421 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3804 asynchronously\n",
      "2025-03-13 15:33:48,573 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:48,615 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 38\n",
      "2025-03-13 15:33:48,616 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5571\n",
      "2025-03-13 15:33:48,616 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5571 for 399 questions\n",
      "2025-03-13 15:33:48,616 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5571 asynchronously\n",
      "2025-03-13 15:33:51,769 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:51,825 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4018\n",
      "2025-03-13 15:33:51,825 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 751\n",
      "2025-03-13 15:33:51,825 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 751 for 399 questions\n",
      "2025-03-13 15:33:51,826 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 751 asynchronously\n",
      "2025-03-13 15:33:57,917 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:57,986 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4382\n",
      "2025-03-13 15:33:57,987 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4676\n",
      "2025-03-13 15:33:57,987 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4676 for 399 questions\n",
      "2025-03-13 15:33:57,988 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4676 asynchronously\n",
      "2025-03-13 15:33:58,230 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:58,287 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3788\n",
      "2025-03-13 15:33:58,287 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3634\n",
      "2025-03-13 15:33:58,288 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3634 for 399 questions\n",
      "2025-03-13 15:33:58,289 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3634 asynchronously\n",
      "2025-03-13 15:33:58,884 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:58,928 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3598\n",
      "2025-03-13 15:33:58,928 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5609\n",
      "2025-03-13 15:33:58,929 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5609 for 399 questions\n",
      "2025-03-13 15:33:58,930 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5609 asynchronously\n",
      "2025-03-13 15:33:59,030 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:59,057 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6063\n",
      "2025-03-13 15:33:59,057 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3200\n",
      "2025-03-13 15:33:59,058 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3200 for 399 questions\n",
      "2025-03-13 15:33:59,058 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3200 asynchronously\n",
      "2025-03-13 15:33:59,089 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:59,123 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2931\n",
      "2025-03-13 15:33:59,124 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 119\n",
      "2025-03-13 15:33:59,124 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 119 for 399 questions\n",
      "2025-03-13 15:33:59,124 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 119 asynchronously\n",
      "2025-03-13 15:33:59,163 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:59,192 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1870\n",
      "2025-03-13 15:33:59,192 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5768\n",
      "2025-03-13 15:33:59,192 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5768 for 399 questions\n",
      "2025-03-13 15:33:59,193 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5768 asynchronously\n",
      "2025-03-13 15:33:59,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:59,364 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5180\n",
      "2025-03-13 15:33:59,364 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 634\n",
      "2025-03-13 15:33:59,365 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 634 for 399 questions\n",
      "2025-03-13 15:33:59,365 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 634 asynchronously\n",
      "2025-03-13 15:33:59,389 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:59,403 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:59,416 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6247\n",
      "2025-03-13 15:33:59,416 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6256\n",
      "2025-03-13 15:33:59,416 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6256 for 399 questions\n",
      "2025-03-13 15:33:59,417 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6256 asynchronously\n",
      "2025-03-13 15:33:59,438 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3638\n",
      "2025-03-13 15:33:59,438 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6856\n",
      "2025-03-13 15:33:59,438 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6856 for 399 questions\n",
      "2025-03-13 15:33:59,439 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6856 asynchronously\n",
      "2025-03-13 15:33:59,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:33:59,904 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1829\n",
      "2025-03-13 15:33:59,904 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4194\n",
      "2025-03-13 15:33:59,904 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4194 for 399 questions\n",
      "2025-03-13 15:33:59,905 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4194 asynchronously\n",
      "2025-03-13 15:34:00,390 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:00,415 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1601\n",
      "2025-03-13 15:34:00,415 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1290\n",
      "2025-03-13 15:34:00,416 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1290 for 399 questions\n",
      "2025-03-13 15:34:00,416 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1290 asynchronously\n",
      "2025-03-13 15:34:00,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:00,719 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3965\n",
      "2025-03-13 15:34:00,720 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6838\n",
      "2025-03-13 15:34:00,720 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6838 for 399 questions\n",
      "2025-03-13 15:34:00,720 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6838 asynchronously\n",
      "2025-03-13 15:34:00,786 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:00,818 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 464\n",
      "2025-03-13 15:34:00,819 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3847\n",
      "2025-03-13 15:34:00,819 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3847 for 399 questions\n",
      "2025-03-13 15:34:00,819 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3847 asynchronously\n",
      "2025-03-13 15:34:01,474 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:01,499 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3567\n",
      "2025-03-13 15:34:01,499 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4493\n",
      "2025-03-13 15:34:01,500 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4493 for 399 questions\n",
      "2025-03-13 15:34:01,500 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4493 asynchronously\n",
      "2025-03-13 15:34:01,708 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:01,735 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4282\n",
      "2025-03-13 15:34:01,736 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1460\n",
      "2025-03-13 15:34:01,736 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1460 for 399 questions\n",
      "2025-03-13 15:34:01,736 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1460 asynchronously\n",
      "2025-03-13 15:34:01,840 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:01,880 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 244\n",
      "2025-03-13 15:34:01,881 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6890\n",
      "2025-03-13 15:34:01,881 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6890 for 399 questions\n",
      "2025-03-13 15:34:01,881 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6890 asynchronously\n",
      "2025-03-13 15:34:01,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:01,950 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 42\n",
      "2025-03-13 15:34:01,951 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5152\n",
      "2025-03-13 15:34:01,951 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5152 for 399 questions\n",
      "2025-03-13 15:34:01,951 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5152 asynchronously\n",
      "2025-03-13 15:34:01,958 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:01,983 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6271\n",
      "2025-03-13 15:34:01,984 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4579\n",
      "2025-03-13 15:34:01,984 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4579 for 399 questions\n",
      "2025-03-13 15:34:01,984 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4579 asynchronously\n",
      "2025-03-13 15:34:02,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:02,044 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4357\n",
      "2025-03-13 15:34:02,044 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5232\n",
      "2025-03-13 15:34:02,044 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5232 for 399 questions\n",
      "2025-03-13 15:34:02,044 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5232 asynchronously\n",
      "2025-03-13 15:34:02,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:02,102 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6555\n",
      "2025-03-13 15:34:02,102 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1433\n",
      "2025-03-13 15:34:02,102 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1433 for 399 questions\n",
      "2025-03-13 15:34:02,102 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1433 asynchronously\n",
      "2025-03-13 15:34:02,120 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:02,147 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1633\n",
      "2025-03-13 15:34:02,148 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2190\n",
      "2025-03-13 15:34:02,148 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2190 for 399 questions\n",
      "2025-03-13 15:34:02,148 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2190 asynchronously\n",
      "2025-03-13 15:34:02,200 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:02,232 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3804\n",
      "2025-03-13 15:34:02,232 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3699\n",
      "2025-03-13 15:34:02,232 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3699 for 399 questions\n",
      "2025-03-13 15:34:02,233 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3699 asynchronously\n",
      "2025-03-13 15:34:02,569 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:02,600 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4088\n",
      "2025-03-13 15:34:02,600 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1712\n",
      "2025-03-13 15:34:02,600 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1712 for 399 questions\n",
      "2025-03-13 15:34:02,601 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1712 asynchronously\n",
      "2025-03-13 15:34:02,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:02,830 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4001\n",
      "2025-03-13 15:34:02,831 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2029\n",
      "2025-03-13 15:34:02,831 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2029 for 399 questions\n",
      "2025-03-13 15:34:02,831 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2029 asynchronously\n",
      "2025-03-13 15:34:03,360 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:03,404 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5571\n",
      "2025-03-13 15:34:03,405 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1778\n",
      "2025-03-13 15:34:03,405 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1778 for 399 questions\n",
      "2025-03-13 15:34:03,405 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1778 asynchronously\n",
      "2025-03-13 15:34:03,497 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:03,545 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3055\n",
      "2025-03-13 15:34:03,545 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 44\n",
      "2025-03-13 15:34:03,545 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 44 for 399 questions\n",
      "2025-03-13 15:34:03,546 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 44 asynchronously\n",
      "2025-03-13 15:34:04,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:04,169 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2796\n",
      "2025-03-13 15:34:04,170 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 841\n",
      "2025-03-13 15:34:04,170 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 841 for 399 questions\n",
      "2025-03-13 15:34:04,170 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 841 asynchronously\n",
      "2025-03-13 15:34:05,510 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:05,542 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3964\n",
      "2025-03-13 15:34:05,542 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1859\n",
      "2025-03-13 15:34:05,542 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1859 for 399 questions\n",
      "2025-03-13 15:34:05,542 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1859 asynchronously\n",
      "2025-03-13 15:34:05,758 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:05,825 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6792\n",
      "2025-03-13 15:34:05,825 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2734\n",
      "2025-03-13 15:34:05,826 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2734 for 399 questions\n",
      "2025-03-13 15:34:05,826 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2734 asynchronously\n",
      "2025-03-13 15:34:05,949 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:05,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:05,985 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4619\n",
      "2025-03-13 15:34:05,985 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5176\n",
      "2025-03-13 15:34:05,985 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5176 for 399 questions\n",
      "2025-03-13 15:34:05,986 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5176 asynchronously\n",
      "2025-03-13 15:34:06,010 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2372\n",
      "2025-03-13 15:34:06,010 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 495\n",
      "2025-03-13 15:34:06,010 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 495 for 399 questions\n",
      "2025-03-13 15:34:06,010 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 495 asynchronously\n",
      "2025-03-13 15:34:06,153 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:06,206 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1456\n",
      "2025-03-13 15:34:06,206 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3235\n",
      "2025-03-13 15:34:06,206 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3235 for 399 questions\n",
      "2025-03-13 15:34:06,207 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3235 asynchronously\n",
      "2025-03-13 15:34:06,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:06,791 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2249\n",
      "2025-03-13 15:34:06,792 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1082\n",
      "2025-03-13 15:34:06,792 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1082 for 399 questions\n",
      "2025-03-13 15:34:06,792 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1082 asynchronously\n",
      "2025-03-13 15:34:06,855 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:06,897 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6017\n",
      "2025-03-13 15:34:06,897 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4685\n",
      "2025-03-13 15:34:06,897 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4685 for 399 questions\n",
      "2025-03-13 15:34:06,898 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4685 asynchronously\n",
      "2025-03-13 15:34:07,143 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:07,192 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1979\n",
      "2025-03-13 15:34:07,193 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2004\n",
      "2025-03-13 15:34:07,193 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2004 for 399 questions\n",
      "2025-03-13 15:34:07,194 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2004 asynchronously\n",
      "2025-03-13 15:34:07,661 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 502 Bad Gateway\"\n",
      "2025-03-13 15:34:07,662 - openai._base_client - INFO - Retrying request to /chat/completions in 0.386204 seconds\n",
      "2025-03-13 15:34:07,744 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:07,806 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2242\n",
      "2025-03-13 15:34:07,806 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2137\n",
      "2025-03-13 15:34:07,806 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2137 for 399 questions\n",
      "2025-03-13 15:34:07,807 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2137 asynchronously\n",
      "2025-03-13 15:34:08,276 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:08,288 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:08,318 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5216\n",
      "2025-03-13 15:34:08,318 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 874\n",
      "2025-03-13 15:34:08,319 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 874 for 399 questions\n",
      "2025-03-13 15:34:08,319 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 874 asynchronously\n",
      "2025-03-13 15:34:08,343 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3855\n",
      "2025-03-13 15:34:08,344 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4276\n",
      "2025-03-13 15:34:08,344 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4276 for 399 questions\n",
      "2025-03-13 15:34:08,344 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4276 asynchronously\n",
      "2025-03-13 15:34:08,549 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:08,604 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6543\n",
      "2025-03-13 15:34:08,604 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4113\n",
      "2025-03-13 15:34:08,604 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4113 for 399 questions\n",
      "2025-03-13 15:34:08,605 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4113 asynchronously\n",
      "2025-03-13 15:34:10,734 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:10,785 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 751\n",
      "2025-03-13 15:34:10,785 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2976\n",
      "2025-03-13 15:34:10,786 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2976 for 399 questions\n",
      "2025-03-13 15:34:10,786 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2976 asynchronously\n",
      "2025-03-13 15:34:11,925 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:11,969 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5768\n",
      "2025-03-13 15:34:11,969 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6377\n",
      "2025-03-13 15:34:11,969 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6377 for 399 questions\n",
      "2025-03-13 15:34:11,970 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6377 asynchronously\n",
      "2025-03-13 15:34:13,193 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:13,250 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3200\n",
      "2025-03-13 15:34:13,250 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2696\n",
      "2025-03-13 15:34:13,251 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2696 for 399 questions\n",
      "2025-03-13 15:34:13,251 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2696 asynchronously\n",
      "2025-03-13 15:34:14,218 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:14,266 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6856\n",
      "2025-03-13 15:34:14,266 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 394\n",
      "2025-03-13 15:34:14,266 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 394 for 399 questions\n",
      "2025-03-13 15:34:14,267 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 394 asynchronously\n",
      "2025-03-13 15:34:14,367 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:14,426 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5152\n",
      "2025-03-13 15:34:14,426 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4015\n",
      "2025-03-13 15:34:14,426 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4015 for 399 questions\n",
      "2025-03-13 15:34:14,427 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4015 asynchronously\n",
      "2025-03-13 15:34:14,435 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:14,464 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1433\n",
      "2025-03-13 15:34:14,464 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 635\n",
      "2025-03-13 15:34:14,464 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 635 for 399 questions\n",
      "2025-03-13 15:34:14,465 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 635 asynchronously\n",
      "2025-03-13 15:34:14,699 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:14,753 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6256\n",
      "2025-03-13 15:34:14,754 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5791\n",
      "2025-03-13 15:34:14,754 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5791 for 399 questions\n",
      "2025-03-13 15:34:14,754 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5791 asynchronously\n",
      "2025-03-13 15:34:14,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:14,997 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4579\n",
      "2025-03-13 15:34:14,998 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5023\n",
      "2025-03-13 15:34:14,998 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5023 for 399 questions\n",
      "2025-03-13 15:34:14,999 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5023 asynchronously\n",
      "2025-03-13 15:34:15,228 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:15,293 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4194\n",
      "2025-03-13 15:34:15,293 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6507\n",
      "2025-03-13 15:34:15,294 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6507 for 399 questions\n",
      "2025-03-13 15:34:15,294 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6507 asynchronously\n",
      "2025-03-13 15:34:15,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:15,467 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1290\n",
      "2025-03-13 15:34:15,467 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6837\n",
      "2025-03-13 15:34:15,468 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6837 for 399 questions\n",
      "2025-03-13 15:34:15,468 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6837 asynchronously\n",
      "2025-03-13 15:34:15,774 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:15,827 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6890\n",
      "2025-03-13 15:34:15,827 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5287\n",
      "2025-03-13 15:34:15,828 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5287 for 399 questions\n",
      "2025-03-13 15:34:15,828 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5287 asynchronously\n",
      "2025-03-13 15:34:16,264 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:16,305 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5232\n",
      "2025-03-13 15:34:16,306 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3343\n",
      "2025-03-13 15:34:16,306 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3343 for 399 questions\n",
      "2025-03-13 15:34:16,306 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3343 asynchronously\n",
      "2025-03-13 15:34:16,419 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:16,468 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 841\n",
      "2025-03-13 15:34:16,468 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 462\n",
      "2025-03-13 15:34:16,469 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 462 for 399 questions\n",
      "2025-03-13 15:34:16,469 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 462 asynchronously\n",
      "2025-03-13 15:34:17,097 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:17,151 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2190\n",
      "2025-03-13 15:34:17,151 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1702\n",
      "2025-03-13 15:34:17,152 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1702 for 399 questions\n",
      "2025-03-13 15:34:17,152 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1702 asynchronously\n",
      "2025-03-13 15:34:17,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:17,929 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4676\n",
      "2025-03-13 15:34:17,930 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6715\n",
      "2025-03-13 15:34:17,930 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6715 for 399 questions\n",
      "2025-03-13 15:34:17,931 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6715 asynchronously\n",
      "2025-03-13 15:34:18,038 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:18,084 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 119\n",
      "2025-03-13 15:34:18,084 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 147\n",
      "2025-03-13 15:34:18,084 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 147 for 399 questions\n",
      "2025-03-13 15:34:18,085 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 147 asynchronously\n",
      "2025-03-13 15:34:18,155 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:18,194 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 634\n",
      "2025-03-13 15:34:18,194 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 882\n",
      "2025-03-13 15:34:18,194 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 882 for 399 questions\n",
      "2025-03-13 15:34:18,194 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 882 asynchronously\n",
      "2025-03-13 15:34:18,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:18,228 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4493\n",
      "2025-03-13 15:34:18,229 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3503\n",
      "2025-03-13 15:34:18,229 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3503 for 399 questions\n",
      "2025-03-13 15:34:18,229 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3503 asynchronously\n",
      "2025-03-13 15:34:19,238 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:19,313 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1082\n",
      "2025-03-13 15:34:19,314 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6214\n",
      "2025-03-13 15:34:19,314 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6214 for 399 questions\n",
      "2025-03-13 15:34:19,315 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6214 asynchronously\n",
      "2025-03-13 15:34:19,746 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:19,796 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4685\n",
      "2025-03-13 15:34:19,797 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5439\n",
      "2025-03-13 15:34:19,797 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5439 for 399 questions\n",
      "2025-03-13 15:34:19,798 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5439 asynchronously\n",
      "2025-03-13 15:34:20,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:20,404 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3634\n",
      "2025-03-13 15:34:20,404 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5748\n",
      "2025-03-13 15:34:20,404 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5748 for 399 questions\n",
      "2025-03-13 15:34:20,405 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5748 asynchronously\n",
      "2025-03-13 15:34:20,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:20,588 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3235\n",
      "2025-03-13 15:34:20,588 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6345\n",
      "2025-03-13 15:34:20,588 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6345 for 399 questions\n",
      "2025-03-13 15:34:20,589 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6345 asynchronously\n",
      "2025-03-13 15:34:21,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:21,166 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3847\n",
      "2025-03-13 15:34:21,166 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6323\n",
      "2025-03-13 15:34:21,166 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6323 for 399 questions\n",
      "2025-03-13 15:34:21,167 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6323 asynchronously\n",
      "2025-03-13 15:34:21,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:21,270 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1460\n",
      "2025-03-13 15:34:21,270 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3180\n",
      "2025-03-13 15:34:21,270 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3180 for 399 questions\n",
      "2025-03-13 15:34:21,270 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3180 asynchronously\n",
      "2025-03-13 15:34:22,031 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:22,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:22,084 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3699\n",
      "2025-03-13 15:34:22,084 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4574\n",
      "2025-03-13 15:34:22,085 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4574 for 399 questions\n",
      "2025-03-13 15:34:22,085 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4574 asynchronously\n",
      "2025-03-13 15:34:22,119 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2004\n",
      "2025-03-13 15:34:22,119 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4410\n",
      "2025-03-13 15:34:22,119 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4410 for 399 questions\n",
      "2025-03-13 15:34:22,120 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4410 asynchronously\n",
      "2025-03-13 15:34:22,818 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:22,867 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2029\n",
      "2025-03-13 15:34:22,868 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4359\n",
      "2025-03-13 15:34:22,868 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4359 for 399 questions\n",
      "2025-03-13 15:34:22,868 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4359 asynchronously\n",
      "2025-03-13 15:34:23,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:23,059 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 44\n",
      "2025-03-13 15:34:23,059 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5087\n",
      "2025-03-13 15:34:23,059 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5087 for 399 questions\n",
      "2025-03-13 15:34:23,060 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5087 asynchronously\n",
      "2025-03-13 15:34:23,534 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:23,605 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1712\n",
      "2025-03-13 15:34:23,605 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1238\n",
      "2025-03-13 15:34:23,606 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1238 for 399 questions\n",
      "2025-03-13 15:34:23,606 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1238 asynchronously\n",
      "2025-03-13 15:34:24,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:24,086 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5609\n",
      "2025-03-13 15:34:24,086 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3725\n",
      "2025-03-13 15:34:24,086 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3725 for 399 questions\n",
      "2025-03-13 15:34:24,087 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3725 asynchronously\n",
      "2025-03-13 15:34:24,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:24,371 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5176\n",
      "2025-03-13 15:34:24,372 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4096\n",
      "2025-03-13 15:34:24,372 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4096 for 399 questions\n",
      "2025-03-13 15:34:24,372 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4096 asynchronously\n",
      "2025-03-13 15:34:24,405 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:24,437 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2734\n",
      "2025-03-13 15:34:24,437 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4991\n",
      "2025-03-13 15:34:24,437 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4991 for 399 questions\n",
      "2025-03-13 15:34:24,437 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4991 asynchronously\n",
      "2025-03-13 15:34:24,633 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:24,682 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6838\n",
      "2025-03-13 15:34:24,683 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2686\n",
      "2025-03-13 15:34:24,683 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2686 for 399 questions\n",
      "2025-03-13 15:34:24,683 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2686 asynchronously\n",
      "2025-03-13 15:34:26,508 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:26,554 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1859\n",
      "2025-03-13 15:34:26,555 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1362\n",
      "2025-03-13 15:34:26,555 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1362 for 399 questions\n",
      "2025-03-13 15:34:26,555 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1362 asynchronously\n",
      "2025-03-13 15:34:26,637 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:26,669 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:26,671 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4276\n",
      "2025-03-13 15:34:26,671 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 834\n",
      "2025-03-13 15:34:26,671 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 834 for 399 questions\n",
      "2025-03-13 15:34:26,672 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 834 asynchronously\n",
      "2025-03-13 15:34:26,708 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 495\n",
      "2025-03-13 15:34:26,708 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1771\n",
      "2025-03-13 15:34:26,709 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1771 for 399 questions\n",
      "2025-03-13 15:34:26,709 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1771 asynchronously\n",
      "2025-03-13 15:34:28,552 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:28,597 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 394\n",
      "2025-03-13 15:34:28,598 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3194\n",
      "2025-03-13 15:34:28,598 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3194 for 399 questions\n",
      "2025-03-13 15:34:28,598 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3194 asynchronously\n",
      "2025-03-13 15:34:28,859 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:28,860 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:28,888 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2137\n",
      "2025-03-13 15:34:28,888 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5004\n",
      "2025-03-13 15:34:28,888 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5004 for 399 questions\n",
      "2025-03-13 15:34:28,889 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5004 asynchronously\n",
      "2025-03-13 15:34:28,908 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3343\n",
      "2025-03-13 15:34:28,908 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2525\n",
      "2025-03-13 15:34:28,908 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2525 for 399 questions\n",
      "2025-03-13 15:34:28,909 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2525 asynchronously\n",
      "2025-03-13 15:34:28,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:29,033 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 874\n",
      "2025-03-13 15:34:29,034 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1819\n",
      "2025-03-13 15:34:29,034 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1819 for 399 questions\n",
      "2025-03-13 15:34:29,034 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1819 asynchronously\n",
      "2025-03-13 15:34:29,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:29,618 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1778\n",
      "2025-03-13 15:34:29,619 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 311\n",
      "2025-03-13 15:34:29,619 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 311 for 399 questions\n",
      "2025-03-13 15:34:29,619 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 311 asynchronously\n",
      "2025-03-13 15:34:29,742 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:29,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:29,788 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1702\n",
      "2025-03-13 15:34:29,788 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2401\n",
      "2025-03-13 15:34:29,788 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2401 for 399 questions\n",
      "2025-03-13 15:34:29,789 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2401 asynchronously\n",
      "2025-03-13 15:34:29,823 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5023\n",
      "2025-03-13 15:34:29,823 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6234\n",
      "2025-03-13 15:34:29,823 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6234 for 399 questions\n",
      "2025-03-13 15:34:29,823 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6234 asynchronously\n",
      "2025-03-13 15:34:29,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:30,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:30,031 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6507\n",
      "2025-03-13 15:34:30,032 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 864\n",
      "2025-03-13 15:34:30,032 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 864 for 399 questions\n",
      "2025-03-13 15:34:30,033 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 864 asynchronously\n",
      "2025-03-13 15:34:30,060 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5287\n",
      "2025-03-13 15:34:30,060 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6339\n",
      "2025-03-13 15:34:30,060 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6339 for 399 questions\n",
      "2025-03-13 15:34:30,061 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6339 asynchronously\n",
      "2025-03-13 15:34:30,343 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:30,386 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6837\n",
      "2025-03-13 15:34:30,386 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6844\n",
      "2025-03-13 15:34:30,387 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6844 for 399 questions\n",
      "2025-03-13 15:34:30,387 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6844 asynchronously\n",
      "2025-03-13 15:34:31,580 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:31,584 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:31,621 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6377\n",
      "2025-03-13 15:34:31,622 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4266\n",
      "2025-03-13 15:34:31,622 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4266 for 399 questions\n",
      "2025-03-13 15:34:31,622 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4266 asynchronously\n",
      "2025-03-13 15:34:31,648 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2976\n",
      "2025-03-13 15:34:31,649 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3732\n",
      "2025-03-13 15:34:31,649 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3732 for 399 questions\n",
      "2025-03-13 15:34:31,649 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3732 asynchronously\n",
      "2025-03-13 15:34:32,011 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:32,042 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 882\n",
      "2025-03-13 15:34:32,042 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3411\n",
      "2025-03-13 15:34:32,042 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3411 for 399 questions\n",
      "2025-03-13 15:34:32,043 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3411 asynchronously\n",
      "2025-03-13 15:34:32,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:32,651 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:32,661 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:32,690 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4015\n",
      "2025-03-13 15:34:32,691 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6423\n",
      "2025-03-13 15:34:32,691 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6423 for 399 questions\n",
      "2025-03-13 15:34:32,691 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6423 asynchronously\n",
      "2025-03-13 15:34:32,718 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 147\n",
      "2025-03-13 15:34:32,718 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4761\n",
      "2025-03-13 15:34:32,718 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4761 for 399 questions\n",
      "2025-03-13 15:34:32,719 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4761 asynchronously\n",
      "2025-03-13 15:34:32,741 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2696\n",
      "2025-03-13 15:34:32,742 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2670\n",
      "2025-03-13 15:34:32,742 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2670 for 399 questions\n",
      "2025-03-13 15:34:32,743 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2670 asynchronously\n",
      "2025-03-13 15:34:33,673 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:33,724 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6214\n",
      "2025-03-13 15:34:33,724 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6438\n",
      "2025-03-13 15:34:33,725 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6438 for 399 questions\n",
      "2025-03-13 15:34:33,725 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6438 asynchronously\n",
      "2025-03-13 15:34:34,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:34,202 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5791\n",
      "2025-03-13 15:34:34,203 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5992\n",
      "2025-03-13 15:34:34,203 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5992 for 399 questions\n",
      "2025-03-13 15:34:34,204 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5992 asynchronously\n",
      "2025-03-13 15:34:34,491 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:34,495 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:34,549 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 462\n",
      "2025-03-13 15:34:34,550 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4536\n",
      "2025-03-13 15:34:34,550 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4536 for 399 questions\n",
      "2025-03-13 15:34:34,550 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4536 asynchronously\n",
      "2025-03-13 15:34:34,577 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4410\n",
      "2025-03-13 15:34:34,578 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1573\n",
      "2025-03-13 15:34:34,578 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1573 for 399 questions\n",
      "2025-03-13 15:34:34,578 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1573 asynchronously\n",
      "2025-03-13 15:34:34,650 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:34,689 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4113\n",
      "2025-03-13 15:34:34,689 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2384\n",
      "2025-03-13 15:34:34,689 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2384 for 399 questions\n",
      "2025-03-13 15:34:34,690 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2384 asynchronously\n",
      "2025-03-13 15:34:35,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:35,530 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:35,568 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6345\n",
      "2025-03-13 15:34:35,569 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 313\n",
      "2025-03-13 15:34:35,569 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 313 for 399 questions\n",
      "2025-03-13 15:34:35,569 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 313 asynchronously\n",
      "2025-03-13 15:34:35,596 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5087\n",
      "2025-03-13 15:34:35,596 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2212\n",
      "2025-03-13 15:34:35,596 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2212 for 399 questions\n",
      "2025-03-13 15:34:35,597 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2212 asynchronously\n",
      "2025-03-13 15:34:36,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:36,979 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6715\n",
      "2025-03-13 15:34:36,980 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4892\n",
      "2025-03-13 15:34:36,980 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4892 for 399 questions\n",
      "2025-03-13 15:34:36,981 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4892 asynchronously\n",
      "2025-03-13 15:34:37,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:37,467 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:37,486 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:37,495 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4359\n",
      "2025-03-13 15:34:37,496 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3124\n",
      "2025-03-13 15:34:37,496 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3124 for 399 questions\n",
      "2025-03-13 15:34:37,497 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3124 asynchronously\n",
      "2025-03-13 15:34:37,521 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2686\n",
      "2025-03-13 15:34:37,521 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3786\n",
      "2025-03-13 15:34:37,521 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3786 for 399 questions\n",
      "2025-03-13 15:34:37,521 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3786 asynchronously\n",
      "2025-03-13 15:34:37,550 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3503\n",
      "2025-03-13 15:34:37,550 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2983\n",
      "2025-03-13 15:34:37,551 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2983 for 399 questions\n",
      "2025-03-13 15:34:37,551 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2983 asynchronously\n",
      "2025-03-13 15:34:38,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:38,945 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5439\n",
      "2025-03-13 15:34:38,946 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2017\n",
      "2025-03-13 15:34:38,946 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2017 for 399 questions\n",
      "2025-03-13 15:34:38,947 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2017 asynchronously\n",
      "2025-03-13 15:34:38,977 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:39,008 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3725\n",
      "2025-03-13 15:34:39,008 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3760\n",
      "2025-03-13 15:34:39,008 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3760 for 399 questions\n",
      "2025-03-13 15:34:39,009 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3760 asynchronously\n",
      "2025-03-13 15:34:39,034 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:39,119 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 635\n",
      "2025-03-13 15:34:39,119 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3635\n",
      "2025-03-13 15:34:39,119 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3635 for 399 questions\n",
      "2025-03-13 15:34:39,120 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3635 asynchronously\n",
      "2025-03-13 15:34:39,583 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:39,638 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4991\n",
      "2025-03-13 15:34:39,639 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4687\n",
      "2025-03-13 15:34:39,639 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4687 for 399 questions\n",
      "2025-03-13 15:34:39,640 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4687 asynchronously\n",
      "2025-03-13 15:34:39,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:39,695 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3180\n",
      "2025-03-13 15:34:39,695 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2806\n",
      "2025-03-13 15:34:39,695 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2806 for 399 questions\n",
      "2025-03-13 15:34:39,695 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2806 asynchronously\n",
      "2025-03-13 15:34:39,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:39,745 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5748\n",
      "2025-03-13 15:34:39,745 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3053\n",
      "2025-03-13 15:34:39,745 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3053 for 399 questions\n",
      "2025-03-13 15:34:39,745 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3053 asynchronously\n",
      "2025-03-13 15:34:40,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:40,249 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6323\n",
      "2025-03-13 15:34:40,250 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4996\n",
      "2025-03-13 15:34:40,250 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4996 for 399 questions\n",
      "2025-03-13 15:34:40,250 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4996 asynchronously\n",
      "2025-03-13 15:34:40,943 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:40,998 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4574\n",
      "2025-03-13 15:34:40,998 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4589\n",
      "2025-03-13 15:34:40,998 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4589 for 399 questions\n",
      "2025-03-13 15:34:40,999 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4589 asynchronously\n",
      "2025-03-13 15:34:41,524 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:41,582 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 834\n",
      "2025-03-13 15:34:41,582 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4797\n",
      "2025-03-13 15:34:41,583 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4797 for 399 questions\n",
      "2025-03-13 15:34:41,583 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4797 asynchronously\n",
      "2025-03-13 15:34:42,044 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:42,116 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1362\n",
      "2025-03-13 15:34:42,116 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 527\n",
      "2025-03-13 15:34:42,116 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 527 for 399 questions\n",
      "2025-03-13 15:34:42,117 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 527 asynchronously\n",
      "2025-03-13 15:34:43,096 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:43,160 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1238\n",
      "2025-03-13 15:34:43,160 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6613\n",
      "2025-03-13 15:34:43,160 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6613 for 399 questions\n",
      "2025-03-13 15:34:43,161 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6613 asynchronously\n",
      "2025-03-13 15:34:43,503 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:43,508 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:43,554 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5004\n",
      "2025-03-13 15:34:43,555 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4473\n",
      "2025-03-13 15:34:43,555 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4473 for 399 questions\n",
      "2025-03-13 15:34:43,555 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4473 asynchronously\n",
      "2025-03-13 15:34:43,578 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1819\n",
      "2025-03-13 15:34:43,578 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6449\n",
      "2025-03-13 15:34:43,578 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6449 for 399 questions\n",
      "2025-03-13 15:34:43,579 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6449 asynchronously\n",
      "2025-03-13 15:34:44,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:44,070 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4096\n",
      "2025-03-13 15:34:44,070 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6477\n",
      "2025-03-13 15:34:44,071 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6477 for 399 questions\n",
      "2025-03-13 15:34:44,071 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6477 asynchronously\n",
      "2025-03-13 15:34:44,195 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:44,262 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6234\n",
      "2025-03-13 15:34:44,263 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1891\n",
      "2025-03-13 15:34:44,263 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1891 for 399 questions\n",
      "2025-03-13 15:34:44,263 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1891 asynchronously\n",
      "2025-03-13 15:34:44,362 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:44,416 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2401\n",
      "2025-03-13 15:34:44,417 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2272\n",
      "2025-03-13 15:34:44,417 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2272 for 399 questions\n",
      "2025-03-13 15:34:44,417 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2272 asynchronously\n",
      "2025-03-13 15:34:44,655 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:44,707 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2525\n",
      "2025-03-13 15:34:44,707 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 572\n",
      "2025-03-13 15:34:44,707 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 572 for 399 questions\n",
      "2025-03-13 15:34:44,708 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 572 asynchronously\n",
      "2025-03-13 15:34:45,448 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:45,499 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3194\n",
      "2025-03-13 15:34:45,499 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5591\n",
      "2025-03-13 15:34:45,499 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5591 for 399 questions\n",
      "2025-03-13 15:34:45,500 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5591 asynchronously\n",
      "2025-03-13 15:34:45,756 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:45,810 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6423\n",
      "2025-03-13 15:34:45,810 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 532\n",
      "2025-03-13 15:34:45,810 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 532 for 399 questions\n",
      "2025-03-13 15:34:45,810 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 532 asynchronously\n",
      "2025-03-13 15:34:46,150 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:46,201 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4266\n",
      "2025-03-13 15:34:46,201 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5082\n",
      "2025-03-13 15:34:46,202 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5082 for 399 questions\n",
      "2025-03-13 15:34:46,202 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5082 asynchronously\n",
      "2025-03-13 15:34:47,132 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:47,214 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3732\n",
      "2025-03-13 15:34:47,219 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6823\n",
      "2025-03-13 15:34:47,224 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6823 for 399 questions\n",
      "2025-03-13 15:34:47,229 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6823 asynchronously\n",
      "2025-03-13 15:34:47,569 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:47,622 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3411\n",
      "2025-03-13 15:34:47,622 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4568\n",
      "2025-03-13 15:34:47,622 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4568 for 399 questions\n",
      "2025-03-13 15:34:47,623 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4568 asynchronously\n",
      "2025-03-13 15:34:47,758 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:47,797 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2384\n",
      "2025-03-13 15:34:47,798 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1643\n",
      "2025-03-13 15:34:47,798 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1643 for 399 questions\n",
      "2025-03-13 15:34:47,798 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1643 asynchronously\n",
      "2025-03-13 15:34:48,731 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:48,785 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 311\n",
      "2025-03-13 15:34:48,785 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2355\n",
      "2025-03-13 15:34:48,785 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2355 for 399 questions\n",
      "2025-03-13 15:34:48,785 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2355 asynchronously\n",
      "2025-03-13 15:34:49,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:49,165 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6339\n",
      "2025-03-13 15:34:49,165 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5560\n",
      "2025-03-13 15:34:49,166 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5560 for 399 questions\n",
      "2025-03-13 15:34:49,166 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5560 asynchronously\n",
      "2025-03-13 15:34:50,093 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:50,146 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4536\n",
      "2025-03-13 15:34:50,146 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6404\n",
      "2025-03-13 15:34:50,147 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6404 for 399 questions\n",
      "2025-03-13 15:34:50,147 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6404 asynchronously\n",
      "2025-03-13 15:34:50,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:50,402 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:50,411 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:50,429 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6844\n",
      "2025-03-13 15:34:50,429 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3953\n",
      "2025-03-13 15:34:50,430 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3953 for 399 questions\n",
      "2025-03-13 15:34:50,431 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3953 asynchronously\n",
      "2025-03-13 15:34:50,474 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2983\n",
      "2025-03-13 15:34:50,475 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 170\n",
      "2025-03-13 15:34:50,475 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 170 for 399 questions\n",
      "2025-03-13 15:34:50,475 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 170 asynchronously\n",
      "2025-03-13 15:34:50,502 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 313\n",
      "2025-03-13 15:34:50,503 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 98\n",
      "2025-03-13 15:34:50,503 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 98 for 399 questions\n",
      "2025-03-13 15:34:50,504 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 98 asynchronously\n",
      "2025-03-13 15:34:50,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:50,913 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5992\n",
      "2025-03-13 15:34:50,913 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 148\n",
      "2025-03-13 15:34:50,913 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 148 for 399 questions\n",
      "2025-03-13 15:34:50,914 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 148 asynchronously\n",
      "2025-03-13 15:34:51,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:51,998 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3124\n",
      "2025-03-13 15:34:51,999 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5486\n",
      "2025-03-13 15:34:51,999 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5486 for 399 questions\n",
      "2025-03-13 15:34:51,999 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5486 asynchronously\n",
      "2025-03-13 15:34:52,363 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:52,393 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:52,409 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4761\n",
      "2025-03-13 15:34:52,410 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6714\n",
      "2025-03-13 15:34:52,410 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6714 for 399 questions\n",
      "2025-03-13 15:34:52,410 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6714 asynchronously\n",
      "2025-03-13 15:34:52,441 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6438\n",
      "2025-03-13 15:34:52,442 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2585\n",
      "2025-03-13 15:34:52,442 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2585 for 399 questions\n",
      "2025-03-13 15:34:52,442 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2585 asynchronously\n",
      "2025-03-13 15:34:53,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:53,487 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2670\n",
      "2025-03-13 15:34:53,488 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3710\n",
      "2025-03-13 15:34:53,488 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3710 for 399 questions\n",
      "2025-03-13 15:34:53,488 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3710 asynchronously\n",
      "2025-03-13 15:34:53,845 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:53,905 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1771\n",
      "2025-03-13 15:34:53,906 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2819\n",
      "2025-03-13 15:34:53,906 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2819 for 399 questions\n",
      "2025-03-13 15:34:53,907 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2819 asynchronously\n",
      "2025-03-13 15:34:54,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:54,706 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3635\n",
      "2025-03-13 15:34:54,706 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1448\n",
      "2025-03-13 15:34:54,707 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1448 for 399 questions\n",
      "2025-03-13 15:34:54,707 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1448 asynchronously\n",
      "2025-03-13 15:34:54,775 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:54,816 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2017\n",
      "2025-03-13 15:34:54,817 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2178\n",
      "2025-03-13 15:34:54,817 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2178 for 399 questions\n",
      "2025-03-13 15:34:54,817 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2178 asynchronously\n",
      "2025-03-13 15:34:55,381 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:55,426 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2212\n",
      "2025-03-13 15:34:55,426 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4492\n",
      "2025-03-13 15:34:55,426 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4492 for 399 questions\n",
      "2025-03-13 15:34:55,427 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4492 asynchronously\n",
      "2025-03-13 15:34:55,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:56,045 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4996\n",
      "2025-03-13 15:34:56,045 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3207\n",
      "2025-03-13 15:34:56,046 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3207 for 399 questions\n",
      "2025-03-13 15:34:56,046 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3207 asynchronously\n",
      "2025-03-13 15:34:57,128 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:57,196 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3786\n",
      "2025-03-13 15:34:57,197 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4799\n",
      "2025-03-13 15:34:57,197 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4799 for 399 questions\n",
      "2025-03-13 15:34:57,198 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4799 asynchronously\n",
      "2025-03-13 15:34:57,634 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:57,691 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4892\n",
      "2025-03-13 15:34:57,691 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2793\n",
      "2025-03-13 15:34:57,692 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2793 for 399 questions\n",
      "2025-03-13 15:34:57,692 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2793 asynchronously\n",
      "2025-03-13 15:34:57,892 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:57,932 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1573\n",
      "2025-03-13 15:34:57,932 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 980\n",
      "2025-03-13 15:34:57,933 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 980 for 399 questions\n",
      "2025-03-13 15:34:57,933 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 980 asynchronously\n",
      "2025-03-13 15:34:58,091 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:58,137 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1891\n",
      "2025-03-13 15:34:58,138 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 773\n",
      "2025-03-13 15:34:58,138 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 773 for 399 questions\n",
      "2025-03-13 15:34:58,138 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 773 asynchronously\n",
      "2025-03-13 15:34:59,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:59,094 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6613\n",
      "2025-03-13 15:34:59,094 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4730\n",
      "2025-03-13 15:34:59,094 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4730 for 399 questions\n",
      "2025-03-13 15:34:59,095 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4730 asynchronously\n",
      "2025-03-13 15:34:59,333 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:59,391 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3760\n",
      "2025-03-13 15:34:59,392 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1881\n",
      "2025-03-13 15:34:59,392 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1881 for 399 questions\n",
      "2025-03-13 15:34:59,392 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1881 asynchronously\n",
      "2025-03-13 15:34:59,786 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:34:59,838 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6449\n",
      "2025-03-13 15:34:59,838 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4646\n",
      "2025-03-13 15:34:59,838 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4646 for 399 questions\n",
      "2025-03-13 15:34:59,839 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4646 asynchronously\n",
      "2025-03-13 15:35:00,298 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:00,333 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:00,355 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4589\n",
      "2025-03-13 15:35:00,356 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4673\n",
      "2025-03-13 15:35:00,356 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4673 for 399 questions\n",
      "2025-03-13 15:35:00,357 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4673 asynchronously\n",
      "2025-03-13 15:35:00,384 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3053\n",
      "2025-03-13 15:35:00,385 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 31\n",
      "2025-03-13 15:35:00,385 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 31 for 399 questions\n",
      "2025-03-13 15:35:00,386 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 31 asynchronously\n",
      "2025-03-13 15:35:01,116 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:01,166 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4687\n",
      "2025-03-13 15:35:01,167 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3443\n",
      "2025-03-13 15:35:01,167 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3443 for 399 questions\n",
      "2025-03-13 15:35:01,167 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3443 asynchronously\n",
      "2025-03-13 15:35:01,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:01,531 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:01,579 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2806\n",
      "2025-03-13 15:35:01,579 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1361\n",
      "2025-03-13 15:35:01,579 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1361 for 399 questions\n",
      "2025-03-13 15:35:01,580 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1361 asynchronously\n",
      "2025-03-13 15:35:01,605 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4568\n",
      "2025-03-13 15:35:01,605 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3890\n",
      "2025-03-13 15:35:01,605 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3890 for 399 questions\n",
      "2025-03-13 15:35:01,606 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3890 asynchronously\n",
      "2025-03-13 15:35:01,875 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:01,930 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4797\n",
      "2025-03-13 15:35:01,931 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1022\n",
      "2025-03-13 15:35:01,931 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1022 for 399 questions\n",
      "2025-03-13 15:35:01,932 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1022 asynchronously\n",
      "2025-03-13 15:35:02,550 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:02,605 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6823\n",
      "2025-03-13 15:35:02,605 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 318\n",
      "2025-03-13 15:35:02,606 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 318 for 399 questions\n",
      "2025-03-13 15:35:02,606 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 318 asynchronously\n",
      "2025-03-13 15:35:03,041 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:03,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:03,093 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5591\n",
      "2025-03-13 15:35:03,094 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4608\n",
      "2025-03-13 15:35:03,094 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4608 for 399 questions\n",
      "2025-03-13 15:35:03,094 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4608 asynchronously\n",
      "2025-03-13 15:35:03,120 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4473\n",
      "2025-03-13 15:35:03,121 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2087\n",
      "2025-03-13 15:35:03,121 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2087 for 399 questions\n",
      "2025-03-13 15:35:03,121 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2087 asynchronously\n",
      "2025-03-13 15:35:03,151 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:03,184 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6477\n",
      "2025-03-13 15:35:03,185 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1515\n",
      "2025-03-13 15:35:03,185 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1515 for 399 questions\n",
      "2025-03-13 15:35:03,185 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1515 asynchronously\n",
      "2025-03-13 15:35:03,584 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:03,631 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2272\n",
      "2025-03-13 15:35:03,632 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5013\n",
      "2025-03-13 15:35:03,632 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5013 for 399 questions\n",
      "2025-03-13 15:35:03,632 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5013 asynchronously\n",
      "2025-03-13 15:35:03,730 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:03,767 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 572\n",
      "2025-03-13 15:35:03,767 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6084\n",
      "2025-03-13 15:35:03,767 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6084 for 399 questions\n",
      "2025-03-13 15:35:03,768 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6084 asynchronously\n",
      "2025-03-13 15:35:03,839 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:03,883 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1643\n",
      "2025-03-13 15:35:03,883 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2122\n",
      "2025-03-13 15:35:03,884 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2122 for 399 questions\n",
      "2025-03-13 15:35:03,884 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2122 asynchronously\n",
      "2025-03-13 15:35:04,291 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:04,353 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 98\n",
      "2025-03-13 15:35:04,353 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1551\n",
      "2025-03-13 15:35:04,353 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1551 for 399 questions\n",
      "2025-03-13 15:35:04,353 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1551 asynchronously\n",
      "2025-03-13 15:35:04,635 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:04,688 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 864\n",
      "2025-03-13 15:35:04,688 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2933\n",
      "2025-03-13 15:35:04,688 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2933 for 399 questions\n",
      "2025-03-13 15:35:04,689 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2933 asynchronously\n",
      "2025-03-13 15:35:04,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:04,764 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2355\n",
      "2025-03-13 15:35:04,764 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5254\n",
      "2025-03-13 15:35:04,764 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5254 for 399 questions\n",
      "2025-03-13 15:35:04,765 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5254 asynchronously\n",
      "2025-03-13 15:35:04,953 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:04,997 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 532\n",
      "2025-03-13 15:35:04,998 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3902\n",
      "2025-03-13 15:35:04,998 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3902 for 399 questions\n",
      "2025-03-13 15:35:04,998 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3902 asynchronously\n",
      "2025-03-13 15:35:05,155 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:05,212 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5560\n",
      "2025-03-13 15:35:05,213 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4238\n",
      "2025-03-13 15:35:05,213 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4238 for 399 questions\n",
      "2025-03-13 15:35:05,213 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4238 asynchronously\n",
      "2025-03-13 15:35:05,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:05,934 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6714\n",
      "2025-03-13 15:35:05,934 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6958\n",
      "2025-03-13 15:35:05,934 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6958 for 399 questions\n",
      "2025-03-13 15:35:05,935 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6958 asynchronously\n",
      "2025-03-13 15:35:05,948 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:05,982 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6404\n",
      "2025-03-13 15:35:05,983 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3696\n",
      "2025-03-13 15:35:05,983 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3696 for 399 questions\n",
      "2025-03-13 15:35:05,983 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3696 asynchronously\n",
      "2025-03-13 15:35:06,384 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:06,431 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5082\n",
      "2025-03-13 15:35:06,432 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6408\n",
      "2025-03-13 15:35:06,432 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6408 for 399 questions\n",
      "2025-03-13 15:35:06,432 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6408 asynchronously\n",
      "2025-03-13 15:35:07,031 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:07,088 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2819\n",
      "2025-03-13 15:35:07,089 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2898\n",
      "2025-03-13 15:35:07,089 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2898 for 399 questions\n",
      "2025-03-13 15:35:07,089 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2898 asynchronously\n",
      "2025-03-13 15:35:07,875 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:07,931 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 170\n",
      "2025-03-13 15:35:07,932 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2055\n",
      "2025-03-13 15:35:07,932 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2055 for 399 questions\n",
      "2025-03-13 15:35:07,932 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2055 asynchronously\n",
      "2025-03-13 15:35:08,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:08,944 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3207\n",
      "2025-03-13 15:35:08,944 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6618\n",
      "2025-03-13 15:35:08,945 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6618 for 399 questions\n",
      "2025-03-13 15:35:08,945 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6618 asynchronously\n",
      "2025-03-13 15:35:09,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:09,290 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2178\n",
      "2025-03-13 15:35:09,291 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3402\n",
      "2025-03-13 15:35:09,291 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3402 for 399 questions\n",
      "2025-03-13 15:35:09,292 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3402 asynchronously\n",
      "2025-03-13 15:35:09,718 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:09,776 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3953\n",
      "2025-03-13 15:35:09,776 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4441\n",
      "2025-03-13 15:35:09,777 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4441 for 399 questions\n",
      "2025-03-13 15:35:09,777 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4441 asynchronously\n",
      "2025-03-13 15:35:10,038 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:10,104 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 148\n",
      "2025-03-13 15:35:10,104 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 7042\n",
      "2025-03-13 15:35:10,104 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 7042 for 399 questions\n",
      "2025-03-13 15:35:10,105 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 7042 asynchronously\n",
      "2025-03-13 15:35:10,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:10,964 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2793\n",
      "2025-03-13 15:35:10,964 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5816\n",
      "2025-03-13 15:35:10,965 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5816 for 399 questions\n",
      "2025-03-13 15:35:10,965 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5816 asynchronously\n",
      "2025-03-13 15:35:11,452 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:11,509 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 980\n",
      "2025-03-13 15:35:11,510 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3888\n",
      "2025-03-13 15:35:11,510 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3888 for 399 questions\n",
      "2025-03-13 15:35:11,511 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3888 asynchronously\n",
      "2025-03-13 15:35:11,553 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:11,596 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5486\n",
      "2025-03-13 15:35:11,597 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1467\n",
      "2025-03-13 15:35:11,597 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1467 for 399 questions\n",
      "2025-03-13 15:35:11,597 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1467 asynchronously\n",
      "2025-03-13 15:35:11,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:11,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:11,728 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4730\n",
      "2025-03-13 15:35:11,728 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 891\n",
      "2025-03-13 15:35:11,729 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 891 for 399 questions\n",
      "2025-03-13 15:35:11,729 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 891 asynchronously\n",
      "2025-03-13 15:35:11,756 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4799\n",
      "2025-03-13 15:35:11,756 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6576\n",
      "2025-03-13 15:35:11,757 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6576 for 399 questions\n",
      "2025-03-13 15:35:11,757 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6576 asynchronously\n",
      "2025-03-13 15:35:12,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:12,459 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 527\n",
      "2025-03-13 15:35:12,459 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 287\n",
      "2025-03-13 15:35:12,460 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 287 for 399 questions\n",
      "2025-03-13 15:35:12,460 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 287 asynchronously\n",
      "2025-03-13 15:35:12,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:12,923 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2585\n",
      "2025-03-13 15:35:12,923 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5151\n",
      "2025-03-13 15:35:12,924 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5151 for 399 questions\n",
      "2025-03-13 15:35:12,924 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5151 asynchronously\n",
      "2025-03-13 15:35:13,999 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:14,047 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 31\n",
      "2025-03-13 15:35:14,048 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 14\n",
      "2025-03-13 15:35:14,048 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 14 for 399 questions\n",
      "2025-03-13 15:35:14,049 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 14 asynchronously\n",
      "2025-03-13 15:35:14,634 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:14,687 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 773\n",
      "2025-03-13 15:35:14,688 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4911\n",
      "2025-03-13 15:35:14,688 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4911 for 399 questions\n",
      "2025-03-13 15:35:14,688 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4911 asynchronously\n",
      "2025-03-13 15:35:15,014 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:15,063 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1881\n",
      "2025-03-13 15:35:15,064 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 7016\n",
      "2025-03-13 15:35:15,064 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 7016 for 399 questions\n",
      "2025-03-13 15:35:15,065 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 7016 asynchronously\n",
      "2025-03-13 15:35:15,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:15,509 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4646\n",
      "2025-03-13 15:35:15,510 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 875\n",
      "2025-03-13 15:35:15,510 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 875 for 399 questions\n",
      "2025-03-13 15:35:15,510 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 875 asynchronously\n",
      "2025-03-13 15:35:15,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:15,935 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1448\n",
      "2025-03-13 15:35:15,936 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6784\n",
      "2025-03-13 15:35:15,936 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6784 for 399 questions\n",
      "2025-03-13 15:35:15,937 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6784 asynchronously\n",
      "2025-03-13 15:35:16,579 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:16,629 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3710\n",
      "2025-03-13 15:35:16,630 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3234\n",
      "2025-03-13 15:35:16,630 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3234 for 399 questions\n",
      "2025-03-13 15:35:16,631 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3234 asynchronously\n",
      "2025-03-13 15:35:16,646 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:16,676 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4492\n",
      "2025-03-13 15:35:16,676 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6867\n",
      "2025-03-13 15:35:16,677 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6867 for 399 questions\n",
      "2025-03-13 15:35:16,677 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6867 asynchronously\n",
      "2025-03-13 15:35:16,802 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:16,839 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 318\n",
      "2025-03-13 15:35:16,839 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4739\n",
      "2025-03-13 15:35:16,839 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4739 for 399 questions\n",
      "2025-03-13 15:35:16,840 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4739 asynchronously\n",
      "2025-03-13 15:35:17,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:17,087 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4673\n",
      "2025-03-13 15:35:17,087 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2873\n",
      "2025-03-13 15:35:17,087 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2873 for 399 questions\n",
      "2025-03-13 15:35:17,088 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2873 asynchronously\n",
      "2025-03-13 15:35:17,603 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:17,657 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2087\n",
      "2025-03-13 15:35:17,658 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6822\n",
      "2025-03-13 15:35:17,658 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6822 for 399 questions\n",
      "2025-03-13 15:35:17,658 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6822 asynchronously\n",
      "2025-03-13 15:35:17,801 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:17,848 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3443\n",
      "2025-03-13 15:35:17,849 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2591\n",
      "2025-03-13 15:35:17,849 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2591 for 399 questions\n",
      "2025-03-13 15:35:17,849 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2591 asynchronously\n",
      "2025-03-13 15:35:18,025 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:18,071 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1361\n",
      "2025-03-13 15:35:18,071 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2588\n",
      "2025-03-13 15:35:18,071 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2588 for 399 questions\n",
      "2025-03-13 15:35:18,072 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2588 asynchronously\n",
      "2025-03-13 15:35:18,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:18,578 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4608\n",
      "2025-03-13 15:35:18,579 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4807\n",
      "2025-03-13 15:35:18,579 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4807 for 399 questions\n",
      "2025-03-13 15:35:18,579 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4807 asynchronously\n",
      "2025-03-13 15:35:19,555 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:19,616 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1551\n",
      "2025-03-13 15:35:19,617 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1132\n",
      "2025-03-13 15:35:19,617 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1132 for 399 questions\n",
      "2025-03-13 15:35:19,618 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1132 asynchronously\n",
      "2025-03-13 15:35:20,780 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:20,830 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6084\n",
      "2025-03-13 15:35:20,830 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6003\n",
      "2025-03-13 15:35:20,831 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6003 for 399 questions\n",
      "2025-03-13 15:35:20,831 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6003 asynchronously\n",
      "2025-03-13 15:35:21,326 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:21,384 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1022\n",
      "2025-03-13 15:35:21,384 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5257\n",
      "2025-03-13 15:35:21,385 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5257 for 399 questions\n",
      "2025-03-13 15:35:21,385 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5257 asynchronously\n",
      "2025-03-13 15:35:21,610 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:21,651 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4238\n",
      "2025-03-13 15:35:21,651 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1216\n",
      "2025-03-13 15:35:21,651 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1216 for 399 questions\n",
      "2025-03-13 15:35:21,651 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1216 asynchronously\n",
      "2025-03-13 15:35:21,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:21,753 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2122\n",
      "2025-03-13 15:35:21,753 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2235\n",
      "2025-03-13 15:35:21,753 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2235 for 399 questions\n",
      "2025-03-13 15:35:21,753 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2235 asynchronously\n",
      "2025-03-13 15:35:22,094 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:22,145 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5013\n",
      "2025-03-13 15:35:22,145 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5431\n",
      "2025-03-13 15:35:22,145 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5431 for 399 questions\n",
      "2025-03-13 15:35:22,146 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5431 asynchronously\n",
      "2025-03-13 15:35:22,153 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:22,190 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3890\n",
      "2025-03-13 15:35:22,191 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1281\n",
      "2025-03-13 15:35:22,191 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1281 for 399 questions\n",
      "2025-03-13 15:35:22,191 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1281 asynchronously\n",
      "2025-03-13 15:35:22,548 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:22,620 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5254\n",
      "2025-03-13 15:35:22,621 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1014\n",
      "2025-03-13 15:35:22,621 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1014 for 399 questions\n",
      "2025-03-13 15:35:22,621 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1014 asynchronously\n",
      "2025-03-13 15:35:22,713 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:22,749 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3902\n",
      "2025-03-13 15:35:22,750 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5225\n",
      "2025-03-13 15:35:22,750 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5225 for 399 questions\n",
      "2025-03-13 15:35:22,751 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5225 asynchronously\n",
      "2025-03-13 15:35:23,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:23,389 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3696\n",
      "2025-03-13 15:35:23,390 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5867\n",
      "2025-03-13 15:35:23,390 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5867 for 399 questions\n",
      "2025-03-13 15:35:23,391 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5867 asynchronously\n",
      "2025-03-13 15:35:23,966 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:24,028 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1515\n",
      "2025-03-13 15:35:24,029 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6437\n",
      "2025-03-13 15:35:24,029 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6437 for 399 questions\n",
      "2025-03-13 15:35:24,029 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6437 asynchronously\n",
      "2025-03-13 15:35:25,074 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:25,118 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3402\n",
      "2025-03-13 15:35:25,118 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1597\n",
      "2025-03-13 15:35:25,118 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1597 for 399 questions\n",
      "2025-03-13 15:35:25,119 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1597 asynchronously\n",
      "2025-03-13 15:35:25,134 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:25,161 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2933\n",
      "2025-03-13 15:35:25,161 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2805\n",
      "2025-03-13 15:35:25,162 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2805 for 399 questions\n",
      "2025-03-13 15:35:25,162 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2805 asynchronously\n",
      "2025-03-13 15:35:25,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:25,240 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2898\n",
      "2025-03-13 15:35:25,240 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3039\n",
      "2025-03-13 15:35:25,240 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3039 for 399 questions\n",
      "2025-03-13 15:35:25,241 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3039 asynchronously\n",
      "2025-03-13 15:35:25,368 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:25,410 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2055\n",
      "2025-03-13 15:35:25,410 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4002\n",
      "2025-03-13 15:35:25,411 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4002 for 399 questions\n",
      "2025-03-13 15:35:25,411 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4002 asynchronously\n",
      "2025-03-13 15:35:26,307 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:26,314 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:26,365 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6618\n",
      "2025-03-13 15:35:26,366 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6367\n",
      "2025-03-13 15:35:26,366 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6367 for 399 questions\n",
      "2025-03-13 15:35:26,366 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6367 asynchronously\n",
      "2025-03-13 15:35:26,399 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6408\n",
      "2025-03-13 15:35:26,400 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5690\n",
      "2025-03-13 15:35:26,400 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5690 for 399 questions\n",
      "2025-03-13 15:35:26,400 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5690 asynchronously\n",
      "2025-03-13 15:35:26,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:26,937 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 891\n",
      "2025-03-13 15:35:26,937 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5803\n",
      "2025-03-13 15:35:26,938 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5803 for 399 questions\n",
      "2025-03-13 15:35:26,938 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5803 asynchronously\n",
      "2025-03-13 15:35:28,560 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:28,613 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4441\n",
      "2025-03-13 15:35:28,614 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5006\n",
      "2025-03-13 15:35:28,614 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5006 for 399 questions\n",
      "2025-03-13 15:35:28,614 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5006 asynchronously\n",
      "2025-03-13 15:35:29,074 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:29,129 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 287\n",
      "2025-03-13 15:35:29,129 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1314\n",
      "2025-03-13 15:35:29,129 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1314 for 399 questions\n",
      "2025-03-13 15:35:29,130 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1314 asynchronously\n",
      "2025-03-13 15:35:29,483 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:29,489 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:29,511 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:29,547 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 7016\n",
      "2025-03-13 15:35:29,547 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5362\n",
      "2025-03-13 15:35:29,547 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5362 for 399 questions\n",
      "2025-03-13 15:35:29,548 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5362 asynchronously\n",
      "2025-03-13 15:35:29,582 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4911\n",
      "2025-03-13 15:35:29,583 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2065\n",
      "2025-03-13 15:35:29,583 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2065 for 399 questions\n",
      "2025-03-13 15:35:29,583 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2065 asynchronously\n",
      "2025-03-13 15:35:29,609 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6576\n",
      "2025-03-13 15:35:29,609 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6608\n",
      "2025-03-13 15:35:29,610 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6608 for 399 questions\n",
      "2025-03-13 15:35:29,610 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6608 asynchronously\n",
      "2025-03-13 15:35:31,198 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:31,250 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3888\n",
      "2025-03-13 15:35:31,250 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2655\n",
      "2025-03-13 15:35:31,250 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2655 for 399 questions\n",
      "2025-03-13 15:35:31,251 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2655 asynchronously\n",
      "2025-03-13 15:35:31,393 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:31,440 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 14\n",
      "2025-03-13 15:35:31,441 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3597\n",
      "2025-03-13 15:35:31,441 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3597 for 399 questions\n",
      "2025-03-13 15:35:31,441 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3597 asynchronously\n",
      "2025-03-13 15:35:31,530 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:31,570 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3234\n",
      "2025-03-13 15:35:32,961 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:32,968 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:33,016 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6784\n",
      "2025-03-13 15:35:33,053 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6958\n",
      "2025-03-13 15:35:33,578 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:33,593 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:33,596 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:33,637 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2591\n",
      "2025-03-13 15:35:33,663 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2873\n",
      "2025-03-13 15:35:33,688 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4739\n",
      "2025-03-13 15:35:33,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:33,819 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2588\n",
      "2025-03-13 15:35:33,926 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:33,963 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5151\n",
      "2025-03-13 15:35:33,992 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:34,034 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6822\n",
      "2025-03-13 15:35:34,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:34,187 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6003\n",
      "2025-03-13 15:35:34,346 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:34,391 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 7042\n",
      "2025-03-13 15:35:34,729 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:34,787 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5257\n",
      "2025-03-13 15:35:35,728 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:35,784 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5431\n",
      "2025-03-13 15:35:35,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:35,831 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1132\n",
      "2025-03-13 15:35:36,050 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:36,107 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4807\n",
      "2025-03-13 15:35:36,190 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:36,235 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1014\n",
      "2025-03-13 15:35:36,855 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:36,915 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1467\n",
      "2025-03-13 15:35:37,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:37,983 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5816\n",
      "2025-03-13 15:35:38,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:38,114 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1281\n",
      "2025-03-13 15:35:38,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:38,270 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6867\n",
      "2025-03-13 15:35:38,304 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:38,334 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:38,370 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 875\n",
      "2025-03-13 15:35:38,394 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1216\n",
      "2025-03-13 15:35:38,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:38,944 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5225\n",
      "2025-03-13 15:35:39,084 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:39,128 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1597\n",
      "2025-03-13 15:35:39,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:39,952 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5867\n",
      "2025-03-13 15:35:40,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:40,392 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5690\n",
      "2025-03-13 15:35:41,434 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:41,476 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5803\n",
      "2025-03-13 15:35:41,580 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:41,628 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2235\n",
      "2025-03-13 15:35:42,690 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:42,722 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4002\n",
      "2025-03-13 15:35:43,000 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:43,064 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6437\n",
      "2025-03-13 15:35:44,024 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:44,078 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6367\n",
      "2025-03-13 15:35:44,432 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:44,483 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3039\n",
      "2025-03-13 15:35:45,559 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:45,606 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5362\n",
      "2025-03-13 15:35:45,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:45,782 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5006\n",
      "2025-03-13 15:35:46,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:46,841 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6608\n",
      "2025-03-13 15:35:46,992 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:46,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:47,037 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3597\n",
      "2025-03-13 15:35:47,064 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2805\n",
      "2025-03-13 15:35:47,300 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:47,354 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1314\n",
      "2025-03-13 15:35:48,939 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:48,992 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2065\n",
      "2025-03-13 15:35:50,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:35:50,424 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2655\n"
     ]
    }
   ],
   "source": [
    "NUM_EXTRACT = 400\n",
    "patient_concepts_subset = {str(idx): patient_concepts[str(idx)] for idx in train_idxs[:NUM_EXTRACT]}\n",
    "async_processor.patient_notes = {str(idx): patient_notes[str(idx)] for idx in train_idxs[:NUM_EXTRACT]}\n",
    "\n",
    "patient_answers = await async_processor._generate_answers_async(\n",
    "    patient_concepts=patient_concepts_subset,\n",
    "    topic_questions=all_topic_questions,\n",
    "    answer_generator=answer_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create topic matrix\n",
    "topic_matrix = answer_generator.create_topic_matrix(patient_answers)\n",
    "\n",
    "# Create matrix DataFrames (always do this even if not saving)\n",
    "binary_matrix_df = MatrixBuilder.create_binary_matrix(topic_matrix)\n",
    "probability_matrix_df = MatrixBuilder.create_probability_matrix(\n",
    "    topic_matrix\n",
    ")\n",
    "\n",
    "# Create return dictionary with DataFrames\n",
    "results = {\n",
    "    \"binary_matrix_df\": binary_matrix_df,\n",
    "    \"probability_matrix_df\": probability_matrix_df,\n",
    "    \"topic_matrix\": topic_matrix,\n",
    "    \"topics\": topics,\n",
    "    \"topic_questions\": all_topic_questions,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"exp_mimic/_output/train.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"exp_mimic/_output/train.pkl\", \"rb\") as f:\n",
    "    train_results = pickle.load(f)\n",
    "    probability_matrix_df = train_results['probability_matrix_df']\n",
    "    all_topic_questions = train_results['topic_questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fake labels\n",
    "COEF = 4\n",
    "true_prob = 1/(1 + np.exp(-(\n",
    "    # -100 +\n",
    "    llm_extract_df.label_employment_False * COEF + llm_extract_df.label_housing_False * COEF + (llm_extract_df.label_alcohol_Past + llm_extract_df.label_alcohol_Present) * COEF\n",
    "    + (llm_extract_df.label_tobacco_Past + llm_extract_df.label_tobacco_Present) * COEF\n",
    "    + (llm_extract_df.label_drugs_Past + llm_extract_df.label_drugs_Present) * (COEF + 1)\n",
    "    )))\n",
    "llm_extract_df['y'] =  np.random.binomial(n=1, p=true_prob, size=llm_extract_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label_community_present', 'label_community_absent', 'label_education',\n",
       "       'label_employment_False', 'label_employment_None',\n",
       "       'label_employment_True', 'label_housing_False', 'label_housing_None',\n",
       "       'label_housing_True', 'label_alcohol_Never', 'label_alcohol_None',\n",
       "       'label_alcohol_Past', 'label_alcohol_Present', 'label_alcohol_Unsure',\n",
       "       'label_tobacco_Never', 'label_tobacco_None', 'label_tobacco_Past',\n",
       "       'label_tobacco_Present', 'label_tobacco_Unsure', 'label_drugs_Never',\n",
       "       'label_drugs_None', 'label_drugs_Past', 'label_drugs_Present',\n",
       "       'label_drugs_Unsure', 'sentence', 'llm_output', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_extract_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=10, n_jobs=5, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegressionCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\">?<span>Documentation for LogisticRegressionCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegressionCV(cv=10, n_jobs=5, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(cv=10, n_jobs=5, solver='saga')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EXTRACT = 400\n",
    "lr = LogisticRegressionCV(penalty=\"l2\", solver=\"saga\", cv=10, n_jobs=5) #, l1_ratios=[0.1,.9])\n",
    "lr.fit(probability_matrix_df, llm_extract_df.y.iloc[train_idxs[:NUM_EXTRACT]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.261716</td>\n",
       "      <td>1.261716</td>\n",
       "      <td>Is the patient retired?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.916829</td>\n",
       "      <td>0.916829</td>\n",
       "      <td>Is the patient an elderly senior adult?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.815470</td>\n",
       "      <td>0.815470</td>\n",
       "      <td>Is the patient a smoker?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.657332</td>\n",
       "      <td>0.657332</td>\n",
       "      <td>Is the patient consuming alcohol?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.617676</td>\n",
       "      <td>0.617676</td>\n",
       "      <td>Does the patient have unhealthy lifestyle fact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.597225</td>\n",
       "      <td>0.597225</td>\n",
       "      <td>Is the patient coughing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.584264</td>\n",
       "      <td>0.584264</td>\n",
       "      <td>Is Lasix (furosemide) being given to the patient?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>-0.576725</td>\n",
       "      <td>0.576725</td>\n",
       "      <td>Is the patient responsive and mobile?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.533678</td>\n",
       "      <td>0.533678</td>\n",
       "      <td>Is the patient drug-free?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.490400</td>\n",
       "      <td>0.490400</td>\n",
       "      <td>Does the patient have COPD?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.486223</td>\n",
       "      <td>0.486223</td>\n",
       "      <td>Is the patient conscious?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.479834</td>\n",
       "      <td>0.479834</td>\n",
       "      <td>Is the patient in an intensive care unit?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.478043</td>\n",
       "      <td>0.478043</td>\n",
       "      <td>Is the patient consuming alcohol?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-0.470812</td>\n",
       "      <td>0.470812</td>\n",
       "      <td>Has the patient had an echocardiogram?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.466568</td>\n",
       "      <td>0.466568</td>\n",
       "      <td>Does the patient have high cholesterol?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.464638</td>\n",
       "      <td>0.464638</td>\n",
       "      <td>Is the patient abstinent from substances?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.460945</td>\n",
       "      <td>0.460945</td>\n",
       "      <td>Has the patient visited the ED?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.412843</td>\n",
       "      <td>0.412843</td>\n",
       "      <td>Is the patient married?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.406688</td>\n",
       "      <td>0.406688</td>\n",
       "      <td>Is the patient alert?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.398240</td>\n",
       "      <td>0.398240</td>\n",
       "      <td>Is the patient currently unemployed?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coef  abs_coef                                           question\n",
       "104  1.261716  1.261716                            Is the patient retired?\n",
       "0   -0.916829  0.916829            Is the patient an elderly senior adult?\n",
       "180  0.815470  0.815470                           Is the patient a smoker?\n",
       "4    0.657332  0.657332                  Is the patient consuming alcohol?\n",
       "26   0.617676  0.617676  Does the patient have unhealthy lifestyle fact...\n",
       "58   0.597225  0.597225                           Is the patient coughing?\n",
       "203  0.584264  0.584264  Is Lasix (furosemide) being given to the patient?\n",
       "220 -0.576725  0.576725              Is the patient responsive and mobile?\n",
       "12  -0.533678  0.533678                          Is the patient drug-free?\n",
       "126  0.490400  0.490400                        Does the patient have COPD?\n",
       "112  0.486223  0.486223                          Is the patient conscious?\n",
       "50  -0.479834  0.479834          Is the patient in an intensive care unit?\n",
       "60   0.478043  0.478043                  Is the patient consuming alcohol?\n",
       "191 -0.470812  0.470812             Has the patient had an echocardiogram?\n",
       "94   0.466568  0.466568            Does the patient have high cholesterol?\n",
       "75  -0.464638  0.464638          Is the patient abstinent from substances?\n",
       "131  0.460945  0.460945                    Has the patient visited the ED?\n",
       "14   0.412843  0.412843                            Is the patient married?\n",
       "271  0.406688  0.406688                              Is the patient alert?\n",
       "22   0.398240  0.398240               Is the patient currently unemployed?"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    \"coef\": lr.coef_[0],\n",
    "    \"abs_coef\": np.abs(lr.coef_[0]),\n",
    "    \"question\": [topic_q.question for topic_q in all_topic_questions]\n",
    "})\n",
    "coef_df.sort_values(by=\"abs_coef\", ascending=False).head(20)\n",
    "# print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_import</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031660</td>\n",
       "      <td>Is the patient an elderly senior adult?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.021260</td>\n",
       "      <td>Is the patient retired?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.020510</td>\n",
       "      <td>Is the patient consuming alcohol?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.016481</td>\n",
       "      <td>Is the patient cohabitating with someone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.015763</td>\n",
       "      <td>Does the patient have unhealthy lifestyle fact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015108</td>\n",
       "      <td>Is the patient consuming alcohol?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014113</td>\n",
       "      <td>Is the patient a woman?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.013002</td>\n",
       "      <td>Does the patient have children?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0.012679</td>\n",
       "      <td>Is the patient's sex biological?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.012449</td>\n",
       "      <td>Is the patient drug-free?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.011901</td>\n",
       "      <td>Is the patient married?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.011563</td>\n",
       "      <td>Is the patient experiencing diarrhea?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.011532</td>\n",
       "      <td>Is the patient being treated with antibiotics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.011249</td>\n",
       "      <td>Is the patient abstinent from substances?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.011226</td>\n",
       "      <td>Is the patient responsive and mobile?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.011163</td>\n",
       "      <td>Has the patient visited the ED?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.011118</td>\n",
       "      <td>Is the patient feeling fatigued?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.011116</td>\n",
       "      <td>Is there a clinical report available for the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.010987</td>\n",
       "      <td>Is the patient conscious?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.010979</td>\n",
       "      <td>Is the patient currently unemployed?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_import                                           question\n",
       "0       0.031660            Is the patient an elderly senior adult?\n",
       "104     0.021260                            Is the patient retired?\n",
       "60      0.020510                  Is the patient consuming alcohol?\n",
       "61      0.016481          Is the patient cohabitating with someone?\n",
       "26      0.015763  Does the patient have unhealthy lifestyle fact...\n",
       "4       0.015108                  Is the patient consuming alcohol?\n",
       "2       0.014113                            Is the patient a woman?\n",
       "45      0.013002                    Does the patient have children?\n",
       "367     0.012679                   Is the patient's sex biological?\n",
       "12      0.012449                          Is the patient drug-free?\n",
       "14      0.011901                            Is the patient married?\n",
       "33      0.011563              Is the patient experiencing diarrhea?\n",
       "16      0.011532  Is the patient being treated with antibiotics ...\n",
       "75      0.011249          Is the patient abstinent from substances?\n",
       "220     0.011226              Is the patient responsive and mobile?\n",
       "131     0.011163                    Has the patient visited the ED?\n",
       "38      0.011118                   Is the patient feeling fatigued?\n",
       "125     0.011116  Is there a clinical report available for the p...\n",
       "112     0.010987                          Is the patient conscious?\n",
       "22      0.010979               Is the patient currently unemployed?"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=5)\n",
    "rf.fit(probability_matrix_df, llm_extract_df.y.iloc[train_idxs[:NUM_EXTRACT]])\n",
    "rf_df = pd.DataFrame({\n",
    "    \"feat_import\": rf.feature_importances_,\n",
    "    \"question\": [topic_q.question for topic_q in all_topic_questions]\n",
    "})\n",
    "rf_df.sort_values(by=\"feat_import\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_import</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.116339</td>\n",
       "      <td>Is the patient retired?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090566</td>\n",
       "      <td>Is the patient an elderly senior adult?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088487</td>\n",
       "      <td>Is the patient consuming alcohol?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.058740</td>\n",
       "      <td>Does the patient have unhealthy lifestyle fact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.030939</td>\n",
       "      <td>Is the patient a smoker?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.026064</td>\n",
       "      <td>Is the patient experiencing self-harm or suici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025070</td>\n",
       "      <td>Is the patient a woman?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.020435</td>\n",
       "      <td>Did the onset of symptoms occur suddenly?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.020214</td>\n",
       "      <td>Is the patient's condition deteriorating?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.020065</td>\n",
       "      <td>Has the patient denied substance use?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.019024</td>\n",
       "      <td>Is there swelling in the leg?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.018780</td>\n",
       "      <td>Is the patient drug-free?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.017801</td>\n",
       "      <td>Does the patient have a documented social hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.015186</td>\n",
       "      <td>Is the patient conscious?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.013756</td>\n",
       "      <td>Does the patient have tachycardia?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.013704</td>\n",
       "      <td>Is the patient feeling fatigued?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012997</td>\n",
       "      <td>Is the patient experiencing muscle pain?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.012593</td>\n",
       "      <td>Is there fluid retention in the patient?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.012306</td>\n",
       "      <td>Is the patient coughing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.012261</td>\n",
       "      <td>Is the patient alert?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_import                                           question\n",
       "104     0.116339                            Is the patient retired?\n",
       "0       0.090566            Is the patient an elderly senior adult?\n",
       "4       0.088487                  Is the patient consuming alcohol?\n",
       "26      0.058740  Does the patient have unhealthy lifestyle fact...\n",
       "180     0.030939                           Is the patient a smoker?\n",
       "260     0.026064  Is the patient experiencing self-harm or suici...\n",
       "2       0.025070                            Is the patient a woman?\n",
       "211     0.020435          Did the onset of symptoms occur suddenly?\n",
       "72      0.020214          Is the patient's condition deteriorating?\n",
       "118     0.020065              Has the patient denied substance use?\n",
       "59      0.019024                      Is there swelling in the leg?\n",
       "12      0.018780                          Is the patient drug-free?\n",
       "7       0.017801  Does the patient have a documented social hist...\n",
       "112     0.015186                          Is the patient conscious?\n",
       "18      0.013756                 Does the patient have tachycardia?\n",
       "38      0.013704                   Is the patient feeling fatigued?\n",
       "10      0.012997           Is the patient experiencing muscle pain?\n",
       "55      0.012593           Is there fluid retention in the patient?\n",
       "58      0.012306                           Is the patient coughing?\n",
       "271     0.012261                              Is the patient alert?"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(probability_matrix_df, llm_extract_df.y.iloc[train_idxs[:NUM_EXTRACT]])\n",
    "gb_df = pd.DataFrame({\n",
    "    \"feat_import\": gb.feature_importances_,\n",
    "    \"question\": [topic_q.question for topic_q in all_topic_questions]\n",
    "})\n",
    "gb_df.sort_values(by=\"feat_import\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 16:02:45,658 - text_topic_extraction.text_topic_processor - INFO - Generating answers for 400 patients and 399 questions\n",
      "2025-03-13 16:02:45,660 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3276\n",
      "2025-03-13 16:02:45,660 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3276 for 399 questions\n",
      "2025-03-13 16:02:45,661 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3276 asynchronously\n",
      "2025-03-13 16:02:45,661 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6688\n",
      "2025-03-13 16:02:45,662 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6688 for 399 questions\n",
      "2025-03-13 16:02:45,662 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6688 asynchronously\n",
      "2025-03-13 16:02:45,662 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5079\n",
      "2025-03-13 16:02:45,663 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5079 for 399 questions\n",
      "2025-03-13 16:02:45,663 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5079 asynchronously\n",
      "2025-03-13 16:02:45,664 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3534\n",
      "2025-03-13 16:02:45,664 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3534 for 399 questions\n",
      "2025-03-13 16:02:45,664 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3534 asynchronously\n",
      "2025-03-13 16:02:45,664 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5218\n",
      "2025-03-13 16:02:45,665 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5218 for 399 questions\n",
      "2025-03-13 16:02:45,665 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5218 asynchronously\n",
      "2025-03-13 16:02:45,665 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2475\n",
      "2025-03-13 16:02:45,665 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2475 for 399 questions\n",
      "2025-03-13 16:02:45,666 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2475 asynchronously\n",
      "2025-03-13 16:02:45,666 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4696\n",
      "2025-03-13 16:02:45,667 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4696 for 399 questions\n",
      "2025-03-13 16:02:45,667 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4696 asynchronously\n",
      "2025-03-13 16:02:45,668 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6949\n",
      "2025-03-13 16:02:45,668 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6949 for 399 questions\n",
      "2025-03-13 16:02:45,668 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6949 asynchronously\n",
      "2025-03-13 16:02:45,668 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2563\n",
      "2025-03-13 16:02:45,669 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2563 for 399 questions\n",
      "2025-03-13 16:02:45,669 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2563 asynchronously\n",
      "2025-03-13 16:02:45,669 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1946\n",
      "2025-03-13 16:02:45,670 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1946 for 399 questions\n",
      "2025-03-13 16:02:45,670 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1946 asynchronously\n",
      "2025-03-13 16:02:45,671 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6413\n",
      "2025-03-13 16:02:45,671 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6413 for 399 questions\n",
      "2025-03-13 16:02:45,672 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6413 asynchronously\n",
      "2025-03-13 16:02:45,672 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5847\n",
      "2025-03-13 16:02:45,672 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5847 for 399 questions\n",
      "2025-03-13 16:02:45,672 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5847 asynchronously\n",
      "2025-03-13 16:02:45,673 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3222\n",
      "2025-03-13 16:02:45,673 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3222 for 399 questions\n",
      "2025-03-13 16:02:45,673 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3222 asynchronously\n",
      "2025-03-13 16:02:45,674 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6717\n",
      "2025-03-13 16:02:45,674 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6717 for 399 questions\n",
      "2025-03-13 16:02:45,674 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6717 asynchronously\n",
      "2025-03-13 16:02:45,675 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 33\n",
      "2025-03-13 16:02:45,675 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 33 for 399 questions\n",
      "2025-03-13 16:02:45,675 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 33 asynchronously\n",
      "2025-03-13 16:02:45,676 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4055\n",
      "2025-03-13 16:02:45,676 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4055 for 399 questions\n",
      "2025-03-13 16:02:45,676 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4055 asynchronously\n",
      "2025-03-13 16:02:45,676 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2890\n",
      "2025-03-13 16:02:45,676 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2890 for 399 questions\n",
      "2025-03-13 16:02:45,676 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2890 asynchronously\n",
      "2025-03-13 16:02:45,677 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1835\n",
      "2025-03-13 16:02:45,677 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1835 for 399 questions\n",
      "2025-03-13 16:02:45,677 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1835 asynchronously\n",
      "2025-03-13 16:02:45,677 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6991\n",
      "2025-03-13 16:02:45,677 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6991 for 399 questions\n",
      "2025-03-13 16:02:45,678 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6991 asynchronously\n",
      "2025-03-13 16:02:45,678 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2078\n",
      "2025-03-13 16:02:45,679 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2078 for 399 questions\n",
      "2025-03-13 16:02:45,679 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2078 asynchronously\n",
      "2025-03-13 16:02:45,680 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4649\n",
      "2025-03-13 16:02:45,680 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4649 for 399 questions\n",
      "2025-03-13 16:02:45,680 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4649 asynchronously\n",
      "2025-03-13 16:02:45,680 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 976\n",
      "2025-03-13 16:02:45,681 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 976 for 399 questions\n",
      "2025-03-13 16:02:45,681 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 976 asynchronously\n",
      "2025-03-13 16:02:45,682 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6990\n",
      "2025-03-13 16:02:45,682 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6990 for 399 questions\n",
      "2025-03-13 16:02:45,682 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6990 asynchronously\n",
      "2025-03-13 16:02:45,683 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1722\n",
      "2025-03-13 16:02:45,683 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1722 for 399 questions\n",
      "2025-03-13 16:02:45,683 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1722 asynchronously\n",
      "2025-03-13 16:02:45,683 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3517\n",
      "2025-03-13 16:02:45,683 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3517 for 399 questions\n",
      "2025-03-13 16:02:45,684 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3517 asynchronously\n",
      "2025-03-13 16:02:45,684 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2955\n",
      "2025-03-13 16:02:45,684 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2955 for 399 questions\n",
      "2025-03-13 16:02:45,684 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2955 asynchronously\n",
      "2025-03-13 16:02:45,685 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 194\n",
      "2025-03-13 16:02:45,685 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 194 for 399 questions\n",
      "2025-03-13 16:02:45,685 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 194 asynchronously\n",
      "2025-03-13 16:02:45,685 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2608\n",
      "2025-03-13 16:02:45,685 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2608 for 399 questions\n",
      "2025-03-13 16:02:45,686 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2608 asynchronously\n",
      "2025-03-13 16:02:45,686 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5901\n",
      "2025-03-13 16:02:45,686 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5901 for 399 questions\n",
      "2025-03-13 16:02:45,687 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5901 asynchronously\n",
      "2025-03-13 16:02:45,687 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4737\n",
      "2025-03-13 16:02:45,687 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4737 for 399 questions\n",
      "2025-03-13 16:02:45,688 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4737 asynchronously\n",
      "2025-03-13 16:02:45,688 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3526\n",
      "2025-03-13 16:02:45,688 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3526 for 399 questions\n",
      "2025-03-13 16:02:45,689 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3526 asynchronously\n",
      "2025-03-13 16:02:45,689 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5190\n",
      "2025-03-13 16:02:45,689 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5190 for 399 questions\n",
      "2025-03-13 16:02:45,690 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5190 asynchronously\n",
      "2025-03-13 16:02:45,690 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3428\n",
      "2025-03-13 16:02:45,690 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3428 for 399 questions\n",
      "2025-03-13 16:02:45,691 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3428 asynchronously\n",
      "2025-03-13 16:02:45,691 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4858\n",
      "2025-03-13 16:02:45,691 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4858 for 399 questions\n",
      "2025-03-13 16:02:45,691 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4858 asynchronously\n",
      "2025-03-13 16:02:45,692 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6070\n",
      "2025-03-13 16:02:45,694 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6070 for 399 questions\n",
      "2025-03-13 16:02:45,697 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6070 asynchronously\n",
      "2025-03-13 16:02:45,699 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6716\n",
      "2025-03-13 16:02:45,700 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6716 for 399 questions\n",
      "2025-03-13 16:02:45,700 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6716 asynchronously\n",
      "2025-03-13 16:02:45,701 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3545\n",
      "2025-03-13 16:02:45,701 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3545 for 399 questions\n",
      "2025-03-13 16:02:45,702 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3545 asynchronously\n",
      "2025-03-13 16:02:45,702 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5584\n",
      "2025-03-13 16:02:45,703 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5584 for 399 questions\n",
      "2025-03-13 16:02:45,704 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5584 asynchronously\n",
      "2025-03-13 16:02:45,704 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1710\n",
      "2025-03-13 16:02:45,704 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1710 for 399 questions\n",
      "2025-03-13 16:02:45,704 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1710 asynchronously\n",
      "2025-03-13 16:02:45,705 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5953\n",
      "2025-03-13 16:02:45,705 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5953 for 399 questions\n",
      "2025-03-13 16:02:45,706 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5953 asynchronously\n",
      "2025-03-13 16:02:45,707 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: dc5a06b89b...)\n",
      "2025-03-13 16:02:45,708 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3276\n",
      "2025-03-13 16:02:45,708 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0468c93c84...)\n",
      "2025-03-13 16:02:45,709 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6688\n",
      "2025-03-13 16:02:45,709 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0e44bc263b...)\n",
      "2025-03-13 16:02:45,709 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5079\n",
      "2025-03-13 16:02:45,710 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7c1aa65ccd...)\n",
      "2025-03-13 16:02:45,710 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3534\n",
      "2025-03-13 16:02:45,711 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4400\n",
      "2025-03-13 16:02:45,711 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4400 for 399 questions\n",
      "2025-03-13 16:02:45,712 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4400 asynchronously\n",
      "2025-03-13 16:02:45,712 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3662\n",
      "2025-03-13 16:02:45,712 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3662 for 399 questions\n",
      "2025-03-13 16:02:45,713 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3662 asynchronously\n",
      "2025-03-13 16:02:45,713 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1160\n",
      "2025-03-13 16:02:45,716 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1160 for 399 questions\n",
      "2025-03-13 16:02:45,717 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1160 asynchronously\n",
      "2025-03-13 16:02:45,718 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 7024\n",
      "2025-03-13 16:02:45,719 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 7024 for 399 questions\n",
      "2025-03-13 16:02:45,720 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 7024 asynchronously\n",
      "2025-03-13 16:02:45,723 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 2e974a9c6d...)\n",
      "2025-03-13 16:02:45,726 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5218\n",
      "2025-03-13 16:02:45,729 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5386\n",
      "2025-03-13 16:02:45,730 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5386 for 399 questions\n",
      "2025-03-13 16:02:45,733 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5386 asynchronously\n",
      "2025-03-13 16:02:45,740 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 75fd84affa...)\n",
      "2025-03-13 16:02:45,743 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2475\n",
      "2025-03-13 16:02:45,744 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3410\n",
      "2025-03-13 16:02:45,744 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3410 for 399 questions\n",
      "2025-03-13 16:02:45,745 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3410 asynchronously\n",
      "2025-03-13 16:02:45,754 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7537287baa...)\n",
      "2025-03-13 16:02:45,755 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4696\n",
      "2025-03-13 16:02:45,755 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3154\n",
      "2025-03-13 16:02:45,756 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3154 for 399 questions\n",
      "2025-03-13 16:02:45,756 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3154 asynchronously\n",
      "2025-03-13 16:02:45,761 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 14a786da29...)\n",
      "2025-03-13 16:02:45,762 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6949\n",
      "2025-03-13 16:02:45,762 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 528\n",
      "2025-03-13 16:02:45,763 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 528 for 399 questions\n",
      "2025-03-13 16:02:45,763 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 528 asynchronously\n",
      "2025-03-13 16:02:45,768 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 02e4337d5e...)\n",
      "2025-03-13 16:02:45,769 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2563\n",
      "2025-03-13 16:02:45,769 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 90\n",
      "2025-03-13 16:02:45,769 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 90 for 399 questions\n",
      "2025-03-13 16:02:45,770 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 90 asynchronously\n",
      "2025-03-13 16:02:45,774 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c21c0fdd00...)\n",
      "2025-03-13 16:02:45,775 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1946\n",
      "2025-03-13 16:02:45,775 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2604\n",
      "2025-03-13 16:02:45,776 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2604 for 399 questions\n",
      "2025-03-13 16:02:45,776 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2604 asynchronously\n",
      "2025-03-13 16:02:45,781 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a93e68c9b8...)\n",
      "2025-03-13 16:02:45,782 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6413\n",
      "2025-03-13 16:02:45,782 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1571\n",
      "2025-03-13 16:02:45,783 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1571 for 399 questions\n",
      "2025-03-13 16:02:45,783 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1571 asynchronously\n",
      "2025-03-13 16:02:45,787 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 00cac6c00b...)\n",
      "2025-03-13 16:02:45,788 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5847\n",
      "2025-03-13 16:02:45,788 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1833\n",
      "2025-03-13 16:02:45,789 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1833 for 399 questions\n",
      "2025-03-13 16:02:45,789 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1833 asynchronously\n",
      "2025-03-13 16:02:45,793 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: efa761b3df...)\n",
      "2025-03-13 16:02:45,795 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3222\n",
      "2025-03-13 16:02:45,795 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1008\n",
      "2025-03-13 16:02:45,795 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1008 for 399 questions\n",
      "2025-03-13 16:02:45,795 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1008 asynchronously\n",
      "2025-03-13 16:02:45,799 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0830d30927...)\n",
      "2025-03-13 16:02:45,994 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6717\n",
      "2025-03-13 16:02:45,995 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 304\n",
      "2025-03-13 16:02:45,995 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 304 for 399 questions\n",
      "2025-03-13 16:02:45,995 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 304 asynchronously\n",
      "2025-03-13 16:02:45,996 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c4039946e3...)\n",
      "2025-03-13 16:02:45,997 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 33\n",
      "2025-03-13 16:02:45,997 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1529\n",
      "2025-03-13 16:02:45,997 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1529 for 399 questions\n",
      "2025-03-13 16:02:45,997 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1529 asynchronously\n",
      "2025-03-13 16:02:46,002 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d12eabcf29...)\n",
      "2025-03-13 16:02:46,003 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4055\n",
      "2025-03-13 16:02:46,003 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2417\n",
      "2025-03-13 16:02:46,003 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2417 for 399 questions\n",
      "2025-03-13 16:02:46,004 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2417 asynchronously\n",
      "2025-03-13 16:02:46,009 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6c7c4391f8...)\n",
      "2025-03-13 16:02:46,009 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2890\n",
      "2025-03-13 16:02:46,010 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6202\n",
      "2025-03-13 16:02:46,010 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6202 for 399 questions\n",
      "2025-03-13 16:02:46,010 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6202 asynchronously\n",
      "2025-03-13 16:02:46,014 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: cbd0506466...)\n",
      "2025-03-13 16:02:46,015 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1835\n",
      "2025-03-13 16:02:46,015 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1196\n",
      "2025-03-13 16:02:46,016 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1196 for 399 questions\n",
      "2025-03-13 16:02:46,016 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1196 asynchronously\n",
      "2025-03-13 16:02:46,020 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 3af9f3089f...)\n",
      "2025-03-13 16:02:46,021 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6991\n",
      "2025-03-13 16:02:46,021 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4838\n",
      "2025-03-13 16:02:46,022 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4838 for 399 questions\n",
      "2025-03-13 16:02:46,022 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4838 asynchronously\n",
      "2025-03-13 16:02:46,026 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9687664486...)\n",
      "2025-03-13 16:02:46,027 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2078\n",
      "2025-03-13 16:02:46,027 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2752\n",
      "2025-03-13 16:02:46,027 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2752 for 399 questions\n",
      "2025-03-13 16:02:46,028 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2752 asynchronously\n",
      "2025-03-13 16:02:46,032 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 3be73e365f...)\n",
      "2025-03-13 16:02:46,033 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4649\n",
      "2025-03-13 16:02:46,034 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1526\n",
      "2025-03-13 16:02:46,034 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1526 for 399 questions\n",
      "2025-03-13 16:02:46,034 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1526 asynchronously\n",
      "2025-03-13 16:02:46,038 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: b5187ad663...)\n",
      "2025-03-13 16:02:46,039 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 976\n",
      "2025-03-13 16:02:46,040 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4934\n",
      "2025-03-13 16:02:46,040 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4934 for 399 questions\n",
      "2025-03-13 16:02:46,040 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4934 asynchronously\n",
      "2025-03-13 16:02:46,045 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: df444d4781...)\n",
      "2025-03-13 16:02:46,045 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6990\n",
      "2025-03-13 16:02:46,046 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6574\n",
      "2025-03-13 16:02:46,046 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6574 for 399 questions\n",
      "2025-03-13 16:02:46,046 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6574 asynchronously\n",
      "2025-03-13 16:02:46,051 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 079a31c8f6...)\n",
      "2025-03-13 16:02:46,052 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1722\n",
      "2025-03-13 16:02:46,052 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3312\n",
      "2025-03-13 16:02:46,052 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3312 for 399 questions\n",
      "2025-03-13 16:02:46,052 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3312 asynchronously\n",
      "2025-03-13 16:02:46,057 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 8c48efe7d0...)\n",
      "2025-03-13 16:02:46,058 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3517\n",
      "2025-03-13 16:02:46,058 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6109\n",
      "2025-03-13 16:02:46,058 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6109 for 399 questions\n",
      "2025-03-13 16:02:46,058 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6109 asynchronously\n",
      "2025-03-13 16:02:46,063 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 41f42a65ad...)\n",
      "2025-03-13 16:02:46,064 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2955\n",
      "2025-03-13 16:02:46,065 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1736\n",
      "2025-03-13 16:02:46,065 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1736 for 399 questions\n",
      "2025-03-13 16:02:46,065 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1736 asynchronously\n",
      "2025-03-13 16:02:46,070 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ec3e33eca1...)\n",
      "2025-03-13 16:02:46,070 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 194\n",
      "2025-03-13 16:02:46,071 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6655\n",
      "2025-03-13 16:02:46,071 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6655 for 399 questions\n",
      "2025-03-13 16:02:46,071 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6655 asynchronously\n",
      "2025-03-13 16:02:46,075 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ba134940d3...)\n",
      "2025-03-13 16:02:46,077 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2608\n",
      "2025-03-13 16:02:46,077 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1692\n",
      "2025-03-13 16:02:46,077 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1692 for 399 questions\n",
      "2025-03-13 16:02:46,078 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1692 asynchronously\n",
      "2025-03-13 16:02:46,081 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: b1ab4ec8ca...)\n",
      "2025-03-13 16:02:46,082 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5901\n",
      "2025-03-13 16:02:46,082 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3874\n",
      "2025-03-13 16:02:46,082 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3874 for 399 questions\n",
      "2025-03-13 16:02:46,083 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3874 asynchronously\n",
      "2025-03-13 16:02:46,087 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: b9bd9d2104...)\n",
      "2025-03-13 16:02:46,088 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4737\n",
      "2025-03-13 16:02:46,088 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4275\n",
      "2025-03-13 16:02:46,088 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4275 for 399 questions\n",
      "2025-03-13 16:02:46,089 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4275 asynchronously\n",
      "2025-03-13 16:02:46,093 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9b6be22736...)\n",
      "2025-03-13 16:02:46,094 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3526\n",
      "2025-03-13 16:02:46,094 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 227\n",
      "2025-03-13 16:02:46,094 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 227 for 399 questions\n",
      "2025-03-13 16:02:46,095 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 227 asynchronously\n",
      "2025-03-13 16:02:46,099 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: afeb1453b4...)\n",
      "2025-03-13 16:02:46,100 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5190\n",
      "2025-03-13 16:02:46,100 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4623\n",
      "2025-03-13 16:02:46,101 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4623 for 399 questions\n",
      "2025-03-13 16:02:46,101 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4623 asynchronously\n",
      "2025-03-13 16:02:46,105 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 355ff0410e...)\n",
      "2025-03-13 16:02:46,106 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3428\n",
      "2025-03-13 16:02:46,106 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6981\n",
      "2025-03-13 16:02:46,106 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6981 for 399 questions\n",
      "2025-03-13 16:02:46,106 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6981 asynchronously\n",
      "2025-03-13 16:02:46,110 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0d973e55bc...)\n",
      "2025-03-13 16:02:46,111 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4858\n",
      "2025-03-13 16:02:46,112 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3088\n",
      "2025-03-13 16:02:46,112 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3088 for 399 questions\n",
      "2025-03-13 16:02:46,112 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3088 asynchronously\n",
      "2025-03-13 16:02:46,117 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 5fbb9468bc...)\n",
      "2025-03-13 16:02:46,118 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6070\n",
      "2025-03-13 16:02:46,118 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6625\n",
      "2025-03-13 16:02:46,118 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6625 for 399 questions\n",
      "2025-03-13 16:02:46,119 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6625 asynchronously\n",
      "2025-03-13 16:02:46,123 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7c78959553...)\n",
      "2025-03-13 16:02:46,124 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6716\n",
      "2025-03-13 16:02:46,124 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1715\n",
      "2025-03-13 16:02:46,125 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1715 for 399 questions\n",
      "2025-03-13 16:02:46,125 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1715 asynchronously\n",
      "2025-03-13 16:02:46,129 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4f6bece6ac...)\n",
      "2025-03-13 16:02:46,130 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3545\n",
      "2025-03-13 16:02:46,130 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 722\n",
      "2025-03-13 16:02:46,130 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 722 for 399 questions\n",
      "2025-03-13 16:02:46,131 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 722 asynchronously\n",
      "2025-03-13 16:02:46,135 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c651c573be...)\n",
      "2025-03-13 16:02:46,135 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5584\n",
      "2025-03-13 16:02:46,136 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 982\n",
      "2025-03-13 16:02:46,136 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 982 for 399 questions\n",
      "2025-03-13 16:02:46,136 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 982 asynchronously\n",
      "2025-03-13 16:02:46,141 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 8003632d4b...)\n",
      "2025-03-13 16:02:46,141 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1710\n",
      "2025-03-13 16:02:46,142 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5858\n",
      "2025-03-13 16:02:46,142 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5858 for 399 questions\n",
      "2025-03-13 16:02:46,142 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5858 asynchronously\n",
      "2025-03-13 16:02:46,147 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ffec4fd526...)\n",
      "2025-03-13 16:02:46,148 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5953\n",
      "2025-03-13 16:02:46,148 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2949\n",
      "2025-03-13 16:02:46,149 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2949 for 399 questions\n",
      "2025-03-13 16:02:46,149 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2949 asynchronously\n",
      "2025-03-13 16:02:46,153 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0866cc4d3b...)\n",
      "2025-03-13 16:02:46,155 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4400\n",
      "2025-03-13 16:02:46,155 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1864\n",
      "2025-03-13 16:02:46,155 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1864 for 399 questions\n",
      "2025-03-13 16:02:46,155 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1864 asynchronously\n",
      "2025-03-13 16:02:46,160 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 104929c12a...)\n",
      "2025-03-13 16:02:46,161 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3662\n",
      "2025-03-13 16:02:46,161 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4692\n",
      "2025-03-13 16:02:46,162 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4692 for 399 questions\n",
      "2025-03-13 16:02:46,162 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4692 asynchronously\n",
      "2025-03-13 16:02:46,173 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: fc046839db...)\n",
      "2025-03-13 16:02:46,174 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1160\n",
      "2025-03-13 16:02:46,175 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3879\n",
      "2025-03-13 16:02:46,175 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3879 for 399 questions\n",
      "2025-03-13 16:02:46,175 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3879 asynchronously\n",
      "2025-03-13 16:02:46,180 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 98790ef688...)\n",
      "2025-03-13 16:02:46,181 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 7024\n",
      "2025-03-13 16:02:46,181 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3955\n",
      "2025-03-13 16:02:46,182 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3955 for 399 questions\n",
      "2025-03-13 16:02:46,182 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3955 asynchronously\n",
      "2025-03-13 16:02:46,186 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 07161355ba...)\n",
      "2025-03-13 16:02:46,187 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5386\n",
      "2025-03-13 16:02:46,187 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2826\n",
      "2025-03-13 16:02:46,188 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2826 for 399 questions\n",
      "2025-03-13 16:02:46,188 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2826 asynchronously\n",
      "2025-03-13 16:02:46,192 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7061af43ad...)\n",
      "2025-03-13 16:02:46,193 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3410\n",
      "2025-03-13 16:02:46,193 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5288\n",
      "2025-03-13 16:02:46,194 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5288 for 399 questions\n",
      "2025-03-13 16:02:46,194 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5288 asynchronously\n",
      "2025-03-13 16:02:46,199 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: f390eb40aa...)\n",
      "2025-03-13 16:02:46,199 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3154\n",
      "2025-03-13 16:02:46,200 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1122\n",
      "2025-03-13 16:02:46,200 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1122 for 399 questions\n",
      "2025-03-13 16:02:46,200 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1122 asynchronously\n",
      "2025-03-13 16:02:46,204 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0ff03bcdaf...)\n",
      "2025-03-13 16:02:46,205 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 528\n",
      "2025-03-13 16:02:46,206 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2426\n",
      "2025-03-13 16:02:46,206 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2426 for 399 questions\n",
      "2025-03-13 16:02:46,206 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2426 asynchronously\n",
      "2025-03-13 16:02:46,210 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 965cbdfbde...)\n",
      "2025-03-13 16:02:46,211 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 90\n",
      "2025-03-13 16:02:46,211 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1363\n",
      "2025-03-13 16:02:46,211 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1363 for 399 questions\n",
      "2025-03-13 16:02:46,212 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1363 asynchronously\n",
      "2025-03-13 16:02:46,216 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 465bfcef63...)\n",
      "2025-03-13 16:02:46,217 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2604\n",
      "2025-03-13 16:02:46,217 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2892\n",
      "2025-03-13 16:02:46,217 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2892 for 399 questions\n",
      "2025-03-13 16:02:46,218 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2892 asynchronously\n",
      "2025-03-13 16:02:46,222 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 15d1a40811...)\n",
      "2025-03-13 16:02:46,223 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1571\n",
      "2025-03-13 16:02:46,223 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6015\n",
      "2025-03-13 16:02:46,224 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6015 for 399 questions\n",
      "2025-03-13 16:02:46,224 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6015 asynchronously\n",
      "2025-03-13 16:02:46,228 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 444bfb8ffa...)\n",
      "2025-03-13 16:02:46,229 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1833\n",
      "2025-03-13 16:02:46,229 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2141\n",
      "2025-03-13 16:02:46,229 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2141 for 399 questions\n",
      "2025-03-13 16:02:46,230 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2141 asynchronously\n",
      "2025-03-13 16:02:46,234 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 48edab3592...)\n",
      "2025-03-13 16:02:46,235 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1008\n",
      "2025-03-13 16:02:46,235 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 49\n",
      "2025-03-13 16:02:46,235 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 49 for 399 questions\n",
      "2025-03-13 16:02:46,236 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 49 asynchronously\n",
      "2025-03-13 16:02:46,240 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c6187370b1...)\n",
      "2025-03-13 16:02:46,241 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 304\n",
      "2025-03-13 16:02:46,241 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 420\n",
      "2025-03-13 16:02:46,241 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 420 for 399 questions\n",
      "2025-03-13 16:02:46,241 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 420 asynchronously\n",
      "2025-03-13 16:02:46,245 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 878916d434...)\n",
      "2025-03-13 16:02:46,246 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1529\n",
      "2025-03-13 16:02:46,247 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6359\n",
      "2025-03-13 16:02:46,247 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6359 for 399 questions\n",
      "2025-03-13 16:02:46,247 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6359 asynchronously\n",
      "2025-03-13 16:02:46,251 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 36080f286d...)\n",
      "2025-03-13 16:02:46,252 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2417\n",
      "2025-03-13 16:02:46,252 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5353\n",
      "2025-03-13 16:02:46,252 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5353 for 399 questions\n",
      "2025-03-13 16:02:46,253 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5353 asynchronously\n",
      "2025-03-13 16:02:46,257 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: bba86a15a1...)\n",
      "2025-03-13 16:02:46,258 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6202\n",
      "2025-03-13 16:02:46,258 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1035\n",
      "2025-03-13 16:02:46,258 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1035 for 399 questions\n",
      "2025-03-13 16:02:46,259 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1035 asynchronously\n",
      "2025-03-13 16:02:46,280 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ceb074baf7...)\n",
      "2025-03-13 16:02:46,285 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1196\n",
      "2025-03-13 16:02:46,289 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3416\n",
      "2025-03-13 16:02:46,289 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3416 for 399 questions\n",
      "2025-03-13 16:02:46,290 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3416 asynchronously\n",
      "2025-03-13 16:02:46,293 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 1f6e08a4b2...)\n",
      "2025-03-13 16:02:46,296 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4838\n",
      "2025-03-13 16:02:46,297 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5366\n",
      "2025-03-13 16:02:46,297 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5366 for 399 questions\n",
      "2025-03-13 16:02:46,298 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5366 asynchronously\n",
      "2025-03-13 16:02:46,303 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 5664409c93...)\n",
      "2025-03-13 16:02:46,304 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2752\n",
      "2025-03-13 16:02:46,304 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 291\n",
      "2025-03-13 16:02:46,304 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 291 for 399 questions\n",
      "2025-03-13 16:02:46,305 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 291 asynchronously\n",
      "2025-03-13 16:02:46,309 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c95f4f3bc7...)\n",
      "2025-03-13 16:02:46,310 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1526\n",
      "2025-03-13 16:02:46,310 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6614\n",
      "2025-03-13 16:02:46,310 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6614 for 399 questions\n",
      "2025-03-13 16:02:46,311 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6614 asynchronously\n",
      "2025-03-13 16:02:46,315 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: f6bd1e1043...)\n",
      "2025-03-13 16:02:46,316 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4934\n",
      "2025-03-13 16:02:46,316 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2580\n",
      "2025-03-13 16:02:46,317 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2580 for 399 questions\n",
      "2025-03-13 16:02:46,317 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2580 asynchronously\n",
      "2025-03-13 16:02:46,321 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d6ba9cbe5b...)\n",
      "2025-03-13 16:02:46,322 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6574\n",
      "2025-03-13 16:02:46,322 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 39\n",
      "2025-03-13 16:02:46,322 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 39 for 399 questions\n",
      "2025-03-13 16:02:46,323 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 39 asynchronously\n",
      "2025-03-13 16:02:46,327 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 20766dd7e4...)\n",
      "2025-03-13 16:02:46,327 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3312\n",
      "2025-03-13 16:02:46,328 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2754\n",
      "2025-03-13 16:02:46,328 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2754 for 399 questions\n",
      "2025-03-13 16:02:46,328 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2754 asynchronously\n",
      "2025-03-13 16:02:46,333 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: cb8ad4ffb1...)\n",
      "2025-03-13 16:02:46,333 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6109\n",
      "2025-03-13 16:02:46,334 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6944\n",
      "2025-03-13 16:02:46,334 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6944 for 399 questions\n",
      "2025-03-13 16:02:46,334 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6944 asynchronously\n",
      "2025-03-13 16:02:46,338 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: bfeddf23c3...)\n",
      "2025-03-13 16:02:46,339 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1736\n",
      "2025-03-13 16:02:46,339 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4740\n",
      "2025-03-13 16:02:46,339 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4740 for 399 questions\n",
      "2025-03-13 16:02:46,340 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4740 asynchronously\n",
      "2025-03-13 16:02:46,344 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 38f5cbd7ef...)\n",
      "2025-03-13 16:02:46,345 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6655\n",
      "2025-03-13 16:02:46,345 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5774\n",
      "2025-03-13 16:02:46,346 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5774 for 399 questions\n",
      "2025-03-13 16:02:46,346 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5774 asynchronously\n",
      "2025-03-13 16:02:46,350 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e3f119facc...)\n",
      "2025-03-13 16:02:46,351 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1692\n",
      "2025-03-13 16:02:46,351 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1336\n",
      "2025-03-13 16:02:46,351 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1336 for 399 questions\n",
      "2025-03-13 16:02:46,352 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1336 asynchronously\n",
      "2025-03-13 16:02:46,356 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 3dbb1db0ce...)\n",
      "2025-03-13 16:02:46,356 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3874\n",
      "2025-03-13 16:02:46,357 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1654\n",
      "2025-03-13 16:02:46,358 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1654 for 399 questions\n",
      "2025-03-13 16:02:46,358 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1654 asynchronously\n",
      "2025-03-13 16:02:46,361 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7cd24200de...)\n",
      "2025-03-13 16:02:46,362 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4275\n",
      "2025-03-13 16:02:46,362 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2648\n",
      "2025-03-13 16:02:46,363 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2648 for 399 questions\n",
      "2025-03-13 16:02:46,363 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2648 asynchronously\n",
      "2025-03-13 16:02:46,367 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 2d5707f4bc...)\n",
      "2025-03-13 16:02:46,368 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 227\n",
      "2025-03-13 16:02:46,368 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 800\n",
      "2025-03-13 16:02:46,369 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 800 for 399 questions\n",
      "2025-03-13 16:02:46,369 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 800 asynchronously\n",
      "2025-03-13 16:02:46,373 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d2ae99cbba...)\n",
      "2025-03-13 16:02:46,374 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4623\n",
      "2025-03-13 16:02:46,374 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4315\n",
      "2025-03-13 16:02:46,374 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4315 for 399 questions\n",
      "2025-03-13 16:02:46,375 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4315 asynchronously\n",
      "2025-03-13 16:02:46,380 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0cb9fd89dd...)\n",
      "2025-03-13 16:02:46,380 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6981\n",
      "2025-03-13 16:02:46,381 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4046\n",
      "2025-03-13 16:02:46,381 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4046 for 399 questions\n",
      "2025-03-13 16:02:46,381 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4046 asynchronously\n",
      "2025-03-13 16:02:46,386 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 095e27a163...)\n",
      "2025-03-13 16:02:46,387 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3088\n",
      "2025-03-13 16:02:46,387 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3460\n",
      "2025-03-13 16:02:46,387 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3460 for 399 questions\n",
      "2025-03-13 16:02:46,387 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3460 asynchronously\n",
      "2025-03-13 16:02:46,392 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4d344af2d1...)\n",
      "2025-03-13 16:02:46,393 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6625\n",
      "2025-03-13 16:02:46,393 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5135\n",
      "2025-03-13 16:02:46,393 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5135 for 399 questions\n",
      "2025-03-13 16:02:46,394 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5135 asynchronously\n",
      "2025-03-13 16:02:46,397 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 609f063a98...)\n",
      "2025-03-13 16:02:46,398 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1715\n",
      "2025-03-13 16:02:46,399 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3286\n",
      "2025-03-13 16:02:46,399 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3286 for 399 questions\n",
      "2025-03-13 16:02:46,399 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3286 asynchronously\n",
      "2025-03-13 16:02:46,403 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 020f1fa091...)\n",
      "2025-03-13 16:02:46,404 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 722\n",
      "2025-03-13 16:02:46,404 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 629\n",
      "2025-03-13 16:02:46,404 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 629 for 399 questions\n",
      "2025-03-13 16:02:46,405 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 629 asynchronously\n",
      "2025-03-13 16:02:46,409 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 576c527998...)\n",
      "2025-03-13 16:02:46,410 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 982\n",
      "2025-03-13 16:02:46,410 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2478\n",
      "2025-03-13 16:02:46,410 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2478 for 399 questions\n",
      "2025-03-13 16:02:46,410 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2478 asynchronously\n",
      "2025-03-13 16:02:46,416 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6b00bdce7b...)\n",
      "2025-03-13 16:02:46,417 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5858\n",
      "2025-03-13 16:02:46,418 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3319\n",
      "2025-03-13 16:02:46,418 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3319 for 399 questions\n",
      "2025-03-13 16:02:46,419 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3319 asynchronously\n",
      "2025-03-13 16:02:46,422 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9bfe822ae6...)\n",
      "2025-03-13 16:02:46,423 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2949\n",
      "2025-03-13 16:02:46,423 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6163\n",
      "2025-03-13 16:02:46,424 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6163 for 399 questions\n",
      "2025-03-13 16:02:46,424 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6163 asynchronously\n",
      "2025-03-13 16:02:46,429 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0598443fb5...)\n",
      "2025-03-13 16:02:46,431 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1864\n",
      "2025-03-13 16:02:46,431 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 499\n",
      "2025-03-13 16:02:46,432 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 499 for 399 questions\n",
      "2025-03-13 16:02:46,432 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 499 asynchronously\n",
      "2025-03-13 16:02:46,436 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ba6707da77...)\n",
      "2025-03-13 16:02:46,437 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4692\n",
      "2025-03-13 16:02:46,438 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 48\n",
      "2025-03-13 16:02:46,438 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 48 for 399 questions\n",
      "2025-03-13 16:02:46,438 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 48 asynchronously\n",
      "2025-03-13 16:02:46,442 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 33a2dfed1d...)\n",
      "2025-03-13 16:02:46,443 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3879\n",
      "2025-03-13 16:02:46,444 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6580\n",
      "2025-03-13 16:02:46,444 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6580 for 399 questions\n",
      "2025-03-13 16:02:46,445 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6580 asynchronously\n",
      "2025-03-13 16:02:46,448 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 704466f066...)\n",
      "2025-03-13 16:02:46,450 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3955\n",
      "2025-03-13 16:02:46,450 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6931\n",
      "2025-03-13 16:02:46,450 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6931 for 399 questions\n",
      "2025-03-13 16:02:46,451 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6931 asynchronously\n",
      "2025-03-13 16:02:46,456 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4cd582f487...)\n",
      "2025-03-13 16:02:46,457 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2826\n",
      "2025-03-13 16:02:46,457 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1513\n",
      "2025-03-13 16:02:46,458 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1513 for 399 questions\n",
      "2025-03-13 16:02:46,458 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1513 asynchronously\n",
      "2025-03-13 16:02:46,462 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 44ec1f70f4...)\n",
      "2025-03-13 16:02:46,462 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5288\n",
      "2025-03-13 16:02:46,463 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3432\n",
      "2025-03-13 16:02:46,463 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3432 for 399 questions\n",
      "2025-03-13 16:02:46,463 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3432 asynchronously\n",
      "2025-03-13 16:02:46,468 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: fb04a725ae...)\n",
      "2025-03-13 16:02:46,468 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1122\n",
      "2025-03-13 16:02:46,469 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6464\n",
      "2025-03-13 16:02:46,469 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6464 for 399 questions\n",
      "2025-03-13 16:02:46,469 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6464 asynchronously\n",
      "2025-03-13 16:02:46,474 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e382fbbf26...)\n",
      "2025-03-13 16:02:46,474 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2426\n",
      "2025-03-13 16:02:46,475 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4626\n",
      "2025-03-13 16:02:46,475 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4626 for 399 questions\n",
      "2025-03-13 16:02:46,475 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4626 asynchronously\n",
      "2025-03-13 16:02:46,479 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c1383d424b...)\n",
      "2025-03-13 16:02:46,480 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1363\n",
      "2025-03-13 16:02:46,480 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 878\n",
      "2025-03-13 16:02:46,481 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 878 for 399 questions\n",
      "2025-03-13 16:02:46,481 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 878 asynchronously\n",
      "2025-03-13 16:02:46,485 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ac79b60cf6...)\n",
      "2025-03-13 16:02:46,486 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2892\n",
      "2025-03-13 16:02:46,486 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3202\n",
      "2025-03-13 16:02:46,486 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3202 for 399 questions\n",
      "2025-03-13 16:02:46,487 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3202 asynchronously\n",
      "2025-03-13 16:02:46,491 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: fb03344189...)\n",
      "2025-03-13 16:02:46,492 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6015\n",
      "2025-03-13 16:02:46,493 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4751\n",
      "2025-03-13 16:02:46,493 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4751 for 399 questions\n",
      "2025-03-13 16:02:46,493 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4751 asynchronously\n",
      "2025-03-13 16:02:46,521 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 74d535fe3f...)\n",
      "2025-03-13 16:02:46,528 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2141\n",
      "2025-03-13 16:02:46,529 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 541\n",
      "2025-03-13 16:02:46,529 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 541 for 399 questions\n",
      "2025-03-13 16:02:46,530 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 541 asynchronously\n",
      "2025-03-13 16:02:46,533 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d2d1b636f8...)\n",
      "2025-03-13 16:02:46,535 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 49\n",
      "2025-03-13 16:02:46,536 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1595\n",
      "2025-03-13 16:02:46,537 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1595 for 399 questions\n",
      "2025-03-13 16:02:46,538 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1595 asynchronously\n",
      "2025-03-13 16:02:46,542 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: edc390ee7b...)\n",
      "2025-03-13 16:02:46,543 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 420\n",
      "2025-03-13 16:02:46,544 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 479\n",
      "2025-03-13 16:02:46,544 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 479 for 399 questions\n",
      "2025-03-13 16:02:46,544 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 479 asynchronously\n",
      "2025-03-13 16:02:46,548 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: b37a5c25d9...)\n",
      "2025-03-13 16:02:46,549 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6359\n",
      "2025-03-13 16:02:46,549 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4119\n",
      "2025-03-13 16:02:46,550 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4119 for 399 questions\n",
      "2025-03-13 16:02:46,550 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4119 asynchronously\n",
      "2025-03-13 16:02:46,554 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0610ece331...)\n",
      "2025-03-13 16:02:46,555 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5353\n",
      "2025-03-13 16:02:46,555 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1766\n",
      "2025-03-13 16:02:46,556 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1766 for 399 questions\n",
      "2025-03-13 16:02:46,556 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1766 asynchronously\n",
      "2025-03-13 16:02:46,560 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d85e4e500c...)\n",
      "2025-03-13 16:02:46,560 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1035\n",
      "2025-03-13 16:02:46,561 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4395\n",
      "2025-03-13 16:02:46,561 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4395 for 399 questions\n",
      "2025-03-13 16:02:46,561 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4395 asynchronously\n",
      "2025-03-13 16:02:46,565 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 948d3f75b0...)\n",
      "2025-03-13 16:02:46,567 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3416\n",
      "2025-03-13 16:02:46,567 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1785\n",
      "2025-03-13 16:02:46,567 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1785 for 399 questions\n",
      "2025-03-13 16:02:46,567 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1785 asynchronously\n",
      "2025-03-13 16:02:46,571 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 2d03b445c5...)\n",
      "2025-03-13 16:02:46,571 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5366\n",
      "2025-03-13 16:02:46,572 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6650\n",
      "2025-03-13 16:02:46,572 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6650 for 399 questions\n",
      "2025-03-13 16:02:46,572 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6650 asynchronously\n",
      "2025-03-13 16:02:46,576 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6154f43654...)\n",
      "2025-03-13 16:02:46,577 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 291\n",
      "2025-03-13 16:02:46,577 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3480\n",
      "2025-03-13 16:02:46,577 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3480 for 399 questions\n",
      "2025-03-13 16:02:46,578 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3480 asynchronously\n",
      "2025-03-13 16:02:46,582 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 971b1867fc...)\n",
      "2025-03-13 16:02:46,583 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6614\n",
      "2025-03-13 16:02:46,583 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 7031\n",
      "2025-03-13 16:02:46,584 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 7031 for 399 questions\n",
      "2025-03-13 16:02:46,584 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 7031 asynchronously\n",
      "2025-03-13 16:02:46,588 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 09d0c2441a...)\n",
      "2025-03-13 16:02:46,588 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2580\n",
      "2025-03-13 16:02:46,589 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2161\n",
      "2025-03-13 16:02:46,589 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2161 for 399 questions\n",
      "2025-03-13 16:02:46,589 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2161 asynchronously\n",
      "2025-03-13 16:02:46,593 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 2535ea91e5...)\n",
      "2025-03-13 16:02:46,594 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 39\n",
      "2025-03-13 16:02:46,594 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6052\n",
      "2025-03-13 16:02:46,594 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6052 for 399 questions\n",
      "2025-03-13 16:02:46,595 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6052 asynchronously\n",
      "2025-03-13 16:02:46,599 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d935a3cb46...)\n",
      "2025-03-13 16:02:46,600 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2754\n",
      "2025-03-13 16:02:46,600 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3448\n",
      "2025-03-13 16:02:46,600 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3448 for 399 questions\n",
      "2025-03-13 16:02:46,601 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3448 asynchronously\n",
      "2025-03-13 16:02:46,604 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: b46d893c11...)\n",
      "2025-03-13 16:02:46,606 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6944\n",
      "2025-03-13 16:02:46,606 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3594\n",
      "2025-03-13 16:02:46,606 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3594 for 399 questions\n",
      "2025-03-13 16:02:46,607 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3594 asynchronously\n",
      "2025-03-13 16:02:46,610 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7157400b2b...)\n",
      "2025-03-13 16:02:46,611 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4740\n",
      "2025-03-13 16:02:46,611 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3754\n",
      "2025-03-13 16:02:46,611 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3754 for 399 questions\n",
      "2025-03-13 16:02:46,611 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3754 asynchronously\n",
      "2025-03-13 16:02:46,616 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 8d8f40dae2...)\n",
      "2025-03-13 16:02:46,617 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5774\n",
      "2025-03-13 16:02:46,617 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4788\n",
      "2025-03-13 16:02:46,617 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4788 for 399 questions\n",
      "2025-03-13 16:02:46,618 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4788 asynchronously\n",
      "2025-03-13 16:02:46,622 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a0ec1d8795...)\n",
      "2025-03-13 16:02:46,623 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1336\n",
      "2025-03-13 16:02:46,623 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 188\n",
      "2025-03-13 16:02:46,623 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 188 for 399 questions\n",
      "2025-03-13 16:02:46,623 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 188 asynchronously\n",
      "2025-03-13 16:02:46,627 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 71d2fe47b2...)\n",
      "2025-03-13 16:02:46,628 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1654\n",
      "2025-03-13 16:02:46,628 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5888\n",
      "2025-03-13 16:02:46,628 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5888 for 399 questions\n",
      "2025-03-13 16:02:46,629 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5888 asynchronously\n",
      "2025-03-13 16:02:46,633 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 88bca11079...)\n",
      "2025-03-13 16:02:46,634 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2648\n",
      "2025-03-13 16:02:46,634 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3601\n",
      "2025-03-13 16:02:46,634 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3601 for 399 questions\n",
      "2025-03-13 16:02:46,635 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3601 asynchronously\n",
      "2025-03-13 16:02:46,638 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4fdf94fd5b...)\n",
      "2025-03-13 16:02:46,639 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 800\n",
      "2025-03-13 16:02:46,640 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4017\n",
      "2025-03-13 16:02:46,640 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4017 for 399 questions\n",
      "2025-03-13 16:02:46,640 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4017 asynchronously\n",
      "2025-03-13 16:02:46,644 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a8c04a8460...)\n",
      "2025-03-13 16:02:46,645 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4315\n",
      "2025-03-13 16:02:46,645 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4298\n",
      "2025-03-13 16:02:46,645 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4298 for 399 questions\n",
      "2025-03-13 16:02:46,646 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4298 asynchronously\n",
      "2025-03-13 16:02:46,649 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: f3fdfb7a25...)\n",
      "2025-03-13 16:02:46,650 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4046\n",
      "2025-03-13 16:02:46,650 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4582\n",
      "2025-03-13 16:02:46,651 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4582 for 399 questions\n",
      "2025-03-13 16:02:46,651 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4582 asynchronously\n",
      "2025-03-13 16:02:46,655 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 00b230d772...)\n",
      "2025-03-13 16:02:46,656 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3460\n",
      "2025-03-13 16:02:46,656 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1398\n",
      "2025-03-13 16:02:46,657 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1398 for 399 questions\n",
      "2025-03-13 16:02:46,657 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1398 asynchronously\n",
      "2025-03-13 16:02:46,662 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6c233ae71a...)\n",
      "2025-03-13 16:02:46,663 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5135\n",
      "2025-03-13 16:02:46,663 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6490\n",
      "2025-03-13 16:02:46,663 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6490 for 399 questions\n",
      "2025-03-13 16:02:46,663 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6490 asynchronously\n",
      "2025-03-13 16:02:46,667 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: f15c6d12c2...)\n",
      "2025-03-13 16:02:46,668 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3286\n",
      "2025-03-13 16:02:46,668 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5523\n",
      "2025-03-13 16:02:46,669 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5523 for 399 questions\n",
      "2025-03-13 16:02:46,669 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5523 asynchronously\n",
      "2025-03-13 16:02:46,673 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 42e6d34b0b...)\n",
      "2025-03-13 16:02:46,673 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 629\n",
      "2025-03-13 16:02:46,674 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5166\n",
      "2025-03-13 16:02:46,674 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5166 for 399 questions\n",
      "2025-03-13 16:02:46,674 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5166 asynchronously\n",
      "2025-03-13 16:02:46,678 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 89d9f2d116...)\n",
      "2025-03-13 16:02:46,679 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2478\n",
      "2025-03-13 16:02:46,679 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1180\n",
      "2025-03-13 16:02:46,680 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1180 for 399 questions\n",
      "2025-03-13 16:02:46,680 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1180 asynchronously\n",
      "2025-03-13 16:02:46,684 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 1ef05cfcc6...)\n",
      "2025-03-13 16:02:46,685 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3319\n",
      "2025-03-13 16:02:46,686 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 938\n",
      "2025-03-13 16:02:46,686 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 938 for 399 questions\n",
      "2025-03-13 16:02:46,686 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 938 asynchronously\n",
      "2025-03-13 16:02:46,690 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 32cceaf21c...)\n",
      "2025-03-13 16:02:46,691 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6163\n",
      "2025-03-13 16:02:46,691 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6975\n",
      "2025-03-13 16:02:46,692 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6975 for 399 questions\n",
      "2025-03-13 16:02:46,692 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6975 asynchronously\n",
      "2025-03-13 16:02:46,696 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: f0cd2de3cd...)\n",
      "2025-03-13 16:02:46,697 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 499\n",
      "2025-03-13 16:02:46,698 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5280\n",
      "2025-03-13 16:02:46,698 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5280 for 399 questions\n",
      "2025-03-13 16:02:46,698 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5280 asynchronously\n",
      "2025-03-13 16:02:46,717 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4ef80f967f...)\n",
      "2025-03-13 16:02:46,721 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 48\n",
      "2025-03-13 16:02:46,723 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4612\n",
      "2025-03-13 16:02:46,724 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4612 for 399 questions\n",
      "2025-03-13 16:02:46,725 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4612 asynchronously\n",
      "2025-03-13 16:02:46,730 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 24702c7bb4...)\n",
      "2025-03-13 16:02:46,731 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6580\n",
      "2025-03-13 16:02:46,732 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 124\n",
      "2025-03-13 16:02:46,732 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 124 for 399 questions\n",
      "2025-03-13 16:02:46,733 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 124 asynchronously\n",
      "2025-03-13 16:02:46,740 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ae68cc4a06...)\n",
      "2025-03-13 16:02:46,741 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6931\n",
      "2025-03-13 16:02:46,741 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4674\n",
      "2025-03-13 16:02:46,741 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4674 for 399 questions\n",
      "2025-03-13 16:02:46,741 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4674 asynchronously\n",
      "2025-03-13 16:02:46,745 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 52e7ca8ea0...)\n",
      "2025-03-13 16:02:46,746 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1513\n",
      "2025-03-13 16:02:46,747 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 7039\n",
      "2025-03-13 16:02:46,747 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 7039 for 399 questions\n",
      "2025-03-13 16:02:46,747 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 7039 asynchronously\n",
      "2025-03-13 16:02:46,751 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6b09d4bf2c...)\n",
      "2025-03-13 16:02:46,752 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3432\n",
      "2025-03-13 16:02:46,753 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5540\n",
      "2025-03-13 16:02:46,753 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5540 for 399 questions\n",
      "2025-03-13 16:02:46,753 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5540 asynchronously\n",
      "2025-03-13 16:02:46,757 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 20d43abfb3...)\n",
      "2025-03-13 16:02:46,758 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6464\n",
      "2025-03-13 16:02:46,758 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1563\n",
      "2025-03-13 16:02:46,758 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1563 for 399 questions\n",
      "2025-03-13 16:02:46,758 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1563 asynchronously\n",
      "2025-03-13 16:02:46,769 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c3531c73a4...)\n",
      "2025-03-13 16:02:46,770 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4626\n",
      "2025-03-13 16:02:46,770 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4763\n",
      "2025-03-13 16:02:46,771 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4763 for 399 questions\n",
      "2025-03-13 16:02:46,772 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4763 asynchronously\n",
      "2025-03-13 16:02:46,775 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a525f32de7...)\n",
      "2025-03-13 16:02:46,776 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 878\n",
      "2025-03-13 16:02:46,776 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5258\n",
      "2025-03-13 16:02:46,776 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5258 for 399 questions\n",
      "2025-03-13 16:02:46,777 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5258 asynchronously\n",
      "2025-03-13 16:02:46,781 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6b36462630...)\n",
      "2025-03-13 16:02:46,782 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3202\n",
      "2025-03-13 16:02:46,782 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5745\n",
      "2025-03-13 16:02:46,782 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5745 for 399 questions\n",
      "2025-03-13 16:02:46,783 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5745 asynchronously\n",
      "2025-03-13 16:02:46,787 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 8dcb506ff3...)\n",
      "2025-03-13 16:02:46,788 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4751\n",
      "2025-03-13 16:02:46,788 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4024\n",
      "2025-03-13 16:02:46,788 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4024 for 399 questions\n",
      "2025-03-13 16:02:46,788 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4024 asynchronously\n",
      "2025-03-13 16:02:46,793 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7deb7275a0...)\n",
      "2025-03-13 16:02:46,794 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 541\n",
      "2025-03-13 16:02:46,794 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5546\n",
      "2025-03-13 16:02:46,794 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5546 for 399 questions\n",
      "2025-03-13 16:02:46,794 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5546 asynchronously\n",
      "2025-03-13 16:02:46,799 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a7c8db7d5f...)\n",
      "2025-03-13 16:02:46,800 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1595\n",
      "2025-03-13 16:02:46,800 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4301\n",
      "2025-03-13 16:02:46,801 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4301 for 399 questions\n",
      "2025-03-13 16:02:46,801 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4301 asynchronously\n",
      "2025-03-13 16:02:46,804 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9106a31270...)\n",
      "2025-03-13 16:02:46,805 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 479\n",
      "2025-03-13 16:02:46,805 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 768\n",
      "2025-03-13 16:02:46,805 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 768 for 399 questions\n",
      "2025-03-13 16:02:46,806 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 768 asynchronously\n",
      "2025-03-13 16:02:46,809 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6a2240f5a0...)\n",
      "2025-03-13 16:02:46,810 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4119\n",
      "2025-03-13 16:02:46,810 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1237\n",
      "2025-03-13 16:02:46,811 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1237 for 399 questions\n",
      "2025-03-13 16:02:46,811 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1237 asynchronously\n",
      "2025-03-13 16:02:46,815 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e07ab6bb83...)\n",
      "2025-03-13 16:02:46,815 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1766\n",
      "2025-03-13 16:02:46,816 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5308\n",
      "2025-03-13 16:02:46,816 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5308 for 399 questions\n",
      "2025-03-13 16:02:46,816 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5308 asynchronously\n",
      "2025-03-13 16:02:46,820 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 28061c84b7...)\n",
      "2025-03-13 16:02:46,820 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4395\n",
      "2025-03-13 16:02:46,821 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6225\n",
      "2025-03-13 16:02:46,821 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6225 for 399 questions\n",
      "2025-03-13 16:02:46,821 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6225 asynchronously\n",
      "2025-03-13 16:02:46,826 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9be96e40ce...)\n",
      "2025-03-13 16:02:46,827 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1785\n",
      "2025-03-13 16:02:46,827 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2505\n",
      "2025-03-13 16:02:46,827 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2505 for 399 questions\n",
      "2025-03-13 16:02:46,828 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2505 asynchronously\n",
      "2025-03-13 16:02:46,832 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a2ec497efc...)\n",
      "2025-03-13 16:02:46,833 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6650\n",
      "2025-03-13 16:02:46,833 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5507\n",
      "2025-03-13 16:02:46,833 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5507 for 399 questions\n",
      "2025-03-13 16:02:46,833 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5507 asynchronously\n",
      "2025-03-13 16:02:46,837 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 1281669f5d...)\n",
      "2025-03-13 16:02:46,838 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3480\n",
      "2025-03-13 16:02:46,839 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5998\n",
      "2025-03-13 16:02:46,839 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5998 for 399 questions\n",
      "2025-03-13 16:02:46,839 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5998 asynchronously\n",
      "2025-03-13 16:02:46,843 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a36057513a...)\n",
      "2025-03-13 16:02:46,843 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 7031\n",
      "2025-03-13 16:02:46,844 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2134\n",
      "2025-03-13 16:02:46,844 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2134 for 399 questions\n",
      "2025-03-13 16:02:46,844 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2134 asynchronously\n",
      "2025-03-13 16:02:46,849 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e24eadef62...)\n",
      "2025-03-13 16:02:46,849 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2161\n",
      "2025-03-13 16:02:46,850 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2247\n",
      "2025-03-13 16:02:46,850 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2247 for 399 questions\n",
      "2025-03-13 16:02:46,850 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2247 asynchronously\n",
      "2025-03-13 16:02:46,855 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: f5b1c6073f...)\n",
      "2025-03-13 16:02:46,855 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6052\n",
      "2025-03-13 16:02:46,856 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2420\n",
      "2025-03-13 16:02:46,856 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2420 for 399 questions\n",
      "2025-03-13 16:02:46,856 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2420 asynchronously\n",
      "2025-03-13 16:02:46,861 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 43f6c2dd3f...)\n",
      "2025-03-13 16:02:46,862 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3448\n",
      "2025-03-13 16:02:46,862 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4077\n",
      "2025-03-13 16:02:46,862 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4077 for 399 questions\n",
      "2025-03-13 16:02:46,863 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4077 asynchronously\n",
      "2025-03-13 16:02:46,867 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ba2a5fd7a9...)\n",
      "2025-03-13 16:02:46,868 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3594\n",
      "2025-03-13 16:02:46,868 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 771\n",
      "2025-03-13 16:02:46,868 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 771 for 399 questions\n",
      "2025-03-13 16:02:46,868 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 771 asynchronously\n",
      "2025-03-13 16:02:46,872 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 980522d710...)\n",
      "2025-03-13 16:02:46,873 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3754\n",
      "2025-03-13 16:02:46,873 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6727\n",
      "2025-03-13 16:02:46,873 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6727 for 399 questions\n",
      "2025-03-13 16:02:46,874 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6727 asynchronously\n",
      "2025-03-13 16:02:46,878 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: fc02c684e1...)\n",
      "2025-03-13 16:02:46,879 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4788\n",
      "2025-03-13 16:02:46,881 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6212\n",
      "2025-03-13 16:02:46,884 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6212 for 399 questions\n",
      "2025-03-13 16:02:46,885 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6212 asynchronously\n",
      "2025-03-13 16:02:46,902 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ffe492b29c...)\n",
      "2025-03-13 16:02:46,906 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 188\n",
      "2025-03-13 16:02:46,909 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2224\n",
      "2025-03-13 16:02:46,909 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2224 for 399 questions\n",
      "2025-03-13 16:02:46,910 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2224 asynchronously\n",
      "2025-03-13 16:02:46,915 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e54940c206...)\n",
      "2025-03-13 16:02:46,917 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5888\n",
      "2025-03-13 16:02:46,920 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4130\n",
      "2025-03-13 16:02:46,920 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4130 for 399 questions\n",
      "2025-03-13 16:02:46,920 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4130 asynchronously\n",
      "2025-03-13 16:02:46,924 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 37753091e8...)\n",
      "2025-03-13 16:02:46,924 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3601\n",
      "2025-03-13 16:02:46,925 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 842\n",
      "2025-03-13 16:02:46,925 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 842 for 399 questions\n",
      "2025-03-13 16:02:46,925 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 842 asynchronously\n",
      "2025-03-13 16:02:46,930 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 98c1a028fc...)\n",
      "2025-03-13 16:02:46,931 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4017\n",
      "2025-03-13 16:02:46,931 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3348\n",
      "2025-03-13 16:02:46,932 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3348 for 399 questions\n",
      "2025-03-13 16:02:46,932 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3348 asynchronously\n",
      "2025-03-13 16:02:46,936 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6f8603bbcb...)\n",
      "2025-03-13 16:02:46,937 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4298\n",
      "2025-03-13 16:02:46,937 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4979\n",
      "2025-03-13 16:02:46,937 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4979 for 399 questions\n",
      "2025-03-13 16:02:46,938 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4979 asynchronously\n",
      "2025-03-13 16:02:46,943 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4385322c09...)\n",
      "2025-03-13 16:02:46,944 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4582\n",
      "2025-03-13 16:02:46,944 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6573\n",
      "2025-03-13 16:02:46,944 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6573 for 399 questions\n",
      "2025-03-13 16:02:46,945 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6573 asynchronously\n",
      "2025-03-13 16:02:46,949 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 732d408594...)\n",
      "2025-03-13 16:02:46,950 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1398\n",
      "2025-03-13 16:02:46,951 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3166\n",
      "2025-03-13 16:02:46,951 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3166 for 399 questions\n",
      "2025-03-13 16:02:46,951 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3166 asynchronously\n",
      "2025-03-13 16:02:46,955 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 524da6e5a8...)\n",
      "2025-03-13 16:02:46,956 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6490\n",
      "2025-03-13 16:02:46,956 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 475\n",
      "2025-03-13 16:02:46,956 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 475 for 399 questions\n",
      "2025-03-13 16:02:46,956 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 475 asynchronously\n",
      "2025-03-13 16:02:46,967 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 2f5add0878...)\n",
      "2025-03-13 16:02:46,969 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5523\n",
      "2025-03-13 16:02:46,970 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5411\n",
      "2025-03-13 16:02:46,970 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5411 for 399 questions\n",
      "2025-03-13 16:02:46,970 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5411 asynchronously\n",
      "2025-03-13 16:02:46,974 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9c94603f4b...)\n",
      "2025-03-13 16:02:46,975 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5166\n",
      "2025-03-13 16:02:46,975 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6468\n",
      "2025-03-13 16:02:46,976 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6468 for 399 questions\n",
      "2025-03-13 16:02:46,976 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6468 asynchronously\n",
      "2025-03-13 16:02:46,980 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c4d7a2f220...)\n",
      "2025-03-13 16:02:46,981 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1180\n",
      "2025-03-13 16:02:46,982 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6094\n",
      "2025-03-13 16:02:46,982 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6094 for 399 questions\n",
      "2025-03-13 16:02:46,982 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6094 asynchronously\n",
      "2025-03-13 16:02:46,986 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9076a1e71f...)\n",
      "2025-03-13 16:02:46,987 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 938\n",
      "2025-03-13 16:02:46,987 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3212\n",
      "2025-03-13 16:02:46,988 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3212 for 399 questions\n",
      "2025-03-13 16:02:46,988 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3212 asynchronously\n",
      "2025-03-13 16:02:46,992 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: eb6213cfe9...)\n",
      "2025-03-13 16:02:46,993 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6975\n",
      "2025-03-13 16:02:46,993 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6092\n",
      "2025-03-13 16:02:46,993 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6092 for 399 questions\n",
      "2025-03-13 16:02:46,993 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6092 asynchronously\n",
      "2025-03-13 16:02:46,997 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7ad1205fe0...)\n",
      "2025-03-13 16:02:46,999 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5280\n",
      "2025-03-13 16:02:46,999 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3595\n",
      "2025-03-13 16:02:46,999 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3595 for 399 questions\n",
      "2025-03-13 16:02:46,999 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3595 asynchronously\n",
      "2025-03-13 16:02:47,003 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9253706558...)\n",
      "2025-03-13 16:02:47,004 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4612\n",
      "2025-03-13 16:02:47,004 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6166\n",
      "2025-03-13 16:02:47,004 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6166 for 399 questions\n",
      "2025-03-13 16:02:47,005 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6166 asynchronously\n",
      "2025-03-13 16:02:47,009 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0c68e08038...)\n",
      "2025-03-13 16:02:47,010 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 124\n",
      "2025-03-13 16:02:47,010 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4406\n",
      "2025-03-13 16:02:47,011 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4406 for 399 questions\n",
      "2025-03-13 16:02:47,011 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4406 asynchronously\n",
      "2025-03-13 16:02:47,015 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 75791c3728...)\n",
      "2025-03-13 16:02:47,016 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4674\n",
      "2025-03-13 16:02:47,016 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 613\n",
      "2025-03-13 16:02:47,016 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 613 for 399 questions\n",
      "2025-03-13 16:02:47,017 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 613 asynchronously\n",
      "2025-03-13 16:02:47,021 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4e79938c7a...)\n",
      "2025-03-13 16:02:47,021 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 7039\n",
      "2025-03-13 16:02:47,022 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5489\n",
      "2025-03-13 16:02:47,022 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5489 for 399 questions\n",
      "2025-03-13 16:02:47,022 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5489 asynchronously\n",
      "2025-03-13 16:02:47,027 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d0628d9089...)\n",
      "2025-03-13 16:02:47,027 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5540\n",
      "2025-03-13 16:02:47,027 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4837\n",
      "2025-03-13 16:02:47,028 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4837 for 399 questions\n",
      "2025-03-13 16:02:47,028 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4837 asynchronously\n",
      "2025-03-13 16:02:47,033 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7553a29325...)\n",
      "2025-03-13 16:02:47,033 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1563\n",
      "2025-03-13 16:02:47,034 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1843\n",
      "2025-03-13 16:02:47,034 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1843 for 399 questions\n",
      "2025-03-13 16:02:47,034 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1843 asynchronously\n",
      "2025-03-13 16:02:47,038 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: b0cf3be78e...)\n",
      "2025-03-13 16:02:47,039 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4763\n",
      "2025-03-13 16:02:47,039 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 519\n",
      "2025-03-13 16:02:47,040 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 519 for 399 questions\n",
      "2025-03-13 16:02:47,040 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 519 asynchronously\n",
      "2025-03-13 16:02:47,057 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ed8b91a8ca...)\n",
      "2025-03-13 16:02:47,062 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5258\n",
      "2025-03-13 16:02:47,065 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6175\n",
      "2025-03-13 16:02:47,067 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6175 for 399 questions\n",
      "2025-03-13 16:02:47,069 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6175 asynchronously\n",
      "2025-03-13 16:02:47,073 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a26fc1b557...)\n",
      "2025-03-13 16:02:47,074 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5745\n",
      "2025-03-13 16:02:47,075 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6575\n",
      "2025-03-13 16:02:47,075 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6575 for 399 questions\n",
      "2025-03-13 16:02:47,075 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6575 asynchronously\n",
      "2025-03-13 16:02:47,083 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ebaad3adec...)\n",
      "2025-03-13 16:02:47,083 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4024\n",
      "2025-03-13 16:02:47,084 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4946\n",
      "2025-03-13 16:02:47,084 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4946 for 399 questions\n",
      "2025-03-13 16:02:47,084 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4946 asynchronously\n",
      "2025-03-13 16:02:47,089 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9d0acf5ec6...)\n",
      "2025-03-13 16:02:47,090 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5546\n",
      "2025-03-13 16:02:47,090 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 888\n",
      "2025-03-13 16:02:47,091 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 888 for 399 questions\n",
      "2025-03-13 16:02:47,091 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 888 asynchronously\n",
      "2025-03-13 16:02:47,095 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a05b1803e0...)\n",
      "2025-03-13 16:02:47,096 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4301\n",
      "2025-03-13 16:02:47,097 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2650\n",
      "2025-03-13 16:02:47,097 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2650 for 399 questions\n",
      "2025-03-13 16:02:47,098 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2650 asynchronously\n",
      "2025-03-13 16:02:47,102 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a432668df7...)\n",
      "2025-03-13 16:02:47,103 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 768\n",
      "2025-03-13 16:02:47,103 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 143\n",
      "2025-03-13 16:02:47,104 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 143 for 399 questions\n",
      "2025-03-13 16:02:47,104 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 143 asynchronously\n",
      "2025-03-13 16:02:47,108 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 45b4fb3f38...)\n",
      "2025-03-13 16:02:47,109 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1237\n",
      "2025-03-13 16:02:47,110 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4658\n",
      "2025-03-13 16:02:47,110 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4658 for 399 questions\n",
      "2025-03-13 16:02:47,111 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4658 asynchronously\n",
      "2025-03-13 16:02:47,114 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 944c695874...)\n",
      "2025-03-13 16:02:47,116 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5308\n",
      "2025-03-13 16:02:47,116 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2182\n",
      "2025-03-13 16:02:47,116 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2182 for 399 questions\n",
      "2025-03-13 16:02:47,117 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2182 asynchronously\n",
      "2025-03-13 16:02:47,121 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 10fdfc7ecc...)\n",
      "2025-03-13 16:02:47,121 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6225\n",
      "2025-03-13 16:02:47,122 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5875\n",
      "2025-03-13 16:02:47,122 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5875 for 399 questions\n",
      "2025-03-13 16:02:47,122 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5875 asynchronously\n",
      "2025-03-13 16:02:47,127 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: feeb8b3fb3...)\n",
      "2025-03-13 16:02:47,128 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2505\n",
      "2025-03-13 16:02:47,128 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3197\n",
      "2025-03-13 16:02:47,128 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3197 for 399 questions\n",
      "2025-03-13 16:02:47,129 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3197 asynchronously\n",
      "2025-03-13 16:02:47,133 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 2a353fbd08...)\n",
      "2025-03-13 16:02:47,134 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5507\n",
      "2025-03-13 16:02:47,134 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6027\n",
      "2025-03-13 16:02:47,134 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6027 for 399 questions\n",
      "2025-03-13 16:02:47,135 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6027 asynchronously\n",
      "2025-03-13 16:02:47,145 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4834e01964...)\n",
      "2025-03-13 16:02:47,146 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5998\n",
      "2025-03-13 16:02:47,147 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4590\n",
      "2025-03-13 16:02:47,148 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4590 for 399 questions\n",
      "2025-03-13 16:02:47,149 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4590 asynchronously\n",
      "2025-03-13 16:02:47,153 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9f1bc98ede...)\n",
      "2025-03-13 16:02:47,153 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2134\n",
      "2025-03-13 16:02:47,154 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4804\n",
      "2025-03-13 16:02:47,154 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4804 for 399 questions\n",
      "2025-03-13 16:02:47,154 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4804 asynchronously\n",
      "2025-03-13 16:02:47,158 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9827dc795d...)\n",
      "2025-03-13 16:02:47,159 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2247\n",
      "2025-03-13 16:02:47,160 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5925\n",
      "2025-03-13 16:02:47,160 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5925 for 399 questions\n",
      "2025-03-13 16:02:47,160 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5925 asynchronously\n",
      "2025-03-13 16:02:47,164 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 696ceee5ce...)\n",
      "2025-03-13 16:02:47,165 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2420\n",
      "2025-03-13 16:02:47,165 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5351\n",
      "2025-03-13 16:02:47,165 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5351 for 399 questions\n",
      "2025-03-13 16:02:47,166 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5351 asynchronously\n",
      "2025-03-13 16:02:47,169 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4aa9ba0a55...)\n",
      "2025-03-13 16:02:47,170 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4077\n",
      "2025-03-13 16:02:47,170 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5111\n",
      "2025-03-13 16:02:47,171 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5111 for 399 questions\n",
      "2025-03-13 16:02:47,171 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5111 asynchronously\n",
      "2025-03-13 16:02:47,175 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: cce5569140...)\n",
      "2025-03-13 16:02:47,176 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 771\n",
      "2025-03-13 16:02:47,176 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1267\n",
      "2025-03-13 16:02:47,176 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1267 for 399 questions\n",
      "2025-03-13 16:02:47,176 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1267 asynchronously\n",
      "2025-03-13 16:02:47,180 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c83c0e41e5...)\n",
      "2025-03-13 16:02:47,181 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6727\n",
      "2025-03-13 16:02:47,182 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1168\n",
      "2025-03-13 16:02:47,182 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1168 for 399 questions\n",
      "2025-03-13 16:02:47,182 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1168 asynchronously\n",
      "2025-03-13 16:02:47,199 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 619d9eb408...)\n",
      "2025-03-13 16:02:47,204 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6212\n",
      "2025-03-13 16:02:47,206 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 7034\n",
      "2025-03-13 16:02:47,207 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 7034 for 399 questions\n",
      "2025-03-13 16:02:47,208 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 7034 asynchronously\n",
      "2025-03-13 16:02:47,216 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e7478638c0...)\n",
      "2025-03-13 16:02:47,217 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2224\n",
      "2025-03-13 16:02:47,217 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2959\n",
      "2025-03-13 16:02:47,218 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2959 for 399 questions\n",
      "2025-03-13 16:02:47,218 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2959 asynchronously\n",
      "2025-03-13 16:02:47,226 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9733e50cc1...)\n",
      "2025-03-13 16:02:47,227 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4130\n",
      "2025-03-13 16:02:47,227 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1185\n",
      "2025-03-13 16:02:47,228 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1185 for 399 questions\n",
      "2025-03-13 16:02:47,228 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1185 asynchronously\n",
      "2025-03-13 16:02:47,232 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: bf51cbb220...)\n",
      "2025-03-13 16:02:47,233 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 842\n",
      "2025-03-13 16:02:47,233 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6475\n",
      "2025-03-13 16:02:47,234 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6475 for 399 questions\n",
      "2025-03-13 16:02:47,234 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6475 asynchronously\n",
      "2025-03-13 16:02:47,238 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4222ef2751...)\n",
      "2025-03-13 16:02:47,238 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3348\n",
      "2025-03-13 16:02:47,239 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2640\n",
      "2025-03-13 16:02:47,239 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2640 for 399 questions\n",
      "2025-03-13 16:02:47,239 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2640 asynchronously\n",
      "2025-03-13 16:02:47,243 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 3272e8844c...)\n",
      "2025-03-13 16:02:47,244 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4979\n",
      "2025-03-13 16:02:47,244 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2851\n",
      "2025-03-13 16:02:47,244 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2851 for 399 questions\n",
      "2025-03-13 16:02:47,245 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2851 asynchronously\n",
      "2025-03-13 16:02:47,249 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e96f1701ae...)\n",
      "2025-03-13 16:02:47,250 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6573\n",
      "2025-03-13 16:02:47,250 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4617\n",
      "2025-03-13 16:02:47,250 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4617 for 399 questions\n",
      "2025-03-13 16:02:47,250 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4617 asynchronously\n",
      "2025-03-13 16:02:47,255 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: abbc59b3c8...)\n",
      "2025-03-13 16:02:47,255 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3166\n",
      "2025-03-13 16:02:47,256 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3013\n",
      "2025-03-13 16:02:47,256 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3013 for 399 questions\n",
      "2025-03-13 16:02:47,256 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3013 asynchronously\n",
      "2025-03-13 16:02:47,260 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 64613a2be8...)\n",
      "2025-03-13 16:02:47,261 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 475\n",
      "2025-03-13 16:02:47,261 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2661\n",
      "2025-03-13 16:02:47,262 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2661 for 399 questions\n",
      "2025-03-13 16:02:47,262 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2661 asynchronously\n",
      "2025-03-13 16:02:47,266 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a3620723f8...)\n",
      "2025-03-13 16:02:47,267 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5411\n",
      "2025-03-13 16:02:47,268 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5315\n",
      "2025-03-13 16:02:47,268 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5315 for 399 questions\n",
      "2025-03-13 16:02:47,268 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5315 asynchronously\n",
      "2025-03-13 16:02:47,272 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 52c3308bbb...)\n",
      "2025-03-13 16:02:47,272 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6468\n",
      "2025-03-13 16:02:47,273 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2565\n",
      "2025-03-13 16:02:47,273 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2565 for 399 questions\n",
      "2025-03-13 16:02:47,273 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2565 asynchronously\n",
      "2025-03-13 16:02:47,278 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 678444502b...)\n",
      "2025-03-13 16:02:47,278 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6094\n",
      "2025-03-13 16:02:47,279 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 651\n",
      "2025-03-13 16:02:47,279 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 651 for 399 questions\n",
      "2025-03-13 16:02:47,279 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 651 asynchronously\n",
      "2025-03-13 16:02:47,284 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: bec8322aa0...)\n",
      "2025-03-13 16:02:47,285 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3212\n",
      "2025-03-13 16:02:47,285 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4314\n",
      "2025-03-13 16:02:47,286 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4314 for 399 questions\n",
      "2025-03-13 16:02:47,286 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4314 asynchronously\n",
      "2025-03-13 16:02:47,299 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4cd615eb3f...)\n",
      "2025-03-13 16:02:47,301 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6092\n",
      "2025-03-13 16:02:47,301 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2278\n",
      "2025-03-13 16:02:47,302 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2278 for 399 questions\n",
      "2025-03-13 16:02:47,302 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2278 asynchronously\n",
      "2025-03-13 16:02:47,307 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: b79b80dc9a...)\n",
      "2025-03-13 16:02:47,308 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3595\n",
      "2025-03-13 16:02:47,308 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6815\n",
      "2025-03-13 16:02:47,309 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6815 for 399 questions\n",
      "2025-03-13 16:02:47,309 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6815 asynchronously\n",
      "2025-03-13 16:02:47,313 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 400050fb32...)\n",
      "2025-03-13 16:02:47,315 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6166\n",
      "2025-03-13 16:02:47,315 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3994\n",
      "2025-03-13 16:02:47,316 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3994 for 399 questions\n",
      "2025-03-13 16:02:47,317 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3994 asynchronously\n",
      "2025-03-13 16:02:47,321 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: fc5c9118e8...)\n",
      "2025-03-13 16:02:47,322 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4406\n",
      "2025-03-13 16:02:47,323 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2804\n",
      "2025-03-13 16:02:47,323 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2804 for 399 questions\n",
      "2025-03-13 16:02:47,324 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2804 asynchronously\n",
      "2025-03-13 16:02:47,328 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: bd2e3bd1d0...)\n",
      "2025-03-13 16:02:47,330 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 613\n",
      "2025-03-13 16:02:47,330 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3790\n",
      "2025-03-13 16:02:47,331 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3790 for 399 questions\n",
      "2025-03-13 16:02:47,331 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3790 asynchronously\n",
      "2025-03-13 16:02:47,335 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c41bdd4c44...)\n",
      "2025-03-13 16:02:47,336 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5489\n",
      "2025-03-13 16:02:47,336 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5261\n",
      "2025-03-13 16:02:47,337 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5261 for 399 questions\n",
      "2025-03-13 16:02:47,338 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5261 asynchronously\n",
      "2025-03-13 16:02:47,342 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: f990e6c022...)\n",
      "2025-03-13 16:02:47,343 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4837\n",
      "2025-03-13 16:02:47,343 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 737\n",
      "2025-03-13 16:02:47,343 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 737 for 399 questions\n",
      "2025-03-13 16:02:47,344 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 737 asynchronously\n",
      "2025-03-13 16:02:47,349 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c1e676db46...)\n",
      "2025-03-13 16:02:47,350 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1843\n",
      "2025-03-13 16:02:47,351 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2815\n",
      "2025-03-13 16:02:47,351 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2815 for 399 questions\n",
      "2025-03-13 16:02:47,351 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2815 asynchronously\n",
      "2025-03-13 16:02:47,355 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c66a2a30d4...)\n",
      "2025-03-13 16:02:47,356 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 519\n",
      "2025-03-13 16:02:47,356 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 472\n",
      "2025-03-13 16:02:47,356 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 472 for 399 questions\n",
      "2025-03-13 16:02:47,357 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 472 asynchronously\n",
      "2025-03-13 16:02:47,361 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 53fd8d8300...)\n",
      "2025-03-13 16:02:47,362 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6175\n",
      "2025-03-13 16:02:47,362 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2998\n",
      "2025-03-13 16:02:47,362 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2998 for 399 questions\n",
      "2025-03-13 16:02:47,363 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2998 asynchronously\n",
      "2025-03-13 16:02:47,367 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 64e4222ed7...)\n",
      "2025-03-13 16:02:47,368 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6575\n",
      "2025-03-13 16:02:47,368 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5583\n",
      "2025-03-13 16:02:47,368 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5583 for 399 questions\n",
      "2025-03-13 16:02:47,369 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5583 asynchronously\n",
      "2025-03-13 16:02:47,373 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 1d93148b7a...)\n",
      "2025-03-13 16:02:47,375 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4946\n",
      "2025-03-13 16:02:47,375 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6788\n",
      "2025-03-13 16:02:47,375 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6788 for 399 questions\n",
      "2025-03-13 16:02:47,375 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6788 asynchronously\n",
      "2025-03-13 16:02:47,380 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: ddcb81eb5a...)\n",
      "2025-03-13 16:02:47,380 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 888\n",
      "2025-03-13 16:02:47,381 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6482\n",
      "2025-03-13 16:02:47,381 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6482 for 399 questions\n",
      "2025-03-13 16:02:47,381 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6482 asynchronously\n",
      "2025-03-13 16:02:47,386 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 25e5cec913...)\n",
      "2025-03-13 16:02:47,386 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2650\n",
      "2025-03-13 16:02:47,387 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2070\n",
      "2025-03-13 16:02:47,387 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2070 for 399 questions\n",
      "2025-03-13 16:02:47,387 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2070 asynchronously\n",
      "2025-03-13 16:02:47,392 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 8cd36d9230...)\n",
      "2025-03-13 16:02:47,392 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 143\n",
      "2025-03-13 16:02:47,393 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5772\n",
      "2025-03-13 16:02:47,393 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5772 for 399 questions\n",
      "2025-03-13 16:02:47,393 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5772 asynchronously\n",
      "2025-03-13 16:02:47,397 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 8ad61f87fc...)\n",
      "2025-03-13 16:02:47,398 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4658\n",
      "2025-03-13 16:02:47,399 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6164\n",
      "2025-03-13 16:02:47,399 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6164 for 399 questions\n",
      "2025-03-13 16:02:47,399 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6164 asynchronously\n",
      "2025-03-13 16:02:47,403 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 339a94637d...)\n",
      "2025-03-13 16:02:47,404 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2182\n",
      "2025-03-13 16:02:47,404 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6913\n",
      "2025-03-13 16:02:47,404 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6913 for 399 questions\n",
      "2025-03-13 16:02:47,405 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6913 asynchronously\n",
      "2025-03-13 16:02:47,409 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 39811a9616...)\n",
      "2025-03-13 16:02:47,409 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5875\n",
      "2025-03-13 16:02:47,410 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1555\n",
      "2025-03-13 16:02:47,410 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1555 for 399 questions\n",
      "2025-03-13 16:02:47,410 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1555 asynchronously\n",
      "2025-03-13 16:02:47,414 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4bfd816ae0...)\n",
      "2025-03-13 16:02:47,416 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3197\n",
      "2025-03-13 16:02:47,416 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 263\n",
      "2025-03-13 16:02:47,416 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 263 for 399 questions\n",
      "2025-03-13 16:02:47,416 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 263 asynchronously\n",
      "2025-03-13 16:02:47,420 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4b9abe8dd6...)\n",
      "2025-03-13 16:02:47,421 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6027\n",
      "2025-03-13 16:02:47,421 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1343\n",
      "2025-03-13 16:02:47,421 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1343 for 399 questions\n",
      "2025-03-13 16:02:47,421 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1343 asynchronously\n",
      "2025-03-13 16:02:47,426 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 7bdda98ceb...)\n",
      "2025-03-13 16:02:47,426 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4590\n",
      "2025-03-13 16:02:47,426 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6751\n",
      "2025-03-13 16:02:47,427 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6751 for 399 questions\n",
      "2025-03-13 16:02:47,427 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6751 asynchronously\n",
      "2025-03-13 16:02:47,431 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a22ac130c3...)\n",
      "2025-03-13 16:02:47,432 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4804\n",
      "2025-03-13 16:02:47,432 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4884\n",
      "2025-03-13 16:02:47,432 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4884 for 399 questions\n",
      "2025-03-13 16:02:47,433 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4884 asynchronously\n",
      "2025-03-13 16:02:47,437 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a07986c286...)\n",
      "2025-03-13 16:02:47,438 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5925\n",
      "2025-03-13 16:02:47,438 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6652\n",
      "2025-03-13 16:02:47,438 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6652 for 399 questions\n",
      "2025-03-13 16:02:47,438 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6652 asynchronously\n",
      "2025-03-13 16:02:47,450 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 576f4c5a27...)\n",
      "2025-03-13 16:02:47,470 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5351\n",
      "2025-03-13 16:02:47,483 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1421\n",
      "2025-03-13 16:02:47,483 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1421 for 399 questions\n",
      "2025-03-13 16:02:47,484 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1421 asynchronously\n",
      "2025-03-13 16:02:47,485 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: cc29a432b3...)\n",
      "2025-03-13 16:02:47,486 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5111\n",
      "2025-03-13 16:02:47,488 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4100\n",
      "2025-03-13 16:02:47,493 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4100 for 399 questions\n",
      "2025-03-13 16:02:47,494 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4100 asynchronously\n",
      "2025-03-13 16:02:47,496 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e40f4921b0...)\n",
      "2025-03-13 16:02:47,499 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1267\n",
      "2025-03-13 16:02:47,499 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1189\n",
      "2025-03-13 16:02:47,499 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1189 for 399 questions\n",
      "2025-03-13 16:02:47,500 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1189 asynchronously\n",
      "2025-03-13 16:02:47,503 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 963baecf8e...)\n",
      "2025-03-13 16:02:47,506 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1168\n",
      "2025-03-13 16:02:47,506 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1815\n",
      "2025-03-13 16:02:47,507 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1815 for 399 questions\n",
      "2025-03-13 16:02:47,508 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1815 asynchronously\n",
      "2025-03-13 16:02:47,511 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 5cce7bdaa3...)\n",
      "2025-03-13 16:02:47,511 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 7034\n",
      "2025-03-13 16:02:47,512 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3050\n",
      "2025-03-13 16:02:47,512 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3050 for 399 questions\n",
      "2025-03-13 16:02:47,512 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3050 asynchronously\n",
      "2025-03-13 16:02:47,517 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 1a617773f1...)\n",
      "2025-03-13 16:02:47,518 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2959\n",
      "2025-03-13 16:02:47,519 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2694\n",
      "2025-03-13 16:02:47,520 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2694 for 399 questions\n",
      "2025-03-13 16:02:47,520 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2694 asynchronously\n",
      "2025-03-13 16:02:47,525 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a4a8b0393a...)\n",
      "2025-03-13 16:02:47,526 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1185\n",
      "2025-03-13 16:02:47,526 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5799\n",
      "2025-03-13 16:02:47,526 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5799 for 399 questions\n",
      "2025-03-13 16:02:47,527 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5799 asynchronously\n",
      "2025-03-13 16:02:47,531 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9f9e2e5c78...)\n",
      "2025-03-13 16:02:47,532 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6475\n",
      "2025-03-13 16:02:47,532 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4027\n",
      "2025-03-13 16:02:47,532 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4027 for 399 questions\n",
      "2025-03-13 16:02:47,533 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4027 asynchronously\n",
      "2025-03-13 16:02:47,537 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 599d176c7a...)\n",
      "2025-03-13 16:02:47,538 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2640\n",
      "2025-03-13 16:02:47,538 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1034\n",
      "2025-03-13 16:02:47,538 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1034 for 399 questions\n",
      "2025-03-13 16:02:47,539 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1034 asynchronously\n",
      "2025-03-13 16:02:47,543 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4eaa0b5c2d...)\n",
      "2025-03-13 16:02:47,545 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2851\n",
      "2025-03-13 16:02:47,545 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 559\n",
      "2025-03-13 16:02:47,545 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 559 for 399 questions\n",
      "2025-03-13 16:02:47,546 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 559 asynchronously\n",
      "2025-03-13 16:02:47,549 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 5426dcfdcc...)\n",
      "2025-03-13 16:02:47,550 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4617\n",
      "2025-03-13 16:02:47,551 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5937\n",
      "2025-03-13 16:02:47,551 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5937 for 399 questions\n",
      "2025-03-13 16:02:47,551 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5937 asynchronously\n",
      "2025-03-13 16:02:47,555 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 46602f1240...)\n",
      "2025-03-13 16:02:47,556 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3013\n",
      "2025-03-13 16:02:47,556 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3074\n",
      "2025-03-13 16:02:47,556 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3074 for 399 questions\n",
      "2025-03-13 16:02:47,556 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3074 asynchronously\n",
      "2025-03-13 16:02:47,560 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e0c1aad657...)\n",
      "2025-03-13 16:02:47,561 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2661\n",
      "2025-03-13 16:02:47,562 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5668\n",
      "2025-03-13 16:02:47,562 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5668 for 399 questions\n",
      "2025-03-13 16:02:47,562 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5668 asynchronously\n",
      "2025-03-13 16:02:47,566 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0d5db2b198...)\n",
      "2025-03-13 16:02:47,567 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5315\n",
      "2025-03-13 16:02:47,567 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1379\n",
      "2025-03-13 16:02:47,567 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1379 for 399 questions\n",
      "2025-03-13 16:02:47,568 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1379 asynchronously\n",
      "2025-03-13 16:02:47,572 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0dd75f667a...)\n",
      "2025-03-13 16:02:47,573 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2565\n",
      "2025-03-13 16:02:47,573 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5246\n",
      "2025-03-13 16:02:47,573 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5246 for 399 questions\n",
      "2025-03-13 16:02:47,574 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5246 asynchronously\n",
      "2025-03-13 16:02:47,578 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 11d243dddd...)\n",
      "2025-03-13 16:02:47,579 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 651\n",
      "2025-03-13 16:02:47,579 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2014\n",
      "2025-03-13 16:02:47,579 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2014 for 399 questions\n",
      "2025-03-13 16:02:47,580 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2014 asynchronously\n",
      "2025-03-13 16:02:47,585 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4a53e68d71...)\n",
      "2025-03-13 16:02:47,586 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4314\n",
      "2025-03-13 16:02:47,586 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3728\n",
      "2025-03-13 16:02:47,586 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3728 for 399 questions\n",
      "2025-03-13 16:02:47,587 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3728 asynchronously\n",
      "2025-03-13 16:02:47,590 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9a55ee1654...)\n",
      "2025-03-13 16:02:47,591 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2278\n",
      "2025-03-13 16:02:47,591 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3528\n",
      "2025-03-13 16:02:47,591 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3528 for 399 questions\n",
      "2025-03-13 16:02:47,592 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3528 asynchronously\n",
      "2025-03-13 16:02:47,613 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9f26f82d83...)\n",
      "2025-03-13 16:02:47,617 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6815\n",
      "2025-03-13 16:02:47,619 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6224\n",
      "2025-03-13 16:02:47,619 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6224 for 399 questions\n",
      "2025-03-13 16:02:47,621 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6224 asynchronously\n",
      "2025-03-13 16:02:47,633 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 18c3bbe604...)\n",
      "2025-03-13 16:02:47,635 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3994\n",
      "2025-03-13 16:02:47,635 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2579\n",
      "2025-03-13 16:02:47,636 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2579 for 399 questions\n",
      "2025-03-13 16:02:47,636 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2579 asynchronously\n",
      "2025-03-13 16:02:47,644 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 69a91bef6f...)\n",
      "2025-03-13 16:02:47,645 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2804\n",
      "2025-03-13 16:02:47,646 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6950\n",
      "2025-03-13 16:02:47,646 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6950 for 399 questions\n",
      "2025-03-13 16:02:47,647 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6950 asynchronously\n",
      "2025-03-13 16:02:47,652 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 217144bfcf...)\n",
      "2025-03-13 16:02:47,652 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3790\n",
      "2025-03-13 16:02:47,653 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6508\n",
      "2025-03-13 16:02:47,653 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6508 for 399 questions\n",
      "2025-03-13 16:02:47,654 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6508 asynchronously\n",
      "2025-03-13 16:02:47,659 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e59de4baef...)\n",
      "2025-03-13 16:02:47,660 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5261\n",
      "2025-03-13 16:02:47,661 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1593\n",
      "2025-03-13 16:02:47,661 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1593 for 399 questions\n",
      "2025-03-13 16:02:47,661 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1593 asynchronously\n",
      "2025-03-13 16:02:47,666 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6a50997031...)\n",
      "2025-03-13 16:02:47,668 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 737\n",
      "2025-03-13 16:02:47,668 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6724\n",
      "2025-03-13 16:02:47,668 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6724 for 399 questions\n",
      "2025-03-13 16:02:47,669 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6724 asynchronously\n",
      "2025-03-13 16:02:47,673 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 27e5f9053f...)\n",
      "2025-03-13 16:02:47,674 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2815\n",
      "2025-03-13 16:02:47,674 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3805\n",
      "2025-03-13 16:02:47,674 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3805 for 399 questions\n",
      "2025-03-13 16:02:47,675 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3805 asynchronously\n",
      "2025-03-13 16:02:47,680 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: fea31c5c96...)\n",
      "2025-03-13 16:02:47,681 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 472\n",
      "2025-03-13 16:02:47,682 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 206\n",
      "2025-03-13 16:02:47,682 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 206 for 399 questions\n",
      "2025-03-13 16:02:47,682 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 206 asynchronously\n",
      "2025-03-13 16:02:47,686 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: b86f330a2b...)\n",
      "2025-03-13 16:02:47,687 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2998\n",
      "2025-03-13 16:02:47,688 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4583\n",
      "2025-03-13 16:02:47,688 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4583 for 399 questions\n",
      "2025-03-13 16:02:47,688 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4583 asynchronously\n",
      "2025-03-13 16:02:47,693 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: f26673b970...)\n",
      "2025-03-13 16:02:47,693 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5583\n",
      "2025-03-13 16:02:47,694 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2381\n",
      "2025-03-13 16:02:47,694 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2381 for 399 questions\n",
      "2025-03-13 16:02:47,694 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2381 asynchronously\n",
      "2025-03-13 16:02:47,699 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a43903ae02...)\n",
      "2025-03-13 16:02:47,699 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6788\n",
      "2025-03-13 16:02:47,700 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 840\n",
      "2025-03-13 16:02:47,700 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 840 for 399 questions\n",
      "2025-03-13 16:02:47,700 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 840 asynchronously\n",
      "2025-03-13 16:02:47,704 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 2bf25357ee...)\n",
      "2025-03-13 16:02:47,705 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6482\n",
      "2025-03-13 16:02:47,705 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1326\n",
      "2025-03-13 16:02:47,705 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1326 for 399 questions\n",
      "2025-03-13 16:02:47,706 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1326 asynchronously\n",
      "2025-03-13 16:02:47,710 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 86c3c2ad9e...)\n",
      "2025-03-13 16:02:47,711 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2070\n",
      "2025-03-13 16:02:47,711 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2260\n",
      "2025-03-13 16:02:47,711 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2260 for 399 questions\n",
      "2025-03-13 16:02:47,712 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2260 asynchronously\n",
      "2025-03-13 16:02:47,716 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9cf59d9db2...)\n",
      "2025-03-13 16:02:47,717 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5772\n",
      "2025-03-13 16:02:47,717 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2102\n",
      "2025-03-13 16:02:47,717 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2102 for 399 questions\n",
      "2025-03-13 16:02:47,717 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2102 asynchronously\n",
      "2025-03-13 16:02:47,722 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: e1c9d0317a...)\n",
      "2025-03-13 16:02:47,722 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6164\n",
      "2025-03-13 16:02:47,723 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 987\n",
      "2025-03-13 16:02:47,723 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 987 for 399 questions\n",
      "2025-03-13 16:02:47,723 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 987 asynchronously\n",
      "2025-03-13 16:02:47,751 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d5aa3ccad1...)\n",
      "2025-03-13 16:02:47,760 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6913\n",
      "2025-03-13 16:02:47,760 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5506\n",
      "2025-03-13 16:02:47,761 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5506 for 399 questions\n",
      "2025-03-13 16:02:47,761 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5506 asynchronously\n",
      "2025-03-13 16:02:47,766 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: b5ba8f5c16...)\n",
      "2025-03-13 16:02:47,769 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1555\n",
      "2025-03-13 16:02:47,769 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2385\n",
      "2025-03-13 16:02:47,770 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2385 for 399 questions\n",
      "2025-03-13 16:02:47,771 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2385 asynchronously\n",
      "2025-03-13 16:02:47,775 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 55928dd842...)\n",
      "2025-03-13 16:02:47,776 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 263\n",
      "2025-03-13 16:02:47,776 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4174\n",
      "2025-03-13 16:02:47,776 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4174 for 399 questions\n",
      "2025-03-13 16:02:47,777 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4174 asynchronously\n",
      "2025-03-13 16:02:47,781 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 145b92ff23...)\n",
      "2025-03-13 16:02:47,782 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1343\n",
      "2025-03-13 16:02:47,782 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3495\n",
      "2025-03-13 16:02:47,782 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3495 for 399 questions\n",
      "2025-03-13 16:02:47,782 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3495 asynchronously\n",
      "2025-03-13 16:02:47,787 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: dee2673d5c...)\n",
      "2025-03-13 16:02:47,788 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6751\n",
      "2025-03-13 16:02:47,788 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6115\n",
      "2025-03-13 16:02:47,789 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6115 for 399 questions\n",
      "2025-03-13 16:02:47,789 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6115 asynchronously\n",
      "2025-03-13 16:02:47,792 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: fa834fbb2c...)\n",
      "2025-03-13 16:02:47,793 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4884\n",
      "2025-03-13 16:02:47,793 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3378\n",
      "2025-03-13 16:02:47,794 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3378 for 399 questions\n",
      "2025-03-13 16:02:47,794 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3378 asynchronously\n",
      "2025-03-13 16:02:47,799 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d45096a5dc...)\n",
      "2025-03-13 16:02:47,799 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6652\n",
      "2025-03-13 16:02:47,800 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6920\n",
      "2025-03-13 16:02:47,800 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6920 for 399 questions\n",
      "2025-03-13 16:02:47,800 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6920 asynchronously\n",
      "2025-03-13 16:02:47,804 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 3100dbb08d...)\n",
      "2025-03-13 16:02:47,805 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1421\n",
      "2025-03-13 16:02:47,805 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6515\n",
      "2025-03-13 16:02:47,806 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6515 for 399 questions\n",
      "2025-03-13 16:02:47,806 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6515 asynchronously\n",
      "2025-03-13 16:02:47,810 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 16200a131b...)\n",
      "2025-03-13 16:02:47,811 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4100\n",
      "2025-03-13 16:02:47,812 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2213\n",
      "2025-03-13 16:02:47,813 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2213 for 399 questions\n",
      "2025-03-13 16:02:47,813 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2213 asynchronously\n",
      "2025-03-13 16:02:47,817 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: c2ca6f04a1...)\n",
      "2025-03-13 16:02:47,819 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1189\n",
      "2025-03-13 16:02:47,819 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4061\n",
      "2025-03-13 16:02:47,820 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4061 for 399 questions\n",
      "2025-03-13 16:02:47,820 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4061 asynchronously\n",
      "2025-03-13 16:02:47,824 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: de6fcd0757...)\n",
      "2025-03-13 16:02:47,825 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1815\n",
      "2025-03-13 16:02:47,825 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3637\n",
      "2025-03-13 16:02:47,826 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3637 for 399 questions\n",
      "2025-03-13 16:02:47,826 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3637 asynchronously\n",
      "2025-03-13 16:02:47,831 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 631e2e472f...)\n",
      "2025-03-13 16:02:47,833 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3050\n",
      "2025-03-13 16:02:47,833 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6042\n",
      "2025-03-13 16:02:47,834 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6042 for 399 questions\n",
      "2025-03-13 16:02:47,834 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6042 asynchronously\n",
      "2025-03-13 16:02:47,838 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 8b4aec4955...)\n",
      "2025-03-13 16:02:47,839 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2694\n",
      "2025-03-13 16:02:47,840 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1824\n",
      "2025-03-13 16:02:47,840 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1824 for 399 questions\n",
      "2025-03-13 16:02:47,840 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1824 asynchronously\n",
      "2025-03-13 16:02:47,844 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 4de07264bd...)\n",
      "2025-03-13 16:02:47,845 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5799\n",
      "2025-03-13 16:02:47,845 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4121\n",
      "2025-03-13 16:02:47,846 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4121 for 399 questions\n",
      "2025-03-13 16:02:47,846 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4121 asynchronously\n",
      "2025-03-13 16:02:47,851 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 8f87239e80...)\n",
      "2025-03-13 16:02:47,853 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4027\n",
      "2025-03-13 16:02:47,854 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1425\n",
      "2025-03-13 16:02:47,854 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1425 for 399 questions\n",
      "2025-03-13 16:02:47,855 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1425 asynchronously\n",
      "2025-03-13 16:02:47,858 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 08373371b4...)\n",
      "2025-03-13 16:02:47,859 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1034\n",
      "2025-03-13 16:02:47,859 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6165\n",
      "2025-03-13 16:02:47,859 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6165 for 399 questions\n",
      "2025-03-13 16:02:47,860 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6165 asynchronously\n",
      "2025-03-13 16:02:47,863 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9108957ec7...)\n",
      "2025-03-13 16:02:47,864 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 559\n",
      "2025-03-13 16:02:47,865 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4302\n",
      "2025-03-13 16:02:47,865 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4302 for 399 questions\n",
      "2025-03-13 16:02:47,865 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4302 asynchronously\n",
      "2025-03-13 16:02:47,870 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 69e4c2a4b2...)\n",
      "2025-03-13 16:02:47,870 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5937\n",
      "2025-03-13 16:02:47,871 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1091\n",
      "2025-03-13 16:02:47,871 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1091 for 399 questions\n",
      "2025-03-13 16:02:47,871 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1091 asynchronously\n",
      "2025-03-13 16:02:47,917 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: eb3f6c7279...)\n",
      "2025-03-13 16:02:47,921 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3074\n",
      "2025-03-13 16:02:47,922 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 29\n",
      "2025-03-13 16:02:47,922 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 29 for 399 questions\n",
      "2025-03-13 16:02:47,923 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 29 asynchronously\n",
      "2025-03-13 16:02:47,930 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 23c12d27b5...)\n",
      "2025-03-13 16:02:47,931 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5668\n",
      "2025-03-13 16:02:47,932 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5634\n",
      "2025-03-13 16:02:47,932 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5634 for 399 questions\n",
      "2025-03-13 16:02:47,932 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5634 asynchronously\n",
      "2025-03-13 16:02:47,937 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6badce2955...)\n",
      "2025-03-13 16:02:47,937 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1379\n",
      "2025-03-13 16:02:47,938 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6351\n",
      "2025-03-13 16:02:47,938 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6351 for 399 questions\n",
      "2025-03-13 16:02:47,938 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6351 asynchronously\n",
      "2025-03-13 16:02:47,943 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 77c028924f...)\n",
      "2025-03-13 16:02:47,944 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5246\n",
      "2025-03-13 16:02:47,944 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3374\n",
      "2025-03-13 16:02:47,944 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3374 for 399 questions\n",
      "2025-03-13 16:02:47,944 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3374 asynchronously\n",
      "2025-03-13 16:02:47,950 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: d949f7df25...)\n",
      "2025-03-13 16:02:47,951 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2014\n",
      "2025-03-13 16:02:47,951 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2301\n",
      "2025-03-13 16:02:47,951 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2301 for 399 questions\n",
      "2025-03-13 16:02:47,952 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2301 asynchronously\n",
      "2025-03-13 16:02:47,956 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6f6e012528...)\n",
      "2025-03-13 16:02:47,957 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3728\n",
      "2025-03-13 16:02:47,957 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6758\n",
      "2025-03-13 16:02:47,958 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6758 for 399 questions\n",
      "2025-03-13 16:02:47,958 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6758 asynchronously\n",
      "2025-03-13 16:02:47,967 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 75e2f63f9e...)\n",
      "2025-03-13 16:02:47,969 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3528\n",
      "2025-03-13 16:02:47,971 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6589\n",
      "2025-03-13 16:02:47,972 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6589 for 399 questions\n",
      "2025-03-13 16:02:47,973 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6589 asynchronously\n",
      "2025-03-13 16:02:47,976 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 90b647b7b6...)\n",
      "2025-03-13 16:02:47,978 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6224\n",
      "2025-03-13 16:02:47,978 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3783\n",
      "2025-03-13 16:02:47,979 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3783 for 399 questions\n",
      "2025-03-13 16:02:47,979 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3783 asynchronously\n",
      "2025-03-13 16:02:47,985 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 9ac2945044...)\n",
      "2025-03-13 16:02:47,986 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2579\n",
      "2025-03-13 16:02:47,987 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2923\n",
      "2025-03-13 16:02:47,988 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2923 for 399 questions\n",
      "2025-03-13 16:02:47,989 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2923 asynchronously\n",
      "2025-03-13 16:02:47,993 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: aeb58f0628...)\n",
      "2025-03-13 16:02:47,994 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6950\n",
      "2025-03-13 16:02:47,995 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 3150\n",
      "2025-03-13 16:02:47,996 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 3150 for 399 questions\n",
      "2025-03-13 16:02:47,996 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 3150 asynchronously\n",
      "2025-03-13 16:02:48,002 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 6ff9f57441...)\n",
      "2025-03-13 16:02:48,003 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6508\n",
      "2025-03-13 16:02:48,004 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1143\n",
      "2025-03-13 16:02:48,004 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1143 for 399 questions\n",
      "2025-03-13 16:02:48,005 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1143 asynchronously\n",
      "2025-03-13 16:02:48,011 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 5329e6aba1...)\n",
      "2025-03-13 16:02:48,014 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1593\n",
      "2025-03-13 16:02:48,015 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6182\n",
      "2025-03-13 16:02:48,016 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6182 for 399 questions\n",
      "2025-03-13 16:02:48,017 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6182 asynchronously\n",
      "2025-03-13 16:02:48,022 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 2fe7e0176b...)\n",
      "2025-03-13 16:02:48,027 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 6724\n",
      "2025-03-13 16:02:48,040 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 5342\n",
      "2025-03-13 16:02:48,041 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 5342 for 399 questions\n",
      "2025-03-13 16:02:48,043 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 5342 asynchronously\n",
      "2025-03-13 16:02:48,058 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 12b006dbe9...)\n",
      "2025-03-13 16:02:48,062 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 3805\n",
      "2025-03-13 16:02:48,063 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1066\n",
      "2025-03-13 16:02:48,063 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1066 for 399 questions\n",
      "2025-03-13 16:02:48,063 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1066 asynchronously\n",
      "2025-03-13 16:02:48,069 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 8b1afb23aa...)\n",
      "2025-03-13 16:02:48,073 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 206\n",
      "2025-03-13 16:02:48,074 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1817\n",
      "2025-03-13 16:02:48,074 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1817 for 399 questions\n",
      "2025-03-13 16:02:48,075 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1817 asynchronously\n",
      "2025-03-13 16:02:48,077 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 24f47c6c98...)\n",
      "2025-03-13 16:02:48,078 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 4583\n",
      "2025-03-13 16:02:48,078 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1536\n",
      "2025-03-13 16:02:48,079 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1536 for 399 questions\n",
      "2025-03-13 16:02:48,079 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1536 asynchronously\n",
      "2025-03-13 16:02:48,083 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: afbbb9f7be...)\n",
      "2025-03-13 16:02:48,084 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2381\n",
      "2025-03-13 16:02:48,084 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4925\n",
      "2025-03-13 16:02:48,084 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4925 for 399 questions\n",
      "2025-03-13 16:02:48,085 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4925 asynchronously\n",
      "2025-03-13 16:02:48,089 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 1c9730860d...)\n",
      "2025-03-13 16:02:48,090 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 840\n",
      "2025-03-13 16:02:48,090 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 2526\n",
      "2025-03-13 16:02:48,090 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 2526 for 399 questions\n",
      "2025-03-13 16:02:48,091 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 2526 asynchronously\n",
      "2025-03-13 16:02:48,095 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a3d5b943f9...)\n",
      "2025-03-13 16:02:48,095 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 1326\n",
      "2025-03-13 16:02:48,096 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6939\n",
      "2025-03-13 16:02:48,096 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6939 for 399 questions\n",
      "2025-03-13 16:02:48,096 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6939 asynchronously\n",
      "2025-03-13 16:02:48,101 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 75b28081f6...)\n",
      "2025-03-13 16:02:48,101 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2260\n",
      "2025-03-13 16:02:48,102 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 1328\n",
      "2025-03-13 16:02:48,102 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 1328 for 399 questions\n",
      "2025-03-13 16:02:48,102 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 1328 asynchronously\n",
      "2025-03-13 16:02:48,106 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: 0571b0f0f8...)\n",
      "2025-03-13 16:02:48,107 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2102\n",
      "2025-03-13 16:02:48,107 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4222\n",
      "2025-03-13 16:02:48,107 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4222 for 399 questions\n",
      "2025-03-13 16:02:48,108 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4222 asynchronously\n",
      "2025-03-13 16:02:48,111 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: b060d12362...)\n",
      "2025-03-13 16:02:48,113 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 987\n",
      "2025-03-13 16:02:48,113 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 6631\n",
      "2025-03-13 16:02:48,113 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 6631 for 399 questions\n",
      "2025-03-13 16:02:48,114 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 6631 asynchronously\n",
      "2025-03-13 16:02:48,117 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: a8ff377380...)\n",
      "2025-03-13 16:02:48,370 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 5506\n",
      "2025-03-13 16:02:48,371 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 593\n",
      "2025-03-13 16:02:48,372 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 593 for 399 questions\n",
      "2025-03-13 16:02:48,373 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 593 asynchronously\n",
      "2025-03-13 16:02:48,374 - text_topic_extraction.llm_api.openai_client - INFO - Using cached structured response (key: bd0482ddac...)\n",
      "2025-03-13 16:02:48,374 - text_topic_extraction.text_topic_processor - INFO - Generated 399 answers for patient 2385\n",
      "2025-03-13 16:02:48,375 - text_topic_extraction.text_topic_processor - INFO - Generating answers for patient 4906\n",
      "2025-03-13 16:02:48,375 - text_topic_extraction.answer_generator.answer_generator - INFO - Generating answers asynchronously for patient 4906 for 399 questions\n",
      "2025-03-13 16:02:48,375 - text_topic_extraction.answer_generator.answer_generator - INFO - Sending batch of 399 questions for patient 4906 asynchronously\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m patient_concepts_subset = {\u001b[38;5;28mstr\u001b[39m(idx): patient_concepts[\u001b[38;5;28mstr\u001b[39m(idx)] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m test_idxs[:NUM_EXTRACT]}\n\u001b[32m      3\u001b[39m async_processor.patient_notes = {\u001b[38;5;28mstr\u001b[39m(idx): patient_notes[\u001b[38;5;28mstr\u001b[39m(idx)] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m test_idxs[:NUM_EXTRACT]}\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m test_patient_answers = \u001b[38;5;28;01mawait\u001b[39;00m async_processor._generate_answers_async(\n\u001b[32m      6\u001b[39m     patient_concepts=patient_concepts_subset,\n\u001b[32m      7\u001b[39m     topic_questions=all_topic_questions,\n\u001b[32m      8\u001b[39m     answer_generator=answer_generator,\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/text_topic_extraction/text_topic_extraction/text_topic_processor.py:1295\u001b[39m, in \u001b[36mAsyncTextTopicProcessor._generate_answers_async\u001b[39m\u001b[34m(self, patient_concepts, topic_questions, answer_generator)\u001b[39m\n\u001b[32m   1289\u001b[39m tasks = [\n\u001b[32m   1290\u001b[39m     generate_answers_for_patient(patient_id, concepts)\n\u001b[32m   1291\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m patient_id, concepts \u001b[38;5;129;01min\u001b[39;00m patient_concepts.items()\n\u001b[32m   1292\u001b[39m ]\n\u001b[32m   1294\u001b[39m \u001b[38;5;66;03m# Run tasks concurrently and gather results\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n\u001b[32m   1297\u001b[39m \u001b[38;5;66;03m# Organize results by patient ID\u001b[39;00m\n\u001b[32m   1298\u001b[39m patient_answers = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/text_topic_extraction/text_topic_extraction/text_topic_processor.py:1269\u001b[39m, in \u001b[36mAsyncTextTopicProcessor._generate_answers_async.<locals>.generate_answers_for_patient\u001b[39m\u001b[34m(patient_id, concepts)\u001b[39m\n\u001b[32m   1266\u001b[39m \u001b[38;5;66;03m# Generate answers using the appropriate method\u001b[39;00m\n\u001b[32m   1267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(answer_generator, AsyncAnswerGenerator):\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# Use the async method directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1269\u001b[39m     answers = \u001b[38;5;28;01mawait\u001b[39;00m answer_generator.generate_answers(\n\u001b[32m   1270\u001b[39m         patient_concepts=concepts,\n\u001b[32m   1271\u001b[39m         topic_questions=topic_questions,\n\u001b[32m   1272\u001b[39m         patient_notes=patient_original_notes,\n\u001b[32m   1273\u001b[39m     )\n\u001b[32m   1274\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1275\u001b[39m     \u001b[38;5;66;03m# Use to_thread for the synchronous AnswerGenerator\u001b[39;00m\n\u001b[32m   1276\u001b[39m     answers = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.to_thread(\n\u001b[32m   1277\u001b[39m         answer_generator.generate_answers,\n\u001b[32m   1278\u001b[39m         patient_concepts=concepts,\n\u001b[32m   1279\u001b[39m         topic_questions=topic_questions,\n\u001b[32m   1280\u001b[39m         patient_notes=patient_original_notes,\n\u001b[32m   1281\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/text_topic_extraction/text_topic_extraction/answer_generator/answer_generator.py:437\u001b[39m, in \u001b[36mAsyncAnswerGenerator.generate_answers\u001b[39m\u001b[34m(self, patient_concepts, topic_questions, patient_notes)\u001b[39m\n\u001b[32m    431\u001b[39m logger.info(\n\u001b[32m    432\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSending batch of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(topic_questions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m questions for patient \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatient_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m asynchronously\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    433\u001b[39m )\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    436\u001b[39m     \u001b[38;5;66;03m# Use structured generation to get a clean JSON response (async version)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.llm_api.async_send_structured_prompt(\n\u001b[32m    438\u001b[39m         prompt=prompt,\n\u001b[32m    439\u001b[39m         response_model=AnswerGenerationResult,\n\u001b[32m    440\u001b[39m     )\n\u001b[32m    442\u001b[39m     \u001b[38;5;66;03m# The response should directly be a dictionary of question indices to probabilities\u001b[39;00m\n\u001b[32m    443\u001b[39m     answers_dict = response[\u001b[33m\"\u001b[39m\u001b[33manswers\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/text_topic_extraction/text_topic_extraction/llm_api/openai_client.py:378\u001b[39m, in \u001b[36mAsyncOpenAIClient.async_send_structured_prompt\u001b[39m\u001b[34m(self, prompt, response_model)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masync_send_structured_prompt\u001b[39m(\n\u001b[32m    366\u001b[39m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, response_model: Type[BaseModel]\n\u001b[32m    367\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    368\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[33;03m    Send a prompt to the LLM asynchronously and get a structured response.\u001b[39;00m\n\u001b[32m    370\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    376\u001b[39m \u001b[33;03m        The structured response as a dictionary\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_generate_structured_response(\n\u001b[32m    379\u001b[39m         prompt=prompt,\n\u001b[32m    380\u001b[39m         response_model=response_model,\n\u001b[32m    381\u001b[39m         use_cache=\u001b[38;5;28mself\u001b[39m.use_cache,\n\u001b[32m    382\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/text_topic_extraction/text_topic_extraction/llm_api/openai_client.py:538\u001b[39m, in \u001b[36mAsyncOpenAIClient.async_generate_structured_response\u001b[39m\u001b[34m(self, prompt, response_model, system_message, use_cache)\u001b[39m\n\u001b[32m    536\u001b[39m \u001b[38;5;66;03m# Check the cache if enabled\u001b[39;00m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n\u001b[32m--> \u001b[39m\u001b[32m538\u001b[39m     cached_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache.async_get_response_by_key(cache_key)\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cached_response:\n\u001b[32m    540\u001b[39m         logger.info(\n\u001b[32m    541\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing cached structured response (key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_key[:\u001b[32m10\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    542\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/text_topic_extraction/text_topic_extraction/cache/cache_manager.py:129\u001b[39m, in \u001b[36mCacheManager.async_get_response_by_key\u001b[39m\u001b[34m(self, cache_key)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masync_get_response_by_key\u001b[39m(\u001b[38;5;28mself\u001b[39m, cache_key: \u001b[38;5;28mstr\u001b[39m) -> Optional[Any]:\n\u001b[32m    120\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03m    Get a response from the cache by its key asynchronously.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    127\u001b[39m \u001b[33;03m        The cached response, or None if not found\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_async(\u001b[38;5;28mself\u001b[39m.get_response_by_key, cache_key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/bc-llm/text_topic_extraction/text_topic_extraction/cache/cache_manager.py:75\u001b[39m, in \u001b[36mCacheManager._run_async\u001b[39m\u001b[34m(self, func, *args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, *args, **kwargs):\n\u001b[32m     74\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run a synchronous function asynchronously using a thread pool.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_event_loop().run_in_executor(\n\u001b[32m     76\u001b[39m         \u001b[38;5;28mself\u001b[39m._executor, \u001b[38;5;28;01mlambda\u001b[39;00m: func(*args, **kwargs)\n\u001b[32m     77\u001b[39m     )\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "NUM_EXTRACT = 400\n",
    "patient_concepts_subset = {str(idx): patient_concepts[str(idx)] for idx in test_idxs[:NUM_EXTRACT]}\n",
    "async_processor.patient_notes = {str(idx): patient_notes[str(idx)] for idx in test_idxs[:NUM_EXTRACT]}\n",
    "\n",
    "test_patient_answers = await async_processor._generate_answers_async(\n",
    "    patient_concepts=patient_concepts_subset,\n",
    "    topic_questions=all_topic_questions,\n",
    "    answer_generator=answer_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create topic matrix\n",
    "test_topic_matrix = answer_generator.create_topic_matrix(test_patient_answers)\n",
    "\n",
    "# Create matrix DataFrames (always do this even if not saving)\n",
    "test_binary_matrix_df = MatrixBuilder.create_binary_matrix(test_topic_matrix)\n",
    "test_probability_matrix_df = MatrixBuilder.create_probability_matrix(\n",
    "    test_topic_matrix\n",
    ")\n",
    "\n",
    "# Create return dictionary with DataFrames\n",
    "test_results = {\n",
    "    \"binary_matrix_df\": test_binary_matrix_df,\n",
    "    \"probability_matrix_df\": test_probability_matrix_df,\n",
    "    \"topic_matrix\": test_topic_matrix,\n",
    "    \"topics\": topics,\n",
    "    \"topic_questions\": all_topic_questions,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"exp_mimic/_output/test.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(test_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"exp_mimic/_output/test.pkl\", \"rb\") as f:\n",
    "    test_results = pickle.load(f)\n",
    "    test_probability_matrix_df = test_results['probability_matrix_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6774193548387096"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(llm_extract_df.y.iloc[test_idxs[:NUM_EXTRACT]], rf.predict_proba(test_probability_matrix_df)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7232057644588662"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(llm_extract_df.y.iloc[test_idxs[:NUM_EXTRACT]], gb.predict_proba(test_probability_matrix_df)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.707052872685627"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(llm_extract_df.y.iloc[test_idxs[:NUM_EXTRACT]], lr.predict_proba(test_probability_matrix_df)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728526436342814"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(llm_extract_df.y.iloc[test_idxs[:NUM_EXTRACT]], true_prob[test_idxs[:NUM_EXTRACT]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=-0.6790301721684652, pvalue=2.1958160898966095e-55)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(probability_matrix_df.iloc[:,1], llm_extract_df.label_tobacco_Present.iloc[train_idxs[:NUM_EXTRACT]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([topic_q.question for topic_q in all_topic_questions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
