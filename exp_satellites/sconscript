import os
from os.path import join as path_join
from nestly.scons import SConsWrap
from nestly import Nest
from SCons.Script import Environment, Command, AddOption

"""
Satellites fMoW experiment
"""

Import('env')
localenv = env.Clone()

# Set up state
nest = SConsWrap(Nest(), localenv['output'], alias_environment=localenv)

# NOTE: The LLM Api only supports images for OpenAI models

BATCH_SIZE = 40
NUM_NEW_TOKENS = 300

NUM_GREEDY = 1
NUM_BOOST_ITERS = 30

BAYESIAN_PRIOR_PROMPT = 'exp_satellites/prompts/bayesian_prior.txt'
BAYESIAN_ITER_PROMPT = 'exp_satellites/prompts/bayesian_iter.txt'
EXTRACT_LLM_PROMPT = 'exp_satellites/prompts/extract_concepts.txt'
BASELINE_PROMPT = 'exp_satellites/prompts/baseline_init.txt'
BOOSTING_PROMPT = 'exp_satellites/prompts/boosting_iter.txt'
CONCEPTS_PROMPT = 'exp_satellites/prompts/concept_questions.txt'

LLM_MODELS = [
    'gpt-4o-mini'
]
LLM_DICT = {
    'gpt-4o-mini': True, # true using API
}

nest.add('seed', [
        0
    ],
    label_func=lambda c: "seed_%d" % c
)

nest.add(
    'use_all_classes',
    [True])

nest.add(
    'max_num_obs', # per class
    [100],
    label_func=lambda c: f'max_num_obs_{c}')

nest.add(
    'country_code',
    ['USA'])

@nest.add_target_with_env(localenv)
def assemble_satellites(env, outdir, c):
    cmd = [
        'python scripts/assemble_satellites.py',
        '--seed', c['seed'] + 1,
        '--labelled-data ${TARGETS[0]}',
        '--max-num-obs', c['max_num_obs'],
        '--country', c['country_code'],
    ]
    if c['use_all_classes']:
        cmd += ['--use-all']

    targets = [
        path_join(outdir, 'labels.csv')
    ]

    return env.Command(
        targets,
        [],
        ' '.join(map(str, cmd))
    )

nest.add('llm_model', LLM_MODELS)

nest.add('test_frac',
    [
        0.5
    ],
    label_func=lambda c: "test_%.2f" % c
)

@nest.add_target_with_env(localenv)
def train_test_split(env, outdir, c):
    cmd = [
        'python scripts/train_test_split.py',
        '--seed', c['seed'] + 1,
        '--data-csv ${SOURCES[0]}',
        '--test-frac',
        c['test_frac'],
        '--indices-csv ${TARGETS[0]}',
    ]

    sources = c['assemble_satellites']
    targets = [
        path_join(outdir, 'train_test_indices.csv'),
    ]

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

@nest.add_target_with_env(localenv)
def extract_llm_output(env, outdir, c):
    targets = [
        path_join(outdir, 'log_extract.txt'),
        path_join(outdir, 'concept_extractions.csv'),
    ]
    cmd = [
        'python scripts/extract_llm_concepts.py',
        f'--seed',
        c['seed'] + 3,
        '--is-image',
        '--num-new-tokens',
        NUM_NEW_TOKENS,
        '--in-dataset-file ${SOURCES[0]}',
        '--indices ${SOURCES[1]}',
        '--batch-size',
        40,
        '--prompt-file',
        EXTRACT_LLM_PROMPT,
        '--log-file ${TARGETS[0]}',
        '--llm-output ${TARGETS[1]}',
        '--llm-model-type',
        c['llm_model'],
        '--use-api',
    ]

    sources = [
        c['assemble_satellites'][0],
        c['train_test_split'][0],
    ]

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

nest.add(
    'num_meta_concepts', 
    lambda c: [60] if c['use_all_classes'] else [20],
    label_func=lambda c: "num_concepts_%s" % c
)
nest.add(
    'max_obs', 
    lambda c: [50 * 56] if c['use_all_classes'] else [50 * 17],
    label_func=lambda c: "max_obs_%s" % c
)
nest.add_aggregate('all_test_extractions', list)
nest.add_aggregate('bayesian_agg', list)
nest.add_aggregate('result_agg', list)
nest.add_aggregate('train_baseline_history', str)
nest.add_aggregate('train_boosting_history', str)

@nest.add_target_with_env(localenv)
def train_baseline(env, outdir, c):
    cached_extractions = path_join('exp_satellites', outdir, 'baseline_extractions.pkl')
    cmd = [
        'python scripts/train_baseline.py',
        f'--seed',
        c['seed'] + 2,
        '--batch-size', BATCH_SIZE,
        '--num-meta-concepts',
        c['num_meta_concepts'],
        '--learner-type count_l2',
        '--in-dataset-file ${SOURCES[0]}',
        '--indices-csv ${SOURCES[1]}',
        '--out-training-history-file ${TARGETS[0]}',
        '--log-file  ${TARGETS[1]}',
        '--num-top-attributes',
        c['num_meta_concepts'] + 20,
        '--llm-model-type',
         c['llm_model'],
         "--max-obs", c['max_obs'],
         '--out-extractions', cached_extractions,
         '--is-image',
         '--prompt-concepts-file', CONCEPTS_PROMPT,
         '--baseline-init-file', BASELINE_PROMPT,
         '--init-concepts-file ${SOURCES[2]}'
    ]

    sources = [
        c['assemble_satellites'][0],
        c['train_test_split'][0],
        c['extract_llm_output'][1],
    ]
    targets = [
        path_join(outdir, 'baseline_history.pkl'),
        path_join(outdir, 'log_train_baseline1.txt'),
    ]
    c['train_baseline_history'] = targets[0]
    if os.path.exists(targets[0]):
        return

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

@nest.add_target_with_env(localenv)
def train_blackbox(env, outdir, c):
    cmd = [
            'python scripts/train_image_blackbox.py',
            '--seed', c['seed'] + 2,
            '--in-dataset-file ${SOURCES[0]}',
            '--indices-csv ${SOURCES[1]}',
            '--log-file  ${TARGETS[0]}',
            '--out-mdl ${TARGETS[1]}'
    ]

    sources = [
        c['assemble_satellites'][0],
        c['train_test_split'][0],
    ]
    targets = [
        path_join(outdir, 'log_train_image_resnet.txt'),
        path_join(outdir, 'resnet_image_mdl.pkl'),
    ]

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )


@nest.add_target_with_env(localenv)
def evaluate_blackbox(env, outdir, c):
    cmd = [
            'python scripts/evaluate_image_blackbox.py',
            f'--seed', c['seed'] + 5,
            '--in-dataset-file ${SOURCES[0]}',
            '--indices-csv ${SOURCES[1]}',
            '--in-mdl ${SOURCES[2]}',
            '--results-csv ${TARGETS[0]}'
    ]

    sources = [
        c['assemble_satellites'][0],
        c['train_test_split'][0],
        c['train_blackbox'][1]
    ]
    targets = [
        path_join(outdir, 'image_resnet_results.csv'),
    ]
    c['result_agg'].append(targets[0])

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

nest.add(
    'bayesian',
    [
        'bayesian',
    ])

nest.add(
    'train_frac',
    [
        0.5
    ],
    label_func=lambda c: "train_frac_%.2f" % c)


@nest.add_target_with_env(localenv)
def train_boosting(env, outdir, c):
#    cached_extractions = path_join('exp_satellites', outdir, 'boosting_extractions.pkl')
    cmd = [
        'python scripts/train_boosting.py',
        f'--seed',
        c['seed'] + 2,
        '--num-boost-samples', 2,
        '--num-iters', NUM_BOOST_ITERS,
        '--batch-size', BATCH_SIZE,
        '--boosting-prompt', BOOSTING_PROMPT,
        '--prompt-concepts-file', CONCEPTS_PROMPT,
        '--in-dataset-file ${SOURCES[0]}',
        '--indices-csv ${SOURCES[1]}',
        '--out-training-history-file ${TARGETS[0]}',
        '--log-file  ${TARGETS[1]}',
        '--llm-model-type', c['llm_model'],
        '--use-api' if LLM_DICT[c['llm_model']] else '',
#        '--out-extractions', cached_extractions,
         '--is-image',
    ]

    sources = [
        c["assemble_satellites"][0],
        c['train_test_split'][0],
    ]
    targets = [
        path_join(outdir, 'boosting_history.pkl'),
        path_join(outdir, 'log_train_boosting.txt')
    ]
    c['train_boosting_history'] = targets[0]
    if os.path.exists(targets[0]):
        return

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

@nest.add_target_with_env(localenv)
def evaluate_boosting(env, outdir, c):
    cmd = [
        'python scripts/evaluate_bayesian.py',
        f'--seed',
        c['seed'] + 5,
        '--method-name boosting',
        '--num-posterior-iters',
        1,
        '--batch-size',
        BATCH_SIZE,
        '--prompt-concepts-file', CONCEPTS_PROMPT,
        '--in-dataset-file ${SOURCES[0]}',
        '--indices-csv ${SOURCES[1]}',
        '--training-history-file ${SOURCES[2]}',
#        '--out-extraction ${SOURCES[3]}',
        '--log-file ${TARGETS[0]}',
        '--llm-model-type',
        c['llm_model'],
        '--use-api' if LLM_DICT[c['llm_model']] else '',
        '--result-csv ${TARGETS[1]}',
        # '--calib ${TARGETS[1]}',
        '--is-image',
    ]

    sources = [
        c["assemble_satellites"][0],
        c['train_test_split'][0],
        c['train_boosting_history'],
#        c['test_extractions'],
    ]
    targets = [
        path_join(outdir, 'test_boosting_log1.txt'),
        # path_join(outdir, 'calib_boosting.png'),
        path_join(outdir, 'result_boosting.csv'),
    ]
    c['result_agg'].append(targets[1])

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

nest.add_aggregate('train_bayesian_history', str)
@nest.add_target_with_env(localenv)
def train_bayesian(env, outdir, c):
    cached_extractions = path_join('exp_satellites', outdir, 'extractions.pkl')
    cmd = [
        'python scripts/train_bayesian.py',
        f'--seed',
        c['seed'] + 4,
        '--batch-size', BATCH_SIZE,
        '--num-greedy-holdout', 2,
        '--num-greedy-epochs', NUM_GREEDY,
        '--is-greedy-metric-acc',
        '--max-epochs',
        1,
        '--num-meta-concepts',
        c['num_meta_concepts'],
        '--learner-type count_l2',
        '--final-learner l2',
        '--train-frac', c['train_frac'],
        '--in-dataset-file ${SOURCES[0]}',
        '--indices-csv ${SOURCES[2]}',
        '--out-extraction', cached_extractions,
        '--log-file ${TARGETS[0]}',
        '--init-history-file ${SOURCES[1]}',
        '--training-history-file ${TARGETS[1]}',
        '--aucs-plot-file ${TARGETS[2]}',
        '--llm-extraction-type',
        c['llm_model'],
        '--llm-iter-type',
        'gpt-4o',
        "--max-obs", c['max_obs'],
        '--is-image',
        '--use-api',
        '--prompt-concepts-file', CONCEPTS_PROMPT,
        '--prompt-prior-file', BAYESIAN_PRIOR_PROMPT,
        '--prompt-iter-file', BAYESIAN_ITER_PROMPT,
        '--prompt-iter-type conditional',
        '--init-concepts-file ${SOURCES[3]}',
    ]

    sources = [
        c['assemble_satellites'][0],
        c['train_baseline_history'],
        c['train_test_split'][0],
        c['extract_llm_output'][1],
    ]
    targets = [
        path_join(outdir, 'log_train_bayesian.txt'),
        path_join(outdir, 'training_history.pkl'),
        path_join(outdir, 'aucs.png'),
    ]
    c['train_bayesian_history'] = targets[1]
    c['bayesian_agg'].append(targets[1])
    # if os.path.exists(targets[1]):
    #     return

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
        )

@nest.add_target_with_env(localenv)
def evaluate_bayesian(env, outdir, c):
    cmd = [
        'python scripts/evaluate_bayesian.py',
        '--cache cache_satellites_test.db',
        f'--seed',
        c['seed'] + 5,
        '--num-posterior-iters',
        c['num_meta_concepts'] * 2,
        '--batch-size',
        BATCH_SIZE,
        '--method-name bayesian',
        '--in-dataset-file ${SOURCES[0]}',
        '--indices-csv ${SOURCES[1]}',
        '--training-history-file ${SOURCES[2]}',
        # '--out-extraction ${SOURCES[3]}',
        '--log-file ${TARGETS[0]}',
        '--llm-model-type',
        c['llm_model'],
        '--prompt-concepts-file', CONCEPTS_PROMPT,
        '--use-api' if LLM_DICT[c['llm_model']] else '',
        '--is-image',
        # '--calib ${TARGETS[1]}',
        '--result-csv ${TARGETS[1]}',
    ]

    sources = [
        c['assemble_satellites'][0],
        c['train_test_split'][0],
        c['train_bayesian_history'],
    ]
    targets = [
        path_join(outdir, 'test_bayesian_log.txt'),
        # path_join(outdir, 'calib_bayesian.png'),
        path_join(outdir, 'result_bayesian.csv'),
    ]
    c['result_agg'].append(targets[1])

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

nest.add(
    'ood_country_code',
    ['CHN'])

@nest.add_target_with_env(localenv)
def assemble_satellites_ood(env, outdir, c):
    cmd = [
        'python scripts/assemble_satellites.py',
        '--seed', c['seed'] + 1,
        '--labelled-data ${TARGETS[0]}',
        '--max-num-obs', c['max_num_obs'],
        '--orig-country', c['country_code'],
        '--country', c['ood_country_code'],
    ]
    if c['use_all_classes']:
        cmd += ['--use-all']

    targets = [
        path_join(outdir, 'ood_labels.csv')
    ]

    return env.Command(
        targets,
        [],
        ' '.join(map(str, cmd))
    )

nest.add('test_frac',
    [
        0.5
    ],
    label_func=lambda c: "test_%.2f" % c
)

@nest.add_target_with_env(localenv)
def train_test_split_ood(env, outdir, c):
    cmd = [
        'python scripts/train_test_split.py',
        '--seed', c['seed'] + 1,
        '--data-csv ${SOURCES[0]}',
        '--test-frac',
        c['test_frac'],
        '--indices-csv ${TARGETS[0]}',
    ]

    sources = c['assemble_satellites_ood']
    targets = [
        path_join(outdir, 'train_test_indices_ood.csv'),
    ]

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

@nest.add_target_with_env(localenv)
def evaluate_bayesian_ood(env, outdir, c):
    cmd = [
        'python scripts/evaluate_bayesian.py',
        '--cache',
        'cache_satellites.db',
        f'--seed',
        c['seed'] + 5,
        '--num-posterior-iters',
        c['num_meta_concepts'] * 2,
        '--batch-size',
        BATCH_SIZE,
        '--method-name bayesian',
        '--in-dataset-file ${SOURCES[0]}',
        '--indices-csv ${SOURCES[1]}',
        '--training-history-file ${SOURCES[2]}',
        # '--out-extraction ${SOURCES[3]}',
        '--log-file ${TARGETS[0]}',
        '--llm-model-type',
        c['llm_model'],
        '--prompt-concepts-file', CONCEPTS_PROMPT,
        '--use-api' if LLM_DICT[c['llm_model']] else '',
        '--is-image',
        # '--calib ${TARGETS[1]}',
        '--result-csv ${TARGETS[1]}',
    ]

    sources = [
        c['assemble_satellites_ood'][0],
        c['train_test_split_ood'][0],
        c['train_bayesian_history'],
    ]
    targets = [
        path_join(outdir, 'test_bayesian_ood_log1.txt'),
        # path_join(outdir, 'calib_bayesian.png'),
        path_join(outdir, 'result_bayesian_ood1.csv'),
    ]
    
    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

# @nest.add_target_with_env(localenv)
# def evaluate_blackbox_ood(env, outdir, c):
#     cmd = [
#             'python scripts/evaluate_image_blackbox.py',
#             f'--seed', c['seed'] + 5,
#             '--in-dataset-file ${SOURCES[0]}',
#             '--indices-csv ${SOURCES[1]}',
#             '--in-mdl ${SOURCES[2]}',
#             '--results-csv ${TARGETS[0]}',
#             '--log ${TARGETS[1]}'
#     ]

#     sources = [
#         c['assemble_satellites_ood'][0],
#         c['train_test_split_ood'][0],
#         c['train_blackbox'][1]
#     ]
#     targets = [
#         path_join(outdir, 'image_resnet_results_ood.csv'),
#         path_join(outdir, 'log_resnet_test_ood.txt'),
#     ]
    
#     return env.Command(
#         targets,
#         sources,
#         ' '.join(map(str, cmd))
#     )

@nest.add_target_with_env(localenv)
def evaluate_boosting_ood(env, outdir, c):
    cmd = [
        'python scripts/evaluate_bayesian.py',
        f'--seed',
        c['seed'] + 5,
        '--method-name boosting',
        '--num-posterior-iters',
        1,
        '--batch-size',
        BATCH_SIZE,
        '--prompt-concepts-file', CONCEPTS_PROMPT,
        '--in-dataset-file ${SOURCES[0]}',
        '--indices-csv ${SOURCES[1]}',
        '--training-history-file ${SOURCES[2]}',
        '--log-file ${TARGETS[0]}',
        '--llm-model-type',
        c['llm_model'],
        '--use-api',
        '--result-csv ${TARGETS[1]}',
        '--is-image',
    ]

    sources = [
        c['assemble_satellites_ood'][0],
        c['train_test_split_ood'][0],
        c['train_boosting_history'],
    ]
    targets = [
        path_join(outdir, 'test_boosting_ood_log1.txt'),
        path_join(outdir, 'result_boosting_ood1.csv'),
    ]

    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd))
    )

# # nest.pop('bayesian')
# # 
# # @nest.add_target_with_env(localenv)
# # def agg_results1(env, outdir, c):
# #     cmd = [
# #         'python scripts/aggregate_results.py',
# #         '--result-files ${SOURCES}',
# #         '--csv-file ${TARGETS[0]}',
# #     ]
# # 
# #     sources = c['result_agg']
# #     targets = [
# #         path_join(outdir, 'agg_res.csv'),
# #     ]
# # 
# #     return env.Command(
# #         targets,
# #         sources,
# #         ' '.join(map(str, cmd))
# #     )
